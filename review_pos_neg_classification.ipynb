{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.lib.io import file_io\n",
    "from konlpy.tag import Twitter\n",
    "from os import path, getcwd\n",
    "from word2vec_review import *\n",
    "from utils import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "데이터를 로드합니다.\n",
    "\n",
    "데이터는 네이버 영화 평점 데이터를 사용하다. <br>\n",
    "데이터에 대한 자세한 설명은 아래 데이터 출처에서 확인 할 수 있다. <br>\n",
    "(출처: https://github.com/e9t/nsmc) <br>\n",
    "\n",
    "data field: |id|document|label| <br>\n",
    "id: key review id <br>\n",
    "document: 140자 이하의 리뷰 글 <br>\n",
    "label: 1~4점은 neg(0), 9~10점은 pos(1), 5~8점은 중립으로 데이터에서 제외함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "work_dir = '/home/khlee/tutorial/review_sentiment_classification'\n",
    "data = pd.read_csv(work_dir + '/ratings_train.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## nan reviews 제거\n",
    "data = data[~pd.isnull(data.document)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    75170\n",
      "1    74825\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('label').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Tokenize\n",
    "한글 리뷰를 토큰화 합니다.\n",
    "한글 토큰화는 konlpy 패키지의 twitter 분석기를 사용하였습니다.\n",
    "kkma 등 다른 분석기와 비교해보니 속도 및 정규화 기능면에서 twitter를 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 21s, sys: 3.73 s, total: 4min 25s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "twit = Twitter()\n",
    "def twit_pos(x):\n",
    "    out = twit.pos(x.replace('\\\\n', ''), norm=True, stem=True)\n",
    "    return [i[0]+'/'+i[1] for i in out]\n",
    "%time data['twit_pos'] = data.document.apply(lambda x: twit_pos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review :\n",
      "아 더빙.. 진짜 짜증나네요 목소리\n",
      "tokenize reviw :\n",
      "['아/Exclamation', '더빙/Noun', '../Punctuation', '진짜/Noun', '짜증/Noun', '나다/Verb', '목소리/Noun']\n"
     ]
    }
   ],
   "source": [
    "print('review :')\n",
    "print(data.document[0])\n",
    "print('tokenize reviw :')\n",
    "print(data.twit_pos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_file = path.join(work_dir, 'twit_pos_df.pkl')\n",
    "with file_io.FileIO(result_file, mode='wb') as fp:\n",
    "     pickle.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 첫 twit_pos 이후 데이터를 저장했다면, 저장한 데이터를 불러온다.\n",
    "#with open(result_file, 'rb') as fp:\n",
    "#    data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Word dictionary\n",
    "word를 int로 변화하는 인코딩 사전과 다시 int를 word로 변경 하는 디코드 사전을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word: 2194536\n",
      "Unique word: 48764\n"
     ]
    }
   ],
   "source": [
    "int_to_word, word_to_int = mk_lookup_table(data.twit_pos)\n",
    "## save dictionary\n",
    "result_file = path.join(work_dir, 'word_dic.pkl')\n",
    "with file_io.FileIO(result_file, mode='wb') as fp:\n",
    "     pickle.dump([int_to_word, word_to_int], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize한 review word들을 위 인코드 사전을 사용해서 int로 변경합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_word = raw_word_to_int(data.twit_pos, word_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아/Exclamation', '더빙/Noun', '../Punctuation', '진짜/Noun', '짜증/Noun', '나다/Verb', '목소리/Noun']\n",
      "[9456, 9007, 9535, 9507, 9335, 9414, 8783]\n"
     ]
    }
   ],
   "source": [
    "print(data.twit_pos[0])\n",
    "print(int_word[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review_word2Vec\n",
    "Review의 word 데이터는 cardinality가 높아 one_hot 인코딩시 매우 sparse하고 단어와 단어사이의 연관성이 사라집니다. word data를 사용하기 위해서 word를 저차원 공간의 vector로 embedding으로 프리트레이닝 합니다.\n",
    "word2vec 수행 과정은 다음과 같이 하였습니다.\n",
    "1. subsampling을 수행합니다.\n",
    "    - 빈번하게 발생하는 단어는 적게 희소한 단어는 최대한 살리는 sampling을 하여 word들이 균형있게 학습되도록 합니다.단어의 sample 확률 계산은 다음 과 같이 합니다. <br>\n",
    "    $ p(w_i) = sqrt( t / f(w_i) ) $, p: 확률, f: 빈도, t: threshold\n",
    "2. Skip-gram 방법으로 학습셋을 구성하고 학습합니다.\n",
    "    - window size = 10 <br>\n",
    "    - embedding size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELAPSED TIME: 0.22 sec\n",
      "size of data: 140028\n",
      "ELAPSED TIME: 1.13 sec\n",
      "Epoch 1/3 Iteration: 5000 Avg. Training loss: 252.2906 0.0094 sec/batch 11 total sec\n",
      "Epoch 1/3 Iteration: 10000 Avg. Training loss: 154.5364 0.0088 sec/batch 19 total sec\n",
      "Epoch 1/3 Iteration: 15000 Avg. Training loss: 102.2329 0.0087 sec/batch 28 total sec\n",
      "Epoch 1/3 Iteration: 20000 Avg. Training loss: 73.2507 0.0085 sec/batch 37 total sec\n",
      "Epoch 1/3 Iteration: 25000 Avg. Training loss: 57.3365 0.0085 sec/batch 45 total sec\n",
      "Epoch 1/3 Iteration: 30000 Avg. Training loss: 47.3191 0.0085 sec/batch 54 total sec\n",
      "Epoch 1/3 Iteration: 35000 Avg. Training loss: 39.9027 0.0085 sec/batch 62 total sec\n",
      "Epoch 1/3 Iteration: 40000 Avg. Training loss: 34.8042 0.0085 sec/batch 71 total sec\n",
      "Epoch 1/3 Iteration: 45000 Avg. Training loss: 32.1070 0.0085 sec/batch 79 total sec\n",
      "Epoch 1/3 Iteration: 50000 Avg. Training loss: 29.0050 0.0084 sec/batch 88 total sec\n",
      "Epoch 1/3 Iteration: 55000 Avg. Training loss: 26.5205 0.0085 sec/batch 96 total sec\n",
      "Epoch 1/3 Iteration: 60000 Avg. Training loss: 26.0171 0.0085 sec/batch 105 total sec\n",
      "Epoch 1/3 Iteration: 65000 Avg. Training loss: 24.0714 0.0085 sec/batch 113 total sec\n",
      "Epoch 1/3 Iteration: 70000 Avg. Training loss: 23.3556 0.0085 sec/batch 122 total sec\n",
      "Epoch 1/3 Iteration: 75000 Avg. Training loss: 22.8996 0.0085 sec/batch 130 total sec\n",
      "Epoch 1/3 Iteration: 80000 Avg. Training loss: 22.4158 0.0086 sec/batch 139 total sec\n",
      "Epoch 1/3 Iteration: 85000 Avg. Training loss: 21.6032 0.0085 sec/batch 147 total sec\n",
      "Epoch 1/3 Iteration: 90000 Avg. Training loss: 21.2126 0.0085 sec/batch 156 total sec\n",
      "Epoch 1/3 Iteration: 95000 Avg. Training loss: 19.8084 0.0085 sec/batch 164 total sec\n",
      "Epoch 1/3 Iteration: 100000 Avg. Training loss: 19.8600 0.0085 sec/batch 173 total sec\n",
      "Nearest to 똥망/Noun: 이라도/Josa, 부터가/Josa, 녀석/Noun, 멈추다/Verb, 느와르/Noun,\n",
      "Nearest to 지하/Noun: 자랑스럽다/Adjective, 전파/Noun, 협박/Noun, ~~!/Punctuation, 계단/Noun,\n",
      "Nearest to 구름/Noun: 개척/Noun, 문어/Noun, 린치/Noun, 피다/Verb, ,.../Punctuation,\n",
      "Nearest to 두려워하다/Verb: 모래/Noun, 간디/Noun, 입증/Noun, 내적/Noun, 공격/Noun,\n",
      "Nearest to 한결/Noun: 잔인/Noun, 평소/Noun, 다만/Noun, 화면/Noun, 심심하다/Adjective,\n",
      "Nearest to 전파/Noun: 고/Noun, 극단/Noun, 햇/Noun, 자랑스럽다/Adjective, 런닝타임/Noun,\n",
      "Nearest to 삼키다/Verb: 진자/Noun, 나니아/Noun, 이제껏/Noun, 크게/Noun, 음식/Noun,\n",
      "Nearest to 빠져나오다/Verb: 완벽/Noun, 가리다/Verb, 치고는/Josa, 옛/Noun, //Punctuation,\n",
      "Nearest to 리더/Noun: 돼지/Noun, 남다/Verb, 오늘/Noun, 정이/Noun, 지우다/Verb,\n",
      "Nearest to 일본어/Noun: 구요다/Verb, 외면/Noun, 변질/Noun, 애절/Noun, 속이다/Verb,\n",
      "Epoch 1/3 Iteration: 105000 Avg. Training loss: 20.2440 0.0086 sec/batch 181 total sec\n",
      "Epoch 1/3 Iteration: 110000 Avg. Training loss: 18.9849 0.0085 sec/batch 190 total sec\n",
      "Epoch 1/3 Iteration: 115000 Avg. Training loss: 19.6055 0.0086 sec/batch 198 total sec\n",
      "Epoch 1/3 Iteration: 120000 Avg. Training loss: 19.2751 0.0086 sec/batch 207 total sec\n",
      "Epoch 1/3 Iteration: 125000 Avg. Training loss: 19.1620 0.0086 sec/batch 215 total sec\n",
      "Epoch 1/3 Iteration: 130000 Avg. Training loss: 19.2188 0.0086 sec/batch 224 total sec\n",
      "Epoch 1/3 Iteration: 135000 Avg. Training loss: 18.3114 0.0086 sec/batch 233 total sec\n",
      "Epoch 1/3 Iteration: 140000 Avg. Training loss: 18.7443 0.0087 sec/batch 241 total sec\n",
      "size of data: 140085\n",
      "ELAPSED TIME: 0.71 sec\n",
      "Epoch 2/3 Iteration: 145000 Avg. Training loss: 18.0274 0.0086 sec/batch 251 total sec\n",
      "Epoch 2/3 Iteration: 150000 Avg. Training loss: 17.9050 0.0087 sec/batch 260 total sec\n",
      "Epoch 2/3 Iteration: 155000 Avg. Training loss: 18.1677 0.0086 sec/batch 268 total sec\n",
      "Epoch 2/3 Iteration: 160000 Avg. Training loss: 18.3009 0.0086 sec/batch 277 total sec\n",
      "Epoch 2/3 Iteration: 165000 Avg. Training loss: 18.0132 0.0087 sec/batch 285 total sec\n",
      "Epoch 2/3 Iteration: 170000 Avg. Training loss: 17.3327 0.0088 sec/batch 294 total sec\n",
      "Epoch 2/3 Iteration: 175000 Avg. Training loss: 17.8014 0.0088 sec/batch 303 total sec\n",
      "Epoch 2/3 Iteration: 180000 Avg. Training loss: 17.3947 0.0088 sec/batch 312 total sec\n",
      "Epoch 2/3 Iteration: 185000 Avg. Training loss: 17.6405 0.0088 sec/batch 321 total sec\n",
      "Epoch 2/3 Iteration: 190000 Avg. Training loss: 17.5435 0.0087 sec/batch 329 total sec\n",
      "Epoch 2/3 Iteration: 195000 Avg. Training loss: 16.8935 0.0087 sec/batch 338 total sec\n",
      "Epoch 2/3 Iteration: 200000 Avg. Training loss: 17.5018 0.0089 sec/batch 347 total sec\n",
      "Nearest to 똥망/Noun: 피식/Adverb, 해대/Noun, 예의/Noun, 증명/Noun, 녀석/Noun,\n",
      "Nearest to 지하/Noun: 자랑스럽다/Adjective, 계단/Noun, 김혜수/Noun, ~~!/Punctuation, 협박/Noun,\n",
      "Nearest to 구름/Noun: is/Alpha, 와는/Josa, 은지원/Noun, 소속/Noun, 스럽지도/Josa,\n",
      "Nearest to 두려워하다/Verb: 공짜/Noun, 졸다/Verb, 공격/Noun, 간디/Noun, 뉴스/Noun,\n",
      "Nearest to 한결/Noun: 요새/Noun, 차려/Noun, 내주다/Verb, 한동안/Adverb, 애절/Noun,\n",
      "Nearest to 전파/Noun: 자랑스럽다/Adjective, 실사/Noun, 고문/Noun, 치가/Noun, 신화/Noun,\n",
      "Nearest to 삼키다/Verb: 이제껏/Noun, o/Alpha, 스파이/Noun, 2000/Number, 음식/Noun,\n",
      "Nearest to 빠져나오다/Verb: 완벽/Noun, 비참/Noun, 에야/Josa, 경기/Noun, 치고는/Josa,\n",
      "Nearest to 리더/Noun: 돼지/Noun, 한지민/Noun, 드네/Noun, 개독/Noun, 블랙/Noun,\n",
      "Nearest to 일본어/Noun: 변질/Noun, 조명/Noun, 홧팅/Noun, 도둑/Noun, 구요다/Verb,\n",
      "Epoch 2/3 Iteration: 205000 Avg. Training loss: 16.9745 0.0088 sec/batch 356 total sec\n",
      "Epoch 2/3 Iteration: 210000 Avg. Training loss: 17.0685 0.0087 sec/batch 365 total sec\n",
      "Epoch 2/3 Iteration: 215000 Avg. Training loss: 16.8035 0.0087 sec/batch 373 total sec\n",
      "Epoch 2/3 Iteration: 220000 Avg. Training loss: 16.7650 0.0088 sec/batch 382 total sec\n",
      "Epoch 2/3 Iteration: 225000 Avg. Training loss: 16.8154 0.0088 sec/batch 391 total sec\n",
      "Epoch 2/3 Iteration: 230000 Avg. Training loss: 17.0454 0.0088 sec/batch 400 total sec\n",
      "Epoch 2/3 Iteration: 235000 Avg. Training loss: 16.2027 0.0088 sec/batch 408 total sec\n",
      "Epoch 2/3 Iteration: 240000 Avg. Training loss: 17.1801 0.0087 sec/batch 417 total sec\n",
      "Epoch 2/3 Iteration: 245000 Avg. Training loss: 17.0131 0.0088 sec/batch 426 total sec\n",
      "Epoch 2/3 Iteration: 250000 Avg. Training loss: 16.1094 0.0089 sec/batch 435 total sec\n",
      "Epoch 2/3 Iteration: 255000 Avg. Training loss: 17.2944 0.0088 sec/batch 444 total sec\n",
      "Epoch 2/3 Iteration: 260000 Avg. Training loss: 16.6507 0.0088 sec/batch 453 total sec\n",
      "Epoch 2/3 Iteration: 265000 Avg. Training loss: 16.7563 0.0088 sec/batch 461 total sec\n",
      "Epoch 2/3 Iteration: 270000 Avg. Training loss: 16.5218 0.0087 sec/batch 470 total sec\n",
      "Epoch 2/3 Iteration: 275000 Avg. Training loss: 16.7191 0.0089 sec/batch 479 total sec\n",
      "Epoch 2/3 Iteration: 280000 Avg. Training loss: 16.2867 0.0088 sec/batch 488 total sec\n",
      "size of data: 140002\n",
      "ELAPSED TIME: 1.18 sec\n",
      "Epoch 3/3 Iteration: 285000 Avg. Training loss: 16.1543 0.0088 sec/batch 498 total sec\n",
      "Epoch 3/3 Iteration: 290000 Avg. Training loss: 16.2678 0.0092 sec/batch 507 total sec\n",
      "Epoch 3/3 Iteration: 295000 Avg. Training loss: 16.3475 0.0089 sec/batch 516 total sec\n",
      "Epoch 3/3 Iteration: 300000 Avg. Training loss: 16.3992 0.0090 sec/batch 525 total sec\n",
      "Nearest to 똥망/Noun: 통찰/Noun, 야/Noun, 폭소/Noun, 하곤/Josa, 대비/Noun,\n",
      "Nearest to 지하/Noun: 김혜수/Noun, 추구/Noun, 전파/Noun, 존내/Noun, 협박/Noun,\n",
      "Nearest to 구름/Noun: 돋다/Adjective, 작위/Noun, 스럽지도/Josa, 횟수/Noun, 소속/Noun,\n",
      "Nearest to 두려워하다/Verb: 공격/Noun, 두근두근/Adverb, 일텐데/Josa, 짜증스럽다/Adjective, 자고/Noun,\n",
      "Nearest to 한결/Noun: 하필/Noun, 감독판/Noun, 진솔/Noun, 렉/Noun, 대안/Noun,\n",
      "Nearest to 전파/Noun: 실사/Noun, 에게도/Josa, 치가/Noun, 멘탈/Noun, 자신감/Noun,\n",
      "Nearest to 삼키다/Verb: 이제껏/Noun, 종합/Noun, 깨어나다/Verb, 애틋/Noun, 저번/Noun,\n",
      "Nearest to 빠져나오다/Verb: 전국/Noun, 드물다/Adjective, 에야/Josa, 대비/Noun, 구혜선/Noun,\n",
      "Nearest to 리더/Noun: 완소/Noun, 최소/Noun, 개독/Noun, 한지민/Noun, 슈퍼맨/Noun,\n",
      "Nearest to 일본어/Noun: 변질/Noun, 조명/Noun, 홧팅/Noun, 곱씹다/Verb, 외면/Noun,\n",
      "Epoch 3/3 Iteration: 305000 Avg. Training loss: 16.1181 0.0091 sec/batch 534 total sec\n",
      "Epoch 3/3 Iteration: 310000 Avg. Training loss: 16.5626 0.0091 sec/batch 543 total sec\n",
      "Epoch 3/3 Iteration: 315000 Avg. Training loss: 16.2672 0.0090 sec/batch 552 total sec\n",
      "Epoch 3/3 Iteration: 320000 Avg. Training loss: 16.1145 0.0090 sec/batch 561 total sec\n",
      "Epoch 3/3 Iteration: 325000 Avg. Training loss: 16.2042 0.0090 sec/batch 570 total sec\n",
      "Epoch 3/3 Iteration: 330000 Avg. Training loss: 16.0301 0.0088 sec/batch 579 total sec\n",
      "Epoch 3/3 Iteration: 335000 Avg. Training loss: 15.6044 0.0090 sec/batch 588 total sec\n",
      "Epoch 3/3 Iteration: 340000 Avg. Training loss: 16.4340 0.0089 sec/batch 597 total sec\n",
      "Epoch 3/3 Iteration: 345000 Avg. Training loss: 16.3986 0.0089 sec/batch 606 total sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 Iteration: 350000 Avg. Training loss: 16.2012 0.0089 sec/batch 615 total sec\n",
      "Epoch 3/3 Iteration: 355000 Avg. Training loss: 15.8062 0.0090 sec/batch 624 total sec\n",
      "Epoch 3/3 Iteration: 360000 Avg. Training loss: 16.4414 0.0090 sec/batch 633 total sec\n",
      "Epoch 3/3 Iteration: 365000 Avg. Training loss: 16.1106 0.0090 sec/batch 642 total sec\n",
      "Epoch 3/3 Iteration: 370000 Avg. Training loss: 15.5705 0.0089 sec/batch 651 total sec\n",
      "Epoch 3/3 Iteration: 375000 Avg. Training loss: 15.5328 0.0088 sec/batch 660 total sec\n",
      "Epoch 3/3 Iteration: 380000 Avg. Training loss: 16.1143 0.0089 sec/batch 669 total sec\n",
      "Epoch 3/3 Iteration: 385000 Avg. Training loss: 15.7420 0.0089 sec/batch 677 total sec\n",
      "Epoch 3/3 Iteration: 390000 Avg. Training loss: 15.2589 0.0090 sec/batch 686 total sec\n",
      "Epoch 3/3 Iteration: 395000 Avg. Training loss: 15.8782 0.0090 sec/batch 695 total sec\n",
      "Epoch 3/3 Iteration: 400000 Avg. Training loss: 16.0207 0.0088 sec/batch 704 total sec\n",
      "Nearest to 똥망/Noun: 폭소/Noun, 짱구/Noun, 예의/Noun, 어장/Noun, 자제/Noun,\n",
      "Nearest to 지하/Noun: 전쟁영화/Noun, 전파/Noun, 존내/Noun, 장소/Noun, 김혜수/Noun,\n",
      "Nearest to 구름/Noun: 작위/Noun, 김선아/Noun, 횟수/Noun, 스럽지도/Josa, 은지원/Noun,\n",
      "Nearest to 두려워하다/Verb: 도달/Noun, 설마설마/Adverb, 그러하다/Adjective, 일텐데/Josa, 짜증스럽다/Adjective,\n",
      "Nearest to 한결/Noun: 토이스토리/Noun, 멍하다/Adjective, 젊은이/Noun, 감독판/Noun, 멍청하다/Adjective,\n",
      "Nearest to 전파/Noun: 자신감/Noun, 성인영화/Noun, 어리석다/Adjective, 최민식/Noun, 에게도/Josa,\n",
      "Nearest to 삼키다/Verb: 둔갑/Noun, 채민서/Noun, 찍히다/Verb, 로드무비/Noun, 깨어나다/Verb,\n",
      "Nearest to 빠져나오다/Verb: 예의/Noun, 전국/Noun, 인사/Noun, 셀/Noun, 서양인/Noun,\n",
      "Nearest to 리더/Noun: 보고서/Noun, 후편/Noun, 세밀/Noun, 최소/Noun, 성해/Noun,\n",
      "Nearest to 일본어/Noun: 변질/Noun, 곱씹다/Verb, 진지/Noun, 조명/Noun, 여실히/Noun,\n",
      "Epoch 3/3 Iteration: 405000 Avg. Training loss: 16.1777 0.0089 sec/batch 713 total sec\n",
      "Epoch 3/3 Iteration: 410000 Avg. Training loss: 15.5545 0.0088 sec/batch 722 total sec\n",
      "Epoch 3/3 Iteration: 415000 Avg. Training loss: 15.8850 0.0089 sec/batch 731 total sec\n",
      "Epoch 3/3 Iteration: 420000 Avg. Training loss: 15.4690 0.0088 sec/batch 740 total sec\n",
      "Nearest to 똥망/Noun: 폭소/Noun, 짱구/Noun, 평등/Noun, 예의/Noun, 자제/Noun,\n",
      "Nearest to 지하/Noun: 전파/Noun, 전쟁영화/Noun, 존내/Noun, 성인영화/Noun, 장소/Noun,\n",
      "Nearest to 구름/Noun: 작위/Noun, 횟수/Noun, 김선아/Noun, 페이/Noun, 스럽지도/Josa,\n",
      "Nearest to 두려워하다/Verb: 설마설마/Adverb, 짜증스럽다/Adjective, 졸/Noun, 도달/Noun, 일텐데/Josa,\n",
      "Nearest to 한결/Noun: 토이스토리/Noun, 멍하다/Adjective, 치면/Noun, 감독판/Noun, 멍청하다/Adjective,\n",
      "Nearest to 전파/Noun: 성인영화/Noun, 작성/Noun, 자신감/Noun, 최민식/Noun, 확신/Noun,\n",
      "Nearest to 삼키다/Verb: 둔갑/Noun, 엉터리/Noun, 로드무비/Noun, 집어넣다/Verb, 채민서/Noun,\n",
      "Nearest to 빠져나오다/Verb: 하리/Noun, 주요/Noun, 제한/Noun, 스텝업/Noun, 초보/Noun,\n",
      "Nearest to 리더/Noun: 후편/Noun, 세밀/Noun, 보고서/Noun, 성해/Noun, 다인/Noun,\n",
      "Nearest to 일본어/Noun: 곱씹다/Verb, 진지/Noun, 여실히/Noun, 어설픔/Noun, 비됴/Noun,\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "## embedding size를 높일 수 록 epochs 수를 높일 수록 수행시간이 길어지므로, 컴퓨터 성능에 맞게 낮게 맞췄다.\n",
    "word2vec_review(int_word, int_to_word, work_dir, epochs=3, n_embedding=32)\n",
    "# 기존 모델과 그래프가 겹치므로 word2vec graph는 reset합니다.\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Visualize\n",
    "word2vec으로 embeddign한 word들을 3차원 시각화해 보고, word들이 적절히 embedding 되었는지 탐색하고 평가한다.\n",
    "* word2vec은 데이터가 충분해야 학습이 잘 되지만 주어진 데이터가 적기 때문에 좋은 임베딩에는 한계가 있었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/khlee/tutorial/review_pos_neg_classification/w2v_model/abuse.ckpt-last\n",
      "Run `tensorboard --logdir=/home/khlee/tutorial/review_pos_neg_classification/w2v_model/tb` to run visualize result on tensorboard\n"
     ]
    }
   ],
   "source": [
    "visualize_embedding(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loss graph\n",
    "<img src=\"img/train_loss.png\" width=\"480\" height=\"320\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding plot\n",
    "<img src=\"img/embedding_plot.png\" width=\"480\" height=\"320\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pos/Neg Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing\n",
    "label 필드(output)와 토크나이즈한 review word를 int로 변환한 필드(input)로 데이터를 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_df = data.reset_index(drop=True)\n",
    "model_df = pd.concat([model_df.loc[:,['label']], pd.Series(int_word)], axis=1)\n",
    "model_df = model_df.rename(index=str, columns={0: 'int_review'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>int_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[9456, 9007, 9535, 9507, 9335, 9414, 8783]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[8486, 9530, 9011, 9480, 8846, 9540, 9279, 948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[9521, 8772, 1, 9514, 8924, 9537, 9269, 9539]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[2604, 9404, 627, 9535, 9272, 9459, 9526, 9525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 9536, 1444, 8079, 9500, 9533, 8611, 9540, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                         int_review\n",
       "0      0         [9456, 9007, 9535, 9507, 9335, 9414, 8783]\n",
       "1      1  [8486, 9530, 9011, 9480, 8846, 9540, 9279, 948...\n",
       "2      0      [9521, 8772, 1, 9514, 8924, 9537, 9269, 9539]\n",
       "3      0  [2604, 9404, 627, 9535, 9272, 9459, 9526, 9525...\n",
       "4      1  [1, 9536, 1444, 8079, 9500, 9533, 8611, 9540, ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review의 length가 서로 다르기 때문에, 최대 길이의 review length만큼 앞단에서 0으로 채워줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9456, 9007, 9535, 9507, 9335, 9414, 8783]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0 9456 9007 9535 9507 9335 9414 8783]\n"
     ]
    }
   ],
   "source": [
    "print(model_df['int_review'][0])\n",
    "max_len = model_df['int_review'].apply(lambda x: len(x)).max()\n",
    "model_df['int_review'] = model_df['int_review'].apply(lambda x: zero_pad(x, max_len))\n",
    "print(model_df['int_review'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split trn & val & tst set\n",
    "data를 train, validation, test set으로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.array(list(range(len(model_df))))\n",
    "tst_size = round(len(model_df) * 0.2)\n",
    "val_size = round(len(model_df) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_size: 104996 val_size: 15000 tst_size: 29999\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=1050)\n",
    "tst_idx = np.random.choice(idx, size=tst_size, replace=False)\n",
    "idx1 = idx[~np.in1d(idx, tst_idx)]\n",
    "val_idx = np.random.choice(idx1, size=val_size, replace=False)\n",
    "trn_idx = idx1[~np.in1d(idx1, val_idx)]\n",
    "print('trn_size:', len(trn_idx), 'val_size:', len(val_idx), 'tst_size:', len(tst_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_model_data(df, shuffle=False):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1)\n",
    "    return (df['int_review'].values.tolist(), \n",
    "            np.expand_dims(df['label'].values, axis=1).tolist()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에 사용할 데이터를 다음과 같은 포멧으로 변경합니다. <br>\n",
    "format : (int_review , label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_data = mk_model_data(model_df.iloc[tst_idx,:])\n",
    "val_data = mk_model_data(model_df.iloc[val_idx,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model Parameters\n",
    "* epoch: max epoch으로 학습시 early stopping logic 사용\n",
    "* rnn_size: 토크나이즈된 review의 최대 길이\n",
    "* n_classes: 예측 노드 수로, label 하나를 사용하므로 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "rnn_size = max_len\n",
    "rnn_layer = 2\n",
    "n_classes = 1\n",
    "n_hidden = 8\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "drop_keep_prob = 0.8\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set placeholder\n",
    "inputs = tf.placeholder(tf.int32, [None, rnn_size], name='inputs')\n",
    "target = tf.placeholder(tf.float32, [None, n_classes], name='target')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 학습한 word2vec 모델을 로드하고 embedding matrix를 불러옵니다. <br>\n",
    "embedding vecotr의 index 0 행은 zeros를 의미함으로 값은 0으로 대체합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from w2v_model/abuse.ckpt-last\n"
     ]
    }
   ],
   "source": [
    "w2v = ImportGraph('w2v_model')\n",
    "embedding, softmax_w, softmax_b = w2v.run()\n",
    "embedding[0] = np.zeros_like(embedding[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "int로 구성된 review data를 embedding 합니다. <br>\n",
    "(?, rnn_size) 로 구성된 data가 임베딩 후 (?, rnn_size, 32)로 변경됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"inputs:0\", shape=(?, 95), dtype=int32)\n",
      "Tensor(\"embedding_lookup:0\", shape=(?, 95, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Embedding layer\n",
    "embedding = tf.Variable(embedding, name = 'embedding')\n",
    "rnn_inputs = tf.nn.embedding_lookup(embedding, inputs)\n",
    "print(inputs)\n",
    "print(rnn_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN과 linear layer를 통해 feedforward output를 계산합니다. <br>\n",
    "최종 output은 0~1 사이값으로 예측할 것이기 때문에 sigmoid를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make rnn layers\n",
    "def lstm_cell():\n",
    "    return tf.contrib.rnn.LayerNormBasicLSTMCell(n_hidden, \n",
    "                                                 layer_norm=False,\n",
    "                                                 dropout_keep_prob=keep_prob, \n",
    "                                                 reuse=tf.AUTO_REUSE)\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(rnn_layer)], state_is_tuple=True)\n",
    "initial_state = cell.zero_state(tf.shape(inputs)[0], tf.float32)\n",
    "\n",
    "# RNN outputs\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, rnn_inputs, \n",
    "                                    initial_state=initial_state, dtype=tf.float32)\n",
    "# linear outputs\n",
    "with tf.name_scope('outputs'):\n",
    "    outputs = tf.contrib.layers.fully_connected(outputs[:, -1], n_classes, activation_fn=tf.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean square error loss 와 adam optimizer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean square error loss\n",
    "with tf.name_scope('cost'):\n",
    "    cost = tf.losses.mean_squared_error(target, outputs)\n",
    "    tf.summary.scalar('cost', cost)\n",
    "# adamoptimizer\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation metric\n",
    "label 긍, 부정 데이터 비율이 비슷하므로 단순히 accuracy 지표를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75170, 74825]\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('label').size().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "with tf.name_scope('evaluation'):\n",
    "    pos_eval = tf.equal(tf.round(outputs), tf.round(target))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pos_eval, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summaries & saver\n",
    "학습과정을 시각화할 지표들을 summary하고 모델을 저장할 saver를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if file_io.is_directory( work_dir + 'model' ):\n",
    "        file_io.delete_recursively( work_dir + 'model' )\n",
    "# Merge all the summaries\n",
    "summary_mg = tf.summary.merge_all()\n",
    "trn_writer = tf.summary.FileWriter(work_dir + '/model/tb/train', graph=tf.get_default_graph())\n",
    "tst_writer = tf.summary.FileWriter(work_dir + '/model/tb/test', graph=tf.get_default_graph())\n",
    "# saver\n",
    "saver = tf.train.Saver()\n",
    "saver.export_meta_graph(work_dir + '/model/abuse.ckpt.meta')\n",
    "()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "모델을 학습하는데, 각 epoch의 validation step 마다 loss를 누적하고, epoch가 끝났을 때, 평균 loss가 이전 epoch loss보다 크다면 penalty를 주고 누적 penalty가 2점이면 학습을 조기 종료합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current val_loss: 0.252392\n",
      "Epoch: 1 Batch_iter: 0 \n",
      " Train Loss: 0.25644886 Valid Loss: 0.25115082 \n",
      " trn_acc: 0.492 val_acc: 0.504\n",
      "spend time = { row/sec: 287.0 optimize: 0.445 eval: 1.694 Elapsed: 3.583 }\n",
      "Epoch: 1 Batch_iter: 10 \n",
      " Train Loss: 0.25010484 Valid Loss: 0.24984755 \n",
      " trn_acc: 0.539 val_acc: 0.499\n",
      "spend time = { row/sec: 2436.0 optimize: 0.053 eval: 2.948 Elapsed: 12.088 }\n",
      "Epoch: 1 Batch_iter: 20 \n",
      " Train Loss: 0.24988881 Valid Loss: 0.24960558 \n",
      " trn_acc: 0.523 val_acc: 0.525\n",
      "spend time = { row/sec: 2566.0 optimize: 0.05 eval: 1.68 Elapsed: 18.97 }\n",
      "Epoch: 1 Batch_iter: 30 \n",
      " Train Loss: 0.2518602 Valid Loss: 0.2494943 \n",
      " trn_acc: 0.438 val_acc: 0.559\n",
      "spend time = { row/sec: 2703.0 optimize: 0.047 eval: 0.768 Elapsed: 27.148 }\n",
      "Epoch: 1 Batch_iter: 40 \n",
      " Train Loss: 0.24977326 Valid Loss: 0.24942265 \n",
      " trn_acc: 0.523 val_acc: 0.511\n",
      "spend time = { row/sec: 2488.0 optimize: 0.051 eval: 1.195 Elapsed: 31.002 }\n",
      "Epoch: 1 Batch_iter: 50 \n",
      " Train Loss: 0.24814078 Valid Loss: 0.24907835 \n",
      " trn_acc: 0.539 val_acc: 0.519\n",
      "spend time = { row/sec: 2224.0 optimize: 0.058 eval: 1.423 Elapsed: 35.181 }\n",
      "Epoch: 1 Batch_iter: 60 \n",
      " Train Loss: 0.25141194 Valid Loss: 0.24880399 \n",
      " trn_acc: 0.477 val_acc: 0.499\n",
      "spend time = { row/sec: 2638.0 optimize: 0.049 eval: 0.966 Elapsed: 39.54 }\n",
      "Epoch: 1 Batch_iter: 70 \n",
      " Train Loss: 0.24742718 Valid Loss: 0.24753486 \n",
      " trn_acc: 0.547 val_acc: 0.568\n",
      "spend time = { row/sec: 2349.0 optimize: 0.054 eval: 1.137 Elapsed: 43.947 }\n",
      "Epoch: 1 Batch_iter: 80 \n",
      " Train Loss: 0.24780983 Valid Loss: 0.24638128 \n",
      " trn_acc: 0.523 val_acc: 0.562\n",
      "spend time = { row/sec: 2755.0 optimize: 0.046 eval: 1.786 Elapsed: 49.333 }\n",
      "Epoch: 1 Batch_iter: 90 \n",
      " Train Loss: 0.2381838 Valid Loss: 0.24103971 \n",
      " trn_acc: 0.656 val_acc: 0.579\n",
      "spend time = { row/sec: 2691.0 optimize: 0.048 eval: 0.742 Elapsed: 53.285 }\n",
      "Epoch: 1 Batch_iter: 100 \n",
      " Train Loss: 0.22345847 Valid Loss: 0.227677 \n",
      " trn_acc: 0.75 val_acc: 0.734\n",
      "spend time = { row/sec: 2288.0 optimize: 0.056 eval: 0.926 Elapsed: 56.523 }\n",
      "Epoch: 1 Batch_iter: 110 \n",
      " Train Loss: 0.2163748 Valid Loss: 0.23214294 \n",
      " trn_acc: 0.742 val_acc: 0.624\n",
      "spend time = { row/sec: 2735.0 optimize: 0.047 eval: 1.309 Elapsed: 59.916 }\n",
      "Epoch: 1 Batch_iter: 120 \n",
      " Train Loss: 0.18447727 Valid Loss: 0.19849148 \n",
      " trn_acc: 0.812 val_acc: 0.761\n",
      "spend time = { row/sec: 2810.0 optimize: 0.046 eval: 1.92 Elapsed: 64.815 }\n",
      "Epoch: 1 Batch_iter: 130 \n",
      " Train Loss: 0.20202363 Valid Loss: 0.19177552 \n",
      " trn_acc: 0.688 val_acc: 0.762\n",
      "spend time = { row/sec: 2245.0 optimize: 0.057 eval: 0.758 Elapsed: 67.328 }\n",
      "Epoch: 1 Batch_iter: 140 \n",
      " Train Loss: 0.20613113 Valid Loss: 0.19468309 \n",
      " trn_acc: 0.688 val_acc: 0.742\n",
      "spend time = { row/sec: 2766.0 optimize: 0.046 eval: 0.843 Elapsed: 69.944 }\n",
      "Epoch: 1 Batch_iter: 150 \n",
      " Train Loss: 0.21369402 Valid Loss: 0.1810712 \n",
      " trn_acc: 0.703 val_acc: 0.768\n",
      "spend time = { row/sec: 2640.0 optimize: 0.048 eval: 0.926 Elapsed: 73.714 }\n",
      "Epoch: 1 Batch_iter: 160 \n",
      " Train Loss: 0.20139338 Valid Loss: 0.1857454 \n",
      " trn_acc: 0.711 val_acc: 0.753\n",
      "spend time = { row/sec: 2654.0 optimize: 0.048 eval: 0.999 Elapsed: 79.108 }\n",
      "Epoch: 1 Batch_iter: 170 \n",
      " Train Loss: 0.15933567 Valid Loss: 0.17314756 \n",
      " trn_acc: 0.773 val_acc: 0.752\n",
      "spend time = { row/sec: 2716.0 optimize: 0.047 eval: 0.75 Elapsed: 81.527 }\n",
      "Epoch: 1 Batch_iter: 180 \n",
      " Train Loss: 0.16948482 Valid Loss: 0.1681773 \n",
      " trn_acc: 0.758 val_acc: 0.769\n",
      "spend time = { row/sec: 2478.0 optimize: 0.052 eval: 0.801 Elapsed: 85.088 }\n",
      "Epoch: 1 Batch_iter: 190 \n",
      " Train Loss: 0.1508868 Valid Loss: 0.16202445 \n",
      " trn_acc: 0.805 val_acc: 0.792\n",
      "spend time = { row/sec: 2364.0 optimize: 0.054 eval: 0.703 Elapsed: 89.332 }\n",
      "Epoch: 1 Batch_iter: 200 \n",
      " Train Loss: 0.20262876 Valid Loss: 0.15866458 \n",
      " trn_acc: 0.734 val_acc: 0.79\n",
      "spend time = { row/sec: 2606.0 optimize: 0.049 eval: 1.433 Elapsed: 92.722 }\n",
      "Epoch: 1 Batch_iter: 210 \n",
      " Train Loss: 0.15533105 Valid Loss: 0.1561495 \n",
      " trn_acc: 0.797 val_acc: 0.795\n",
      "spend time = { row/sec: 2503.0 optimize: 0.051 eval: 1.885 Elapsed: 99.123 }\n",
      "Epoch: 1 Batch_iter: 220 \n",
      " Train Loss: 0.15581019 Valid Loss: 0.15332021 \n",
      " trn_acc: 0.797 val_acc: 0.797\n",
      "spend time = { row/sec: 2385.0 optimize: 0.054 eval: 0.642 Elapsed: 103.414 }\n",
      "Epoch: 1 Batch_iter: 230 \n",
      " Train Loss: 0.17115657 Valid Loss: 0.1504538 \n",
      " trn_acc: 0.734 val_acc: 0.802\n",
      "spend time = { row/sec: 2730.0 optimize: 0.047 eval: 0.728 Elapsed: 106.764 }\n",
      "Epoch: 1 Batch_iter: 240 \n",
      " Train Loss: 0.1811569 Valid Loss: 0.14940298 \n",
      " trn_acc: 0.703 val_acc: 0.802\n",
      "spend time = { row/sec: 2798.0 optimize: 0.046 eval: 0.543 Elapsed: 110.084 }\n",
      "Epoch: 1 Batch_iter: 250 \n",
      " Train Loss: 0.14690672 Valid Loss: 0.14880146 \n",
      " trn_acc: 0.805 val_acc: 0.804\n",
      "spend time = { row/sec: 2156.0 optimize: 0.059 eval: 1.518 Elapsed: 114.958 }\n",
      "Epoch: 1 Batch_iter: 260 \n",
      " Train Loss: 0.16739912 Valid Loss: 0.14810252 \n",
      " trn_acc: 0.742 val_acc: 0.802\n",
      "spend time = { row/sec: 2803.0 optimize: 0.046 eval: 0.707 Elapsed: 117.831 }\n",
      "Epoch: 1 Batch_iter: 270 \n",
      " Train Loss: 0.14405382 Valid Loss: 0.14420123 \n",
      " trn_acc: 0.805 val_acc: 0.806\n",
      "spend time = { row/sec: 2657.0 optimize: 0.048 eval: 1.759 Elapsed: 123.307 }\n",
      "Epoch: 1 Batch_iter: 280 \n",
      " Train Loss: 0.15086207 Valid Loss: 0.14259437 \n",
      " trn_acc: 0.789 val_acc: 0.807\n",
      "spend time = { row/sec: 2537.0 optimize: 0.05 eval: 1.81 Elapsed: 127.544 }\n",
      "Epoch: 1 Batch_iter: 290 \n",
      " Train Loss: 0.1569986 Valid Loss: 0.14603165 \n",
      " trn_acc: 0.812 val_acc: 0.799\n",
      "spend time = { row/sec: 2741.0 optimize: 0.047 eval: 0.609 Elapsed: 130.393 }\n",
      "Epoch: 1 Batch_iter: 300 \n",
      " Train Loss: 0.13777436 Valid Loss: 0.14835201 \n",
      " trn_acc: 0.797 val_acc: 0.796\n",
      "spend time = { row/sec: 2210.0 optimize: 0.058 eval: 0.861 Elapsed: 134.631 }\n",
      "Epoch: 1 Batch_iter: 310 \n",
      " Train Loss: 0.14386323 Valid Loss: 0.14072041 \n",
      " trn_acc: 0.805 val_acc: 0.809\n",
      "spend time = { row/sec: 2452.0 optimize: 0.052 eval: 0.549 Elapsed: 137.044 }\n",
      "Epoch: 1 Batch_iter: 320 \n",
      " Train Loss: 0.13523151 Valid Loss: 0.14853401 \n",
      " trn_acc: 0.82 val_acc: 0.794\n",
      "spend time = { row/sec: 2594.0 optimize: 0.049 eval: 0.69 Elapsed: 139.732 }\n",
      "Epoch: 1 Batch_iter: 330 \n",
      " Train Loss: 0.12381205 Valid Loss: 0.13961582 \n",
      " trn_acc: 0.836 val_acc: 0.811\n",
      "spend time = { row/sec: 2670.0 optimize: 0.048 eval: 0.608 Elapsed: 143.388 }\n",
      "Epoch: 1 Batch_iter: 340 \n",
      " Train Loss: 0.14842229 Valid Loss: 0.13697787 \n",
      " trn_acc: 0.797 val_acc: 0.815\n",
      "spend time = { row/sec: 2661.0 optimize: 0.048 eval: 0.688 Elapsed: 145.888 }\n",
      "Epoch: 1 Batch_iter: 350 \n",
      " Train Loss: 0.13735378 Valid Loss: 0.13920324 \n",
      " trn_acc: 0.828 val_acc: 0.81\n",
      "spend time = { row/sec: 2647.0 optimize: 0.048 eval: 0.74 Elapsed: 148.34 }\n",
      "Epoch: 1 Batch_iter: 360 \n",
      " Train Loss: 0.120882355 Valid Loss: 0.14399394 \n",
      " trn_acc: 0.836 val_acc: 0.799\n",
      "spend time = { row/sec: 2654.0 optimize: 0.048 eval: 0.812 Elapsed: 151.694 }\n",
      "Epoch: 1 Batch_iter: 370 \n",
      " Train Loss: 0.16372572 Valid Loss: 0.14292015 \n",
      " trn_acc: 0.781 val_acc: 0.802\n",
      "spend time = { row/sec: 2343.0 optimize: 0.055 eval: 0.768 Elapsed: 154.252 }\n",
      "Epoch: 1 Batch_iter: 380 \n",
      " Train Loss: 0.16636908 Valid Loss: 0.1373638 \n",
      " trn_acc: 0.734 val_acc: 0.813\n",
      "spend time = { row/sec: 2537.0 optimize: 0.05 eval: 1.43 Elapsed: 158.443 }\n",
      "Epoch: 1 Batch_iter: 390 \n",
      " Train Loss: 0.16766159 Valid Loss: 0.13287279 \n",
      " trn_acc: 0.75 val_acc: 0.821\n",
      "spend time = { row/sec: 2731.0 optimize: 0.047 eval: 0.575 Elapsed: 161.421 }\n",
      "Epoch: 1 Batch_iter: 400 \n",
      " Train Loss: 0.14226133 Valid Loss: 0.13398546 \n",
      " trn_acc: 0.797 val_acc: 0.817\n",
      "spend time = { row/sec: 2391.0 optimize: 0.054 eval: 0.526 Elapsed: 163.612 }\n",
      "Epoch: 1 Batch_iter: 410 \n",
      " Train Loss: 0.14693081 Valid Loss: 0.13110277 \n",
      " trn_acc: 0.789 val_acc: 0.821\n",
      "spend time = { row/sec: 2752.0 optimize: 0.046 eval: 0.729 Elapsed: 166.142 }\n",
      "Epoch: 1 Batch_iter: 420 \n",
      " Train Loss: 0.11801822 Valid Loss: 0.1340808 \n",
      " trn_acc: 0.852 val_acc: 0.817\n",
      "spend time = { row/sec: 2848.0 optimize: 0.045 eval: 0.595 Elapsed: 168.891 }\n",
      "Epoch: 1 Batch_iter: 430 \n",
      " Train Loss: 0.13192299 Valid Loss: 0.128742 \n",
      " trn_acc: 0.797 val_acc: 0.824\n",
      "spend time = { row/sec: 2687.0 optimize: 0.048 eval: 0.551 Elapsed: 171.359 }\n",
      "Epoch: 1 Batch_iter: 440 \n",
      " Train Loss: 0.113852784 Valid Loss: 0.12910981 \n",
      " trn_acc: 0.844 val_acc: 0.822\n",
      "spend time = { row/sec: 2731.0 optimize: 0.047 eval: 0.889 Elapsed: 173.908 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch_iter: 450 \n",
      " Train Loss: 0.1237121 Valid Loss: 0.1279443 \n",
      " trn_acc: 0.891 val_acc: 0.826\n",
      "spend time = { row/sec: 2552.0 optimize: 0.05 eval: 0.733 Elapsed: 178.118 }\n",
      "Epoch: 1 Batch_iter: 460 \n",
      " Train Loss: 0.15374365 Valid Loss: 0.12957256 \n",
      " trn_acc: 0.773 val_acc: 0.823\n",
      "spend time = { row/sec: 2310.0 optimize: 0.055 eval: 0.553 Elapsed: 180.315 }\n",
      "Epoch: 1 Batch_iter: 470 \n",
      " Train Loss: 0.12711717 Valid Loss: 0.12778895 \n",
      " trn_acc: 0.828 val_acc: 0.824\n",
      "spend time = { row/sec: 2556.0 optimize: 0.05 eval: 0.53 Elapsed: 182.612 }\n",
      "Epoch: 1 Batch_iter: 480 \n",
      " Train Loss: 0.11788119 Valid Loss: 0.12640192 \n",
      " trn_acc: 0.852 val_acc: 0.826\n",
      "spend time = { row/sec: 2082.0 optimize: 0.061 eval: 0.548 Elapsed: 185.902 }\n",
      "Epoch: 1 Batch_iter: 490 \n",
      " Train Loss: 0.11825576 Valid Loss: 0.12650897 \n",
      " trn_acc: 0.805 val_acc: 0.826\n",
      "spend time = { row/sec: 2625.0 optimize: 0.049 eval: 0.648 Elapsed: 188.211 }\n",
      "Epoch: 1 Batch_iter: 500 \n",
      " Train Loss: 0.1263632 Valid Loss: 0.13468084 \n",
      " trn_acc: 0.836 val_acc: 0.813\n",
      "spend time = { row/sec: 2588.0 optimize: 0.049 eval: 0.987 Elapsed: 190.812 }\n",
      "Epoch: 1 Batch_iter: 510 \n",
      " Train Loss: 0.12940803 Valid Loss: 0.13590188 \n",
      " trn_acc: 0.828 val_acc: 0.812\n",
      "spend time = { row/sec: 2726.0 optimize: 0.047 eval: 0.621 Elapsed: 193.661 }\n",
      "Epoch: 1 Batch_iter: 520 \n",
      " Train Loss: 0.12926275 Valid Loss: 0.12732427 \n",
      " trn_acc: 0.844 val_acc: 0.824\n",
      "spend time = { row/sec: 2590.0 optimize: 0.049 eval: 1.081 Elapsed: 196.71 }\n",
      "Epoch: 1 Batch_iter: 530 \n",
      " Train Loss: 0.14473218 Valid Loss: 0.12558776 \n",
      " trn_acc: 0.805 val_acc: 0.828\n",
      "spend time = { row/sec: 2456.0 optimize: 0.052 eval: 0.674 Elapsed: 199.157 }\n",
      "Epoch: 1 Batch_iter: 540 \n",
      " Train Loss: 0.15734337 Valid Loss: 0.12757294 \n",
      " trn_acc: 0.742 val_acc: 0.822\n",
      "spend time = { row/sec: 2658.0 optimize: 0.048 eval: 0.666 Elapsed: 202.12 }\n",
      "Epoch: 1 Batch_iter: 550 \n",
      " Train Loss: 0.14897896 Valid Loss: 0.12321139 \n",
      " trn_acc: 0.773 val_acc: 0.831\n",
      "spend time = { row/sec: 2467.0 optimize: 0.052 eval: 0.661 Elapsed: 205.084 }\n",
      "Epoch: 1 Batch_iter: 560 \n",
      " Train Loss: 0.15752688 Valid Loss: 0.12512271 \n",
      " trn_acc: 0.789 val_acc: 0.828\n",
      "spend time = { row/sec: 2737.0 optimize: 0.047 eval: 0.674 Elapsed: 207.404 }\n",
      "Epoch: 1 Batch_iter: 570 \n",
      " Train Loss: 0.15009347 Valid Loss: 0.13819878 \n",
      " trn_acc: 0.805 val_acc: 0.809\n",
      "spend time = { row/sec: 2680.0 optimize: 0.048 eval: 0.582 Elapsed: 210.463 }\n",
      "Epoch: 1 Batch_iter: 580 \n",
      " Train Loss: 0.12370248 Valid Loss: 0.1214996 \n",
      " trn_acc: 0.844 val_acc: 0.833\n",
      "spend time = { row/sec: 2169.0 optimize: 0.059 eval: 0.788 Elapsed: 213.013 }\n",
      "Epoch: 1 Batch_iter: 590 \n",
      " Train Loss: 0.11872396 Valid Loss: 0.12111942 \n",
      " trn_acc: 0.836 val_acc: 0.837\n",
      "spend time = { row/sec: 2735.0 optimize: 0.047 eval: 0.72 Elapsed: 215.755 }\n",
      "Epoch: 1 Batch_iter: 600 \n",
      " Train Loss: 0.1342529 Valid Loss: 0.12389047 \n",
      " trn_acc: 0.812 val_acc: 0.831\n",
      "spend time = { row/sec: 2672.0 optimize: 0.048 eval: 0.975 Elapsed: 219.956 }\n",
      "Epoch: 1 Batch_iter: 610 \n",
      " Train Loss: 0.14080968 Valid Loss: 0.122307606 \n",
      " trn_acc: 0.773 val_acc: 0.832\n",
      "spend time = { row/sec: 2182.0 optimize: 0.059 eval: 1.085 Elapsed: 222.848 }\n",
      "Epoch: 1 Batch_iter: 620 \n",
      " Train Loss: 0.13727897 Valid Loss: 0.12254914 \n",
      " trn_acc: 0.797 val_acc: 0.83\n",
      "spend time = { row/sec: 2734.0 optimize: 0.047 eval: 1.693 Elapsed: 226.357 }\n",
      "Epoch: 1 Batch_iter: 630 \n",
      " Train Loss: 0.11611617 Valid Loss: 0.12099693 \n",
      " trn_acc: 0.828 val_acc: 0.833\n",
      "spend time = { row/sec: 2713.0 optimize: 0.047 eval: 0.558 Elapsed: 229.256 }\n",
      "Epoch: 1 Batch_iter: 640 \n",
      " Train Loss: 0.1398198 Valid Loss: 0.12669565 \n",
      " trn_acc: 0.82 val_acc: 0.822\n",
      "spend time = { row/sec: 2522.0 optimize: 0.051 eval: 1.212 Elapsed: 232.063 }\n",
      "Epoch: 1 Batch_iter: 650 \n",
      " Train Loss: 0.1368163 Valid Loss: 0.122007065 \n",
      " trn_acc: 0.805 val_acc: 0.833\n",
      "spend time = { row/sec: 2755.0 optimize: 0.046 eval: 0.736 Elapsed: 234.761 }\n",
      "Epoch: 1 Batch_iter: 660 \n",
      " Train Loss: 0.13658735 Valid Loss: 0.13326544 \n",
      " trn_acc: 0.812 val_acc: 0.814\n",
      "spend time = { row/sec: 2634.0 optimize: 0.049 eval: 0.548 Elapsed: 237.769 }\n",
      "Epoch: 1 Batch_iter: 670 \n",
      " Train Loss: 0.1191243 Valid Loss: 0.11910078 \n",
      " trn_acc: 0.836 val_acc: 0.839\n",
      "spend time = { row/sec: 2597.0 optimize: 0.049 eval: 0.616 Elapsed: 240.154 }\n",
      "Epoch: 1 Batch_iter: 680 \n",
      " Train Loss: 0.14833245 Valid Loss: 0.11825934 \n",
      " trn_acc: 0.812 val_acc: 0.838\n",
      "spend time = { row/sec: 2691.0 optimize: 0.048 eval: 0.652 Elapsed: 242.732 }\n",
      "Epoch: 1 Batch_iter: 690 \n",
      " Train Loss: 0.12767273 Valid Loss: 0.119709 \n",
      " trn_acc: 0.828 val_acc: 0.835\n",
      "spend time = { row/sec: 2689.0 optimize: 0.048 eval: 0.525 Elapsed: 247.449 }\n",
      "Epoch: 1 Batch_iter: 700 \n",
      " Train Loss: 0.11906475 Valid Loss: 0.11837409 \n",
      " trn_acc: 0.844 val_acc: 0.838\n",
      "spend time = { row/sec: 2406.0 optimize: 0.053 eval: 1.023 Elapsed: 250.203 }\n",
      "Epoch: 1 Batch_iter: 710 \n",
      " Train Loss: 0.120143965 Valid Loss: 0.124624476 \n",
      " trn_acc: 0.82 val_acc: 0.824\n",
      "spend time = { row/sec: 2696.0 optimize: 0.047 eval: 0.6 Elapsed: 252.389 }\n",
      "Epoch: 1 Batch_iter: 720 \n",
      " Train Loss: 0.14615375 Valid Loss: 0.11879159 \n",
      " trn_acc: 0.781 val_acc: 0.836\n",
      "spend time = { row/sec: 2699.0 optimize: 0.047 eval: 0.677 Elapsed: 255.192 }\n",
      "Epoch: 1 Batch_iter: 730 \n",
      " Train Loss: 0.12093757 Valid Loss: 0.11799826 \n",
      " trn_acc: 0.844 val_acc: 0.838\n",
      "spend time = { row/sec: 2425.0 optimize: 0.053 eval: 0.568 Elapsed: 257.811 }\n",
      "Epoch: 1 Batch_iter: 740 \n",
      " Train Loss: 0.12349507 Valid Loss: 0.11738693 \n",
      " trn_acc: 0.852 val_acc: 0.839\n",
      "spend time = { row/sec: 2486.0 optimize: 0.051 eval: 0.566 Elapsed: 260.712 }\n",
      "Epoch: 1 Batch_iter: 750 \n",
      " Train Loss: 0.1474202 Valid Loss: 0.12020951 \n",
      " trn_acc: 0.797 val_acc: 0.836\n",
      "spend time = { row/sec: 2391.0 optimize: 0.054 eval: 0.589 Elapsed: 263.418 }\n",
      "Epoch: 1 Batch_iter: 760 \n",
      " Train Loss: 0.13157594 Valid Loss: 0.1213682 \n",
      " trn_acc: 0.82 val_acc: 0.831\n",
      "spend time = { row/sec: 2328.0 optimize: 0.055 eval: 0.549 Elapsed: 265.756 }\n",
      "Epoch: 1 Batch_iter: 770 \n",
      " Train Loss: 0.12928599 Valid Loss: 0.11855566 \n",
      " trn_acc: 0.82 val_acc: 0.835\n",
      "spend time = { row/sec: 2507.0 optimize: 0.051 eval: 0.602 Elapsed: 268.061 }\n",
      "Epoch: 1 Batch_iter: 780 \n",
      " Train Loss: 0.16400038 Valid Loss: 0.11937373 \n",
      " trn_acc: 0.758 val_acc: 0.833\n",
      "spend time = { row/sec: 2765.0 optimize: 0.046 eval: 0.535 Elapsed: 270.963 }\n",
      "Epoch: 1 Batch_iter: 790 \n",
      " Train Loss: 0.1320135 Valid Loss: 0.12135773 \n",
      " trn_acc: 0.797 val_acc: 0.831\n",
      "spend time = { row/sec: 2260.0 optimize: 0.057 eval: 1.366 Elapsed: 274.031 }\n",
      "Epoch: 1 Batch_iter: 800 \n",
      " Train Loss: 0.099995315 Valid Loss: 0.116115905 \n",
      " trn_acc: 0.875 val_acc: 0.84\n",
      "spend time = { row/sec: 2556.0 optimize: 0.05 eval: 0.549 Elapsed: 276.294 }\n",
      "Epoch: 1 Batch_iter: 810 \n",
      " Train Loss: 0.12511753 Valid Loss: 0.12402832 \n",
      " trn_acc: 0.859 val_acc: 0.826\n",
      "spend time = { row/sec: 2747.0 optimize: 0.047 eval: 0.532 Elapsed: 279.164 }\n",
      "\n",
      " Save the model : current loss  0.15299555982877738 <= 0.252392 prev loss \n",
      "\n",
      "Epoch: 2 Batch_iter: 0 \n",
      " Train Loss: 0.11291632 Valid Loss: 0.116659425 \n",
      " trn_acc: 0.859 val_acc: 0.839\n",
      "spend time = { row/sec: 2519.0 optimize: 0.051 eval: 0.653 Elapsed: 282.998 }\n",
      "Epoch: 2 Batch_iter: 10 \n",
      " Train Loss: 0.11750255 Valid Loss: 0.11702528 \n",
      " trn_acc: 0.828 val_acc: 0.838\n",
      "spend time = { row/sec: 2400.0 optimize: 0.053 eval: 0.943 Elapsed: 285.542 }\n",
      "Epoch: 2 Batch_iter: 20 \n",
      " Train Loss: 0.11151007 Valid Loss: 0.11656655 \n",
      " trn_acc: 0.859 val_acc: 0.841\n",
      "spend time = { row/sec: 2372.0 optimize: 0.054 eval: 0.61 Elapsed: 287.915 }\n",
      "Epoch: 2 Batch_iter: 30 \n",
      " Train Loss: 0.09842144 Valid Loss: 0.116720505 \n",
      " trn_acc: 0.898 val_acc: 0.838\n",
      "spend time = { row/sec: 2761.0 optimize: 0.046 eval: 0.793 Elapsed: 290.835 }\n",
      "Epoch: 2 Batch_iter: 40 \n",
      " Train Loss: 0.1019091 Valid Loss: 0.11603892 \n",
      " trn_acc: 0.852 val_acc: 0.84\n",
      "spend time = { row/sec: 2322.0 optimize: 0.055 eval: 0.537 Elapsed: 294.042 }\n",
      "Epoch: 2 Batch_iter: 50 \n",
      " Train Loss: 0.12549254 Valid Loss: 0.117490046 \n",
      " trn_acc: 0.82 val_acc: 0.837\n",
      "spend time = { row/sec: 2576.0 optimize: 0.05 eval: 0.567 Elapsed: 296.278 }\n",
      "Epoch: 2 Batch_iter: 60 \n",
      " Train Loss: 0.13412586 Valid Loss: 0.11636114 \n",
      " trn_acc: 0.805 val_acc: 0.838\n",
      "spend time = { row/sec: 2764.0 optimize: 0.046 eval: 0.551 Elapsed: 299.997 }\n",
      "Epoch: 2 Batch_iter: 70 \n",
      " Train Loss: 0.0991053 Valid Loss: 0.11551602 \n",
      " trn_acc: 0.852 val_acc: 0.839\n",
      "spend time = { row/sec: 2351.0 optimize: 0.054 eval: 0.497 Elapsed: 302.57 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch_iter: 80 \n",
      " Train Loss: 0.123590484 Valid Loss: 0.12241151 \n",
      " trn_acc: 0.828 val_acc: 0.829\n",
      "spend time = { row/sec: 2648.0 optimize: 0.048 eval: 0.592 Elapsed: 304.884 }\n",
      "Epoch: 2 Batch_iter: 90 \n",
      " Train Loss: 0.11948401 Valid Loss: 0.11827834 \n",
      " trn_acc: 0.844 val_acc: 0.834\n",
      "spend time = { row/sec: 2757.0 optimize: 0.046 eval: 0.579 Elapsed: 308.795 }\n",
      "Epoch: 2 Batch_iter: 100 \n",
      " Train Loss: 0.12515639 Valid Loss: 0.1193208 \n",
      " trn_acc: 0.828 val_acc: 0.832\n",
      "spend time = { row/sec: 2194.0 optimize: 0.058 eval: 0.591 Elapsed: 311.012 }\n",
      "Epoch: 2 Batch_iter: 110 \n",
      " Train Loss: 0.14182281 Valid Loss: 0.117350444 \n",
      " trn_acc: 0.812 val_acc: 0.836\n",
      "spend time = { row/sec: 2734.0 optimize: 0.047 eval: 0.541 Elapsed: 313.282 }\n",
      "Epoch: 2 Batch_iter: 120 \n",
      " Train Loss: 0.117130056 Valid Loss: 0.12007254 \n",
      " trn_acc: 0.836 val_acc: 0.834\n",
      "spend time = { row/sec: 2691.0 optimize: 0.048 eval: 0.544 Elapsed: 316.111 }\n",
      "Epoch: 2 Batch_iter: 130 \n",
      " Train Loss: 0.11870572 Valid Loss: 0.116863266 \n",
      " trn_acc: 0.836 val_acc: 0.837\n",
      "spend time = { row/sec: 2269.0 optimize: 0.056 eval: 0.798 Elapsed: 318.547 }\n",
      "Epoch: 2 Batch_iter: 140 \n",
      " Train Loss: 0.1320731 Valid Loss: 0.115249105 \n",
      " trn_acc: 0.812 val_acc: 0.838\n",
      "spend time = { row/sec: 2703.0 optimize: 0.047 eval: 0.588 Elapsed: 320.961 }\n",
      "Epoch: 2 Batch_iter: 150 \n",
      " Train Loss: 0.102714986 Valid Loss: 0.118779555 \n",
      " trn_acc: 0.875 val_acc: 0.833\n",
      "spend time = { row/sec: 2695.0 optimize: 0.047 eval: 0.784 Elapsed: 324.162 }\n",
      "Epoch: 2 Batch_iter: 160 \n",
      " Train Loss: 0.113794714 Valid Loss: 0.1245068 \n",
      " trn_acc: 0.859 val_acc: 0.829\n",
      "spend time = { row/sec: 2664.0 optimize: 0.048 eval: 0.624 Elapsed: 327.123 }\n",
      "Epoch: 2 Batch_iter: 170 \n",
      " Train Loss: 0.0921749 Valid Loss: 0.11499933 \n",
      " trn_acc: 0.891 val_acc: 0.839\n",
      "spend time = { row/sec: 2667.0 optimize: 0.048 eval: 0.586 Elapsed: 329.369 }\n",
      "Epoch: 2 Batch_iter: 180 \n",
      " Train Loss: 0.12385053 Valid Loss: 0.115059264 \n",
      " trn_acc: 0.828 val_acc: 0.839\n",
      "spend time = { row/sec: 2508.0 optimize: 0.051 eval: 0.553 Elapsed: 332.219 }\n",
      "Epoch: 2 Batch_iter: 190 \n",
      " Train Loss: 0.12961116 Valid Loss: 0.11578766 \n",
      " trn_acc: 0.805 val_acc: 0.836\n",
      "spend time = { row/sec: 2401.0 optimize: 0.053 eval: 0.652 Elapsed: 334.596 }\n",
      "Epoch: 2 Batch_iter: 200 \n",
      " Train Loss: 0.12508005 Valid Loss: 0.13282302 \n",
      " trn_acc: 0.836 val_acc: 0.814\n",
      "spend time = { row/sec: 2699.0 optimize: 0.047 eval: 0.586 Elapsed: 336.856 }\n",
      "Epoch: 2 Batch_iter: 210 \n",
      " Train Loss: 0.10078756 Valid Loss: 0.119928904 \n",
      " trn_acc: 0.867 val_acc: 0.832\n",
      "spend time = { row/sec: 2733.0 optimize: 0.047 eval: 0.72 Elapsed: 340.71 }\n",
      "Epoch: 2 Batch_iter: 220 \n",
      " Train Loss: 0.083892226 Valid Loss: 0.12005009 \n",
      " trn_acc: 0.898 val_acc: 0.831\n",
      "spend time = { row/sec: 2410.0 optimize: 0.053 eval: 0.639 Elapsed: 342.957 }\n",
      "Epoch: 2 Batch_iter: 230 \n",
      " Train Loss: 0.10197844 Valid Loss: 0.11461932 \n",
      " trn_acc: 0.867 val_acc: 0.84\n",
      "spend time = { row/sec: 2688.0 optimize: 0.048 eval: 0.539 Elapsed: 345.276 }\n",
      "Epoch: 2 Batch_iter: 240 \n",
      " Train Loss: 0.11357001 Valid Loss: 0.11427272 \n",
      " trn_acc: 0.844 val_acc: 0.84\n",
      "spend time = { row/sec: 2683.0 optimize: 0.048 eval: 0.552 Elapsed: 348.09 }\n",
      "Epoch: 2 Batch_iter: 250 \n",
      " Train Loss: 0.116002604 Valid Loss: 0.11739061 \n",
      " trn_acc: 0.828 val_acc: 0.835\n",
      "spend time = { row/sec: 2499.0 optimize: 0.051 eval: 0.506 Elapsed: 350.22 }\n",
      "Epoch: 2 Batch_iter: 260 \n",
      " Train Loss: 0.08887845 Valid Loss: 0.115975864 \n",
      " trn_acc: 0.891 val_acc: 0.84\n",
      "spend time = { row/sec: 2657.0 optimize: 0.048 eval: 0.537 Elapsed: 352.379 }\n",
      "Epoch: 2 Batch_iter: 270 \n",
      " Train Loss: 0.13926409 Valid Loss: 0.11736543 \n",
      " trn_acc: 0.797 val_acc: 0.834\n",
      "spend time = { row/sec: 2771.0 optimize: 0.046 eval: 0.549 Elapsed: 355.087 }\n",
      "Epoch: 2 Batch_iter: 280 \n",
      " Train Loss: 0.121720515 Valid Loss: 0.1321175 \n",
      " trn_acc: 0.82 val_acc: 0.811\n",
      "spend time = { row/sec: 2456.0 optimize: 0.052 eval: 0.561 Elapsed: 357.651 }\n",
      "Epoch: 2 Batch_iter: 290 \n",
      " Train Loss: 0.10338807 Valid Loss: 0.13558641 \n",
      " trn_acc: 0.875 val_acc: 0.812\n",
      "spend time = { row/sec: 2579.0 optimize: 0.05 eval: 1.77 Elapsed: 361.101 }\n",
      "Epoch: 2 Batch_iter: 300 \n",
      " Train Loss: 0.13131264 Valid Loss: 0.11791351 \n",
      " trn_acc: 0.836 val_acc: 0.835\n",
      "spend time = { row/sec: 2669.0 optimize: 0.048 eval: 0.574 Elapsed: 363.958 }\n",
      "Epoch: 2 Batch_iter: 310 \n",
      " Train Loss: 0.0935583 Valid Loss: 0.113865755 \n",
      " trn_acc: 0.891 val_acc: 0.842\n",
      "spend time = { row/sec: 2478.0 optimize: 0.052 eval: 0.567 Elapsed: 367.249 }\n",
      "Epoch: 2 Batch_iter: 320 \n",
      " Train Loss: 0.095445015 Valid Loss: 0.11593625 \n",
      " trn_acc: 0.852 val_acc: 0.84\n",
      "spend time = { row/sec: 2711.0 optimize: 0.047 eval: 0.591 Elapsed: 369.447 }\n",
      "Epoch: 2 Batch_iter: 330 \n",
      " Train Loss: 0.115552254 Valid Loss: 0.11763573 \n",
      " trn_acc: 0.852 val_acc: 0.835\n",
      "spend time = { row/sec: 2463.0 optimize: 0.052 eval: 0.588 Elapsed: 372.316 }\n",
      "Epoch: 2 Batch_iter: 340 \n",
      " Train Loss: 0.109053195 Valid Loss: 0.11588809 \n",
      " trn_acc: 0.844 val_acc: 0.837\n",
      "spend time = { row/sec: 2179.0 optimize: 0.059 eval: 0.614 Elapsed: 375.544 }\n",
      "Epoch: 2 Batch_iter: 350 \n",
      " Train Loss: 0.11797644 Valid Loss: 0.11440689 \n",
      " trn_acc: 0.844 val_acc: 0.842\n",
      "spend time = { row/sec: 2578.0 optimize: 0.05 eval: 0.613 Elapsed: 377.805 }\n",
      "Epoch: 2 Batch_iter: 360 \n",
      " Train Loss: 0.1169457 Valid Loss: 0.11690399 \n",
      " trn_acc: 0.867 val_acc: 0.839\n",
      "spend time = { row/sec: 2670.0 optimize: 0.048 eval: 0.56 Elapsed: 380.946 }\n",
      "Epoch: 2 Batch_iter: 370 \n",
      " Train Loss: 0.1252872 Valid Loss: 0.13949265 \n",
      " trn_acc: 0.812 val_acc: 0.808\n",
      "spend time = { row/sec: 2490.0 optimize: 0.051 eval: 0.569 Elapsed: 383.084 }\n",
      "Epoch: 2 Batch_iter: 380 \n",
      " Train Loss: 0.096230865 Valid Loss: 0.114596225 \n",
      " trn_acc: 0.875 val_acc: 0.838\n",
      "spend time = { row/sec: 2685.0 optimize: 0.048 eval: 0.562 Elapsed: 386.321 }\n",
      "Epoch: 2 Batch_iter: 390 \n",
      " Train Loss: 0.085881114 Valid Loss: 0.114989296 \n",
      " trn_acc: 0.875 val_acc: 0.841\n",
      "spend time = { row/sec: 2823.0 optimize: 0.045 eval: 0.559 Elapsed: 391.145 }\n",
      "Epoch: 2 Batch_iter: 400 \n",
      " Train Loss: 0.13423288 Valid Loss: 0.11460832 \n",
      " trn_acc: 0.805 val_acc: 0.841\n",
      "spend time = { row/sec: 2406.0 optimize: 0.053 eval: 0.564 Elapsed: 393.438 }\n",
      "Epoch: 2 Batch_iter: 410 \n",
      " Train Loss: 0.17871852 Valid Loss: 0.12258936 \n",
      " trn_acc: 0.742 val_acc: 0.832\n",
      "spend time = { row/sec: 2573.0 optimize: 0.05 eval: 0.548 Elapsed: 395.733 }\n",
      "Epoch: 2 Batch_iter: 420 \n",
      " Train Loss: 0.12873659 Valid Loss: 0.13321058 \n",
      " trn_acc: 0.82 val_acc: 0.812\n",
      "spend time = { row/sec: 2745.0 optimize: 0.047 eval: 0.566 Elapsed: 399.116 }\n",
      "Epoch: 2 Batch_iter: 430 \n",
      " Train Loss: 0.13347283 Valid Loss: 0.12497576 \n",
      " trn_acc: 0.805 val_acc: 0.824\n",
      "spend time = { row/sec: 2712.0 optimize: 0.047 eval: 0.568 Elapsed: 401.309 }\n",
      "Epoch: 2 Batch_iter: 440 \n",
      " Train Loss: 0.11295626 Valid Loss: 0.12609075 \n",
      " trn_acc: 0.844 val_acc: 0.822\n",
      "spend time = { row/sec: 2623.0 optimize: 0.049 eval: 0.635 Elapsed: 403.697 }\n",
      "Epoch: 2 Batch_iter: 450 \n",
      " Train Loss: 0.11176848 Valid Loss: 0.11323806 \n",
      " trn_acc: 0.844 val_acc: 0.842\n",
      "spend time = { row/sec: 2321.0 optimize: 0.055 eval: 0.551 Elapsed: 406.38 }\n",
      "Epoch: 2 Batch_iter: 460 \n",
      " Train Loss: 0.121633045 Valid Loss: 0.11583358 \n",
      " trn_acc: 0.836 val_acc: 0.838\n",
      "spend time = { row/sec: 2431.0 optimize: 0.053 eval: 0.55 Elapsed: 408.531 }\n",
      "Epoch: 2 Batch_iter: 470 \n",
      " Train Loss: 0.09940845 Valid Loss: 0.11456792 \n",
      " trn_acc: 0.891 val_acc: 0.839\n",
      "spend time = { row/sec: 2781.0 optimize: 0.046 eval: 0.549 Elapsed: 410.675 }\n",
      "Epoch: 2 Batch_iter: 480 \n",
      " Train Loss: 0.1190156 Valid Loss: 0.1202648 \n",
      " trn_acc: 0.859 val_acc: 0.833\n",
      "spend time = { row/sec: 2372.0 optimize: 0.054 eval: 0.602 Elapsed: 413.403 }\n",
      "Epoch: 2 Batch_iter: 490 \n",
      " Train Loss: 0.13400626 Valid Loss: 0.11319346 \n",
      " trn_acc: 0.797 val_acc: 0.843\n",
      "spend time = { row/sec: 2465.0 optimize: 0.052 eval: 0.579 Elapsed: 415.696 }\n",
      "Epoch: 2 Batch_iter: 500 \n",
      " Train Loss: 0.15100119 Valid Loss: 0.11243216 \n",
      " trn_acc: 0.781 val_acc: 0.844\n",
      "spend time = { row/sec: 2726.0 optimize: 0.047 eval: 0.57 Elapsed: 417.879 }\n",
      "Epoch: 2 Batch_iter: 510 \n",
      " Train Loss: 0.11708058 Valid Loss: 0.11644894 \n",
      " trn_acc: 0.867 val_acc: 0.836\n",
      "spend time = { row/sec: 2284.0 optimize: 0.056 eval: 0.632 Elapsed: 420.918 }\n",
      "Epoch: 2 Batch_iter: 520 \n",
      " Train Loss: 0.11765701 Valid Loss: 0.11280036 \n",
      " trn_acc: 0.805 val_acc: 0.843\n",
      "spend time = { row/sec: 2747.0 optimize: 0.047 eval: 0.514 Elapsed: 423.089 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch_iter: 530 \n",
      " Train Loss: 0.10009559 Valid Loss: 0.11256022 \n",
      " trn_acc: 0.883 val_acc: 0.844\n",
      "spend time = { row/sec: 2664.0 optimize: 0.048 eval: 0.594 Elapsed: 425.279 }\n",
      "Epoch: 2 Batch_iter: 540 \n",
      " Train Loss: 0.12214409 Valid Loss: 0.114951186 \n",
      " trn_acc: 0.844 val_acc: 0.842\n",
      "spend time = { row/sec: 2738.0 optimize: 0.047 eval: 0.6 Elapsed: 428.146 }\n",
      "Epoch: 2 Batch_iter: 550 \n",
      " Train Loss: 0.100346036 Valid Loss: 0.11215104 \n",
      " trn_acc: 0.867 val_acc: 0.845\n",
      "spend time = { row/sec: 2448.0 optimize: 0.052 eval: 0.573 Elapsed: 430.419 }\n",
      "Epoch: 2 Batch_iter: 560 \n",
      " Train Loss: 0.123110905 Valid Loss: 0.11508161 \n",
      " trn_acc: 0.828 val_acc: 0.839\n",
      "spend time = { row/sec: 2709.0 optimize: 0.047 eval: 0.611 Elapsed: 432.626 }\n",
      "Epoch: 2 Batch_iter: 570 \n",
      " Train Loss: 0.12251048 Valid Loss: 0.11559145 \n",
      " trn_acc: 0.836 val_acc: 0.839\n",
      "spend time = { row/sec: 2707.0 optimize: 0.047 eval: 0.54 Elapsed: 436.076 }\n",
      "Epoch: 2 Batch_iter: 580 \n",
      " Train Loss: 0.08928628 Valid Loss: 0.11269289 \n",
      " trn_acc: 0.875 val_acc: 0.845\n",
      "spend time = { row/sec: 2312.0 optimize: 0.055 eval: 0.542 Elapsed: 438.19 }\n",
      "Epoch: 2 Batch_iter: 590 \n",
      " Train Loss: 0.108207054 Valid Loss: 0.12811038 \n",
      " trn_acc: 0.844 val_acc: 0.825\n",
      "spend time = { row/sec: 2734.0 optimize: 0.047 eval: 0.582 Elapsed: 440.372 }\n",
      "Epoch: 2 Batch_iter: 600 \n",
      " Train Loss: 0.14049304 Valid Loss: 0.12448964 \n",
      " trn_acc: 0.82 val_acc: 0.83\n",
      "spend time = { row/sec: 2707.0 optimize: 0.047 eval: 0.723 Elapsed: 444.221 }\n",
      "Epoch: 2 Batch_iter: 610 \n",
      " Train Loss: 0.117021024 Valid Loss: 0.12613702 \n",
      " trn_acc: 0.836 val_acc: 0.823\n",
      "spend time = { row/sec: 2340.0 optimize: 0.055 eval: 0.601 Elapsed: 446.481 }\n",
      "Epoch: 2 Batch_iter: 620 \n",
      " Train Loss: 0.096884534 Valid Loss: 0.11264388 \n",
      " trn_acc: 0.883 val_acc: 0.843\n",
      "spend time = { row/sec: 2518.0 optimize: 0.051 eval: 0.542 Elapsed: 448.687 }\n",
      "Epoch: 2 Batch_iter: 630 \n",
      " Train Loss: 0.113324374 Valid Loss: 0.117310286 \n",
      " trn_acc: 0.844 val_acc: 0.837\n",
      "spend time = { row/sec: 2655.0 optimize: 0.048 eval: 0.565 Elapsed: 451.422 }\n",
      "Epoch: 2 Batch_iter: 640 \n",
      " Train Loss: 0.14296731 Valid Loss: 0.13487145 \n",
      " trn_acc: 0.805 val_acc: 0.812\n",
      "spend time = { row/sec: 2688.0 optimize: 0.048 eval: 0.53 Elapsed: 453.68 }\n",
      "Epoch: 2 Batch_iter: 650 \n",
      " Train Loss: 0.09549926 Valid Loss: 0.114551544 \n",
      " trn_acc: 0.906 val_acc: 0.84\n",
      "spend time = { row/sec: 2578.0 optimize: 0.05 eval: 0.578 Elapsed: 455.85 }\n",
      "Epoch: 2 Batch_iter: 660 \n",
      " Train Loss: 0.10818784 Valid Loss: 0.1124358 \n",
      " trn_acc: 0.852 val_acc: 0.846\n",
      "spend time = { row/sec: 2763.0 optimize: 0.046 eval: 0.558 Elapsed: 458.704 }\n",
      "Epoch: 2 Batch_iter: 670 \n",
      " Train Loss: 0.103867844 Valid Loss: 0.11471776 \n",
      " trn_acc: 0.867 val_acc: 0.839\n",
      "spend time = { row/sec: 2121.0 optimize: 0.06 eval: 0.624 Elapsed: 460.944 }\n",
      "Epoch: 2 Batch_iter: 680 \n",
      " Train Loss: 0.121516734 Valid Loss: 0.112603426 \n",
      " trn_acc: 0.844 val_acc: 0.843\n",
      "spend time = { row/sec: 2690.0 optimize: 0.048 eval: 0.521 Elapsed: 463.081 }\n",
      "Epoch: 2 Batch_iter: 690 \n",
      " Train Loss: 0.11497623 Valid Loss: 0.11949457 \n",
      " trn_acc: 0.836 val_acc: 0.832\n",
      "spend time = { row/sec: 2694.0 optimize: 0.048 eval: 0.652 Elapsed: 465.889 }\n",
      "Epoch: 2 Batch_iter: 700 \n",
      " Train Loss: 0.16671506 Valid Loss: 0.11565913 \n",
      " trn_acc: 0.734 val_acc: 0.839\n",
      "spend time = { row/sec: 2487.0 optimize: 0.051 eval: 0.525 Elapsed: 468.474 }\n",
      "Epoch: 2 Batch_iter: 710 \n",
      " Train Loss: 0.12009594 Valid Loss: 0.1192243 \n",
      " trn_acc: 0.82 val_acc: 0.834\n",
      "spend time = { row/sec: 2700.0 optimize: 0.047 eval: 0.561 Elapsed: 470.647 }\n",
      "Epoch: 2 Batch_iter: 720 \n",
      " Train Loss: 0.13905767 Valid Loss: 0.11210556 \n",
      " trn_acc: 0.797 val_acc: 0.842\n",
      "spend time = { row/sec: 2655.0 optimize: 0.048 eval: 0.542 Elapsed: 473.384 }\n",
      "Epoch: 2 Batch_iter: 730 \n",
      " Train Loss: 0.109720744 Valid Loss: 0.116795346 \n",
      " trn_acc: 0.852 val_acc: 0.838\n",
      "spend time = { row/sec: 2247.0 optimize: 0.057 eval: 0.673 Elapsed: 475.763 }\n",
      "Epoch: 2 Batch_iter: 740 \n",
      " Train Loss: 0.11114931 Valid Loss: 0.118109226 \n",
      " trn_acc: 0.828 val_acc: 0.837\n",
      "spend time = { row/sec: 2639.0 optimize: 0.049 eval: 0.573 Elapsed: 478.031 }\n",
      "Epoch: 2 Batch_iter: 750 \n",
      " Train Loss: 0.11016627 Valid Loss: 0.115487754 \n",
      " trn_acc: 0.859 val_acc: 0.84\n",
      "spend time = { row/sec: 2765.0 optimize: 0.046 eval: 0.655 Elapsed: 480.831 }\n",
      "Epoch: 2 Batch_iter: 760 \n",
      " Train Loss: 0.14502253 Valid Loss: 0.11246354 \n",
      " trn_acc: 0.766 val_acc: 0.842\n",
      "spend time = { row/sec: 2494.0 optimize: 0.051 eval: 0.591 Elapsed: 483.073 }\n",
      "Epoch: 2 Batch_iter: 770 \n",
      " Train Loss: 0.09411916 Valid Loss: 0.11220362 \n",
      " trn_acc: 0.859 val_acc: 0.843\n",
      "spend time = { row/sec: 2703.0 optimize: 0.047 eval: 0.542 Elapsed: 485.426 }\n",
      "Epoch: 2 Batch_iter: 780 \n",
      " Train Loss: 0.121126086 Valid Loss: 0.111708365 \n",
      " trn_acc: 0.828 val_acc: 0.845\n",
      "spend time = { row/sec: 2542.0 optimize: 0.05 eval: 0.591 Elapsed: 488.23 }\n",
      "Epoch: 2 Batch_iter: 790 \n",
      " Train Loss: 0.10588677 Valid Loss: 0.11206078 \n",
      " trn_acc: 0.859 val_acc: 0.843\n",
      "spend time = { row/sec: 2653.0 optimize: 0.048 eval: 0.538 Elapsed: 490.416 }\n",
      "Epoch: 2 Batch_iter: 800 \n",
      " Train Loss: 0.10997041 Valid Loss: 0.11688699 \n",
      " trn_acc: 0.836 val_acc: 0.835\n",
      "spend time = { row/sec: 2725.0 optimize: 0.047 eval: 0.538 Elapsed: 492.999 }\n",
      "Epoch: 2 Batch_iter: 810 \n",
      " Train Loss: 0.115390494 Valid Loss: 0.11178309 \n",
      " trn_acc: 0.828 val_acc: 0.844\n",
      "spend time = { row/sec: 2637.0 optimize: 0.049 eval: 0.587 Elapsed: 495.82 }\n",
      "\n",
      " Save the model : current loss  0.11750850171177056 <= 0.15299555982877738 prev loss \n",
      "\n",
      "Epoch: 3 Batch_iter: 0 \n",
      " Train Loss: 0.11044426 Valid Loss: 0.11086362 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2684.0 optimize: 0.048 eval: 0.593 Elapsed: 498.964 }\n",
      "Epoch: 3 Batch_iter: 10 \n",
      " Train Loss: 0.10425807 Valid Loss: 0.110869996 \n",
      " trn_acc: 0.867 val_acc: 0.847\n",
      "spend time = { row/sec: 2263.0 optimize: 0.057 eval: 0.544 Elapsed: 501.094 }\n",
      "Epoch: 3 Batch_iter: 20 \n",
      " Train Loss: 0.094126634 Valid Loss: 0.11677246 \n",
      " trn_acc: 0.875 val_acc: 0.841\n",
      "spend time = { row/sec: 2617.0 optimize: 0.049 eval: 0.568 Elapsed: 503.386 }\n",
      "Epoch: 3 Batch_iter: 30 \n",
      " Train Loss: 0.09799209 Valid Loss: 0.115684085 \n",
      " trn_acc: 0.859 val_acc: 0.84\n",
      "spend time = { row/sec: 2749.0 optimize: 0.047 eval: 0.539 Elapsed: 506.094 }\n",
      "Epoch: 3 Batch_iter: 40 \n",
      " Train Loss: 0.12743273 Valid Loss: 0.11160423 \n",
      " trn_acc: 0.828 val_acc: 0.845\n",
      "spend time = { row/sec: 2551.0 optimize: 0.05 eval: 0.563 Elapsed: 508.333 }\n",
      "Epoch: 3 Batch_iter: 50 \n",
      " Train Loss: 0.09975925 Valid Loss: 0.11814399 \n",
      " trn_acc: 0.867 val_acc: 0.834\n",
      "spend time = { row/sec: 2780.0 optimize: 0.046 eval: 0.523 Elapsed: 510.472 }\n",
      "Epoch: 3 Batch_iter: 60 \n",
      " Train Loss: 0.10843177 Valid Loss: 0.11653299 \n",
      " trn_acc: 0.852 val_acc: 0.837\n",
      "spend time = { row/sec: 2466.0 optimize: 0.052 eval: 0.551 Elapsed: 513.154 }\n",
      "Epoch: 3 Batch_iter: 70 \n",
      " Train Loss: 0.099019356 Valid Loss: 0.1140854 \n",
      " trn_acc: 0.867 val_acc: 0.841\n",
      "spend time = { row/sec: 2439.0 optimize: 0.052 eval: 0.554 Elapsed: 515.375 }\n",
      "Epoch: 3 Batch_iter: 80 \n",
      " Train Loss: 0.09973453 Valid Loss: 0.116031036 \n",
      " trn_acc: 0.859 val_acc: 0.841\n",
      "spend time = { row/sec: 2747.0 optimize: 0.047 eval: 0.541 Elapsed: 517.486 }\n",
      "Epoch: 3 Batch_iter: 90 \n",
      " Train Loss: 0.1301369 Valid Loss: 0.11807835 \n",
      " trn_acc: 0.828 val_acc: 0.838\n",
      "spend time = { row/sec: 2722.0 optimize: 0.047 eval: 0.591 Elapsed: 520.282 }\n",
      "Epoch: 3 Batch_iter: 100 \n",
      " Train Loss: 0.12979245 Valid Loss: 0.116621636 \n",
      " trn_acc: 0.828 val_acc: 0.84\n",
      "spend time = { row/sec: 2677.0 optimize: 0.048 eval: 0.542 Elapsed: 522.4 }\n",
      "Epoch: 3 Batch_iter: 110 \n",
      " Train Loss: 0.103622004 Valid Loss: 0.11290491 \n",
      " trn_acc: 0.859 val_acc: 0.842\n",
      "spend time = { row/sec: 2590.0 optimize: 0.049 eval: 0.534 Elapsed: 524.748 }\n",
      "Epoch: 3 Batch_iter: 120 \n",
      " Train Loss: 0.09026295 Valid Loss: 0.112253144 \n",
      " trn_acc: 0.883 val_acc: 0.842\n",
      "spend time = { row/sec: 2687.0 optimize: 0.048 eval: 0.7 Elapsed: 527.719 }\n",
      "Epoch: 3 Batch_iter: 130 \n",
      " Train Loss: 0.08797473 Valid Loss: 0.112403624 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2543.0 optimize: 0.05 eval: 0.544 Elapsed: 529.917 }\n",
      "Epoch: 3 Batch_iter: 140 \n",
      " Train Loss: 0.13241346 Valid Loss: 0.11321167 \n",
      " trn_acc: 0.82 val_acc: 0.845\n",
      "spend time = { row/sec: 2619.0 optimize: 0.049 eval: 0.535 Elapsed: 532.028 }\n",
      "Epoch: 3 Batch_iter: 150 \n",
      " Train Loss: 0.08958809 Valid Loss: 0.11342478 \n",
      " trn_acc: 0.867 val_acc: 0.844\n",
      "spend time = { row/sec: 2749.0 optimize: 0.047 eval: 0.767 Elapsed: 535.097 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Batch_iter: 160 \n",
      " Train Loss: 0.06796479 Valid Loss: 0.111259945 \n",
      " trn_acc: 0.922 val_acc: 0.848\n",
      "spend time = { row/sec: 2259.0 optimize: 0.057 eval: 0.833 Elapsed: 537.593 }\n",
      "Epoch: 3 Batch_iter: 170 \n",
      " Train Loss: 0.121445775 Valid Loss: 0.1123686 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2804.0 optimize: 0.046 eval: 0.531 Elapsed: 539.649 }\n",
      "Epoch: 3 Batch_iter: 180 \n",
      " Train Loss: 0.09963629 Valid Loss: 0.11510251 \n",
      " trn_acc: 0.852 val_acc: 0.844\n",
      "spend time = { row/sec: 2669.0 optimize: 0.048 eval: 0.553 Elapsed: 542.402 }\n",
      "Epoch: 3 Batch_iter: 190 \n",
      " Train Loss: 0.10137465 Valid Loss: 0.112087384 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2675.0 optimize: 0.048 eval: 0.543 Elapsed: 544.737 }\n",
      "Epoch: 3 Batch_iter: 200 \n",
      " Train Loss: 0.1255343 Valid Loss: 0.112550765 \n",
      " trn_acc: 0.828 val_acc: 0.846\n",
      "spend time = { row/sec: 2755.0 optimize: 0.046 eval: 0.553 Elapsed: 546.887 }\n",
      "Epoch: 3 Batch_iter: 210 \n",
      " Train Loss: 0.095077895 Valid Loss: 0.121329896 \n",
      " trn_acc: 0.883 val_acc: 0.835\n",
      "spend time = { row/sec: 2751.0 optimize: 0.047 eval: 0.571 Elapsed: 549.647 }\n",
      "Epoch: 3 Batch_iter: 220 \n",
      " Train Loss: 0.115967765 Valid Loss: 0.11103872 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2703.0 optimize: 0.047 eval: 0.545 Elapsed: 551.855 }\n",
      "Epoch: 3 Batch_iter: 230 \n",
      " Train Loss: 0.116062164 Valid Loss: 0.11255931 \n",
      " trn_acc: 0.852 val_acc: 0.843\n",
      "spend time = { row/sec: 2519.0 optimize: 0.051 eval: 0.548 Elapsed: 554.032 }\n",
      "Epoch: 3 Batch_iter: 240 \n",
      " Train Loss: 0.11409439 Valid Loss: 0.11817139 \n",
      " trn_acc: 0.852 val_acc: 0.835\n",
      "spend time = { row/sec: 2571.0 optimize: 0.05 eval: 0.562 Elapsed: 556.775 }\n",
      "Epoch: 3 Batch_iter: 250 \n",
      " Train Loss: 0.0916266 Valid Loss: 0.12656063 \n",
      " trn_acc: 0.867 val_acc: 0.824\n",
      "spend time = { row/sec: 2241.0 optimize: 0.057 eval: 0.529 Elapsed: 558.878 }\n",
      "Epoch: 3 Batch_iter: 260 \n",
      " Train Loss: 0.12827647 Valid Loss: 0.1106902 \n",
      " trn_acc: 0.828 val_acc: 0.846\n",
      "spend time = { row/sec: 2397.0 optimize: 0.053 eval: 0.537 Elapsed: 561.139 }\n",
      "Epoch: 3 Batch_iter: 270 \n",
      " Train Loss: 0.121675916 Valid Loss: 0.112815544 \n",
      " trn_acc: 0.859 val_acc: 0.845\n",
      "spend time = { row/sec: 2687.0 optimize: 0.048 eval: 0.6 Elapsed: 563.896 }\n",
      "Epoch: 3 Batch_iter: 280 \n",
      " Train Loss: 0.096226886 Valid Loss: 0.111669764 \n",
      " trn_acc: 0.875 val_acc: 0.845\n",
      "spend time = { row/sec: 2539.0 optimize: 0.05 eval: 0.528 Elapsed: 566.037 }\n",
      "Epoch: 3 Batch_iter: 290 \n",
      " Train Loss: 0.098673195 Valid Loss: 0.11446318 \n",
      " trn_acc: 0.883 val_acc: 0.845\n",
      "spend time = { row/sec: 2733.0 optimize: 0.047 eval: 0.554 Elapsed: 568.192 }\n",
      "Epoch: 3 Batch_iter: 300 \n",
      " Train Loss: 0.13411431 Valid Loss: 0.12348758 \n",
      " trn_acc: 0.828 val_acc: 0.832\n",
      "spend time = { row/sec: 2628.0 optimize: 0.049 eval: 0.526 Elapsed: 571.521 }\n",
      "Epoch: 3 Batch_iter: 310 \n",
      " Train Loss: 0.10427576 Valid Loss: 0.111591205 \n",
      " trn_acc: 0.875 val_acc: 0.845\n",
      "spend time = { row/sec: 2546.0 optimize: 0.05 eval: 0.589 Elapsed: 573.706 }\n",
      "Epoch: 3 Batch_iter: 320 \n",
      " Train Loss: 0.10083102 Valid Loss: 0.117460206 \n",
      " trn_acc: 0.859 val_acc: 0.835\n",
      "spend time = { row/sec: 2800.0 optimize: 0.046 eval: 0.521 Elapsed: 575.875 }\n",
      "Epoch: 3 Batch_iter: 330 \n",
      " Train Loss: 0.09778157 Valid Loss: 0.112771794 \n",
      " trn_acc: 0.867 val_acc: 0.847\n",
      "spend time = { row/sec: 2701.0 optimize: 0.047 eval: 0.527 Elapsed: 578.543 }\n",
      "Epoch: 3 Batch_iter: 340 \n",
      " Train Loss: 0.09137176 Valid Loss: 0.111043856 \n",
      " trn_acc: 0.891 val_acc: 0.847\n",
      "spend time = { row/sec: 2693.0 optimize: 0.048 eval: 0.533 Elapsed: 580.648 }\n",
      "Epoch: 3 Batch_iter: 350 \n",
      " Train Loss: 0.09481942 Valid Loss: 0.1135632 \n",
      " trn_acc: 0.867 val_acc: 0.842\n",
      "spend time = { row/sec: 2824.0 optimize: 0.045 eval: 0.688 Elapsed: 582.935 }\n",
      "Epoch: 3 Batch_iter: 360 \n",
      " Train Loss: 0.10915126 Valid Loss: 0.11276621 \n",
      " trn_acc: 0.852 val_acc: 0.845\n",
      "spend time = { row/sec: 2739.0 optimize: 0.047 eval: 0.519 Elapsed: 585.607 }\n",
      "Epoch: 3 Batch_iter: 370 \n",
      " Train Loss: 0.11457878 Valid Loss: 0.11328979 \n",
      " trn_acc: 0.836 val_acc: 0.844\n",
      "spend time = { row/sec: 2535.0 optimize: 0.05 eval: 0.559 Elapsed: 587.761 }\n",
      "Epoch: 3 Batch_iter: 380 \n",
      " Train Loss: 0.09532173 Valid Loss: 0.11137531 \n",
      " trn_acc: 0.891 val_acc: 0.845\n",
      "spend time = { row/sec: 2706.0 optimize: 0.047 eval: 0.562 Elapsed: 589.869 }\n",
      "Epoch: 3 Batch_iter: 390 \n",
      " Train Loss: 0.1263966 Valid Loss: 0.11242356 \n",
      " trn_acc: 0.828 val_acc: 0.846\n",
      "spend time = { row/sec: 2761.0 optimize: 0.046 eval: 0.54 Elapsed: 592.574 }\n",
      "Epoch: 3 Batch_iter: 400 \n",
      " Train Loss: 0.09622869 Valid Loss: 0.11305749 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2206.0 optimize: 0.058 eval: 0.564 Elapsed: 595.837 }\n",
      "Epoch: 3 Batch_iter: 410 \n",
      " Train Loss: 0.123715796 Valid Loss: 0.118007936 \n",
      " trn_acc: 0.836 val_acc: 0.836\n",
      "spend time = { row/sec: 2712.0 optimize: 0.047 eval: 0.546 Elapsed: 597.985 }\n",
      "Epoch: 3 Batch_iter: 420 \n",
      " Train Loss: 0.09857393 Valid Loss: 0.112183556 \n",
      " trn_acc: 0.844 val_acc: 0.849\n",
      "spend time = { row/sec: 2633.0 optimize: 0.049 eval: 0.544 Elapsed: 600.719 }\n",
      "Epoch: 3 Batch_iter: 430 \n",
      " Train Loss: 0.115041696 Valid Loss: 0.110731594 \n",
      " trn_acc: 0.852 val_acc: 0.846\n",
      "spend time = { row/sec: 2433.0 optimize: 0.053 eval: 0.548 Elapsed: 604.001 }\n",
      "Epoch: 3 Batch_iter: 440 \n",
      " Train Loss: 0.1275408 Valid Loss: 0.13281393 \n",
      " trn_acc: 0.852 val_acc: 0.814\n",
      "spend time = { row/sec: 2446.0 optimize: 0.052 eval: 0.55 Elapsed: 606.203 }\n",
      "Epoch: 3 Batch_iter: 450 \n",
      " Train Loss: 0.09721723 Valid Loss: 0.111044146 \n",
      " trn_acc: 0.867 val_acc: 0.845\n",
      "spend time = { row/sec: 2708.0 optimize: 0.047 eval: 0.583 Elapsed: 608.921 }\n",
      "Epoch: 3 Batch_iter: 460 \n",
      " Train Loss: 0.11399751 Valid Loss: 0.12335955 \n",
      " trn_acc: 0.852 val_acc: 0.831\n",
      "spend time = { row/sec: 2428.0 optimize: 0.053 eval: 0.535 Elapsed: 611.04 }\n",
      "Epoch: 3 Batch_iter: 470 \n",
      " Train Loss: 0.11544901 Valid Loss: 0.11153032 \n",
      " trn_acc: 0.82 val_acc: 0.846\n",
      "spend time = { row/sec: 2635.0 optimize: 0.049 eval: 0.54 Elapsed: 613.911 }\n",
      "Epoch: 3 Batch_iter: 480 \n",
      " Train Loss: 0.09695241 Valid Loss: 0.11087111 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2752.0 optimize: 0.047 eval: 0.54 Elapsed: 616.576 }\n",
      "Epoch: 3 Batch_iter: 490 \n",
      " Train Loss: 0.113627456 Valid Loss: 0.111336835 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2508.0 optimize: 0.051 eval: 0.552 Elapsed: 618.71 }\n",
      "Epoch: 3 Batch_iter: 500 \n",
      " Train Loss: 0.101455584 Valid Loss: 0.11189154 \n",
      " trn_acc: 0.852 val_acc: 0.846\n",
      "spend time = { row/sec: 2677.0 optimize: 0.048 eval: 0.544 Elapsed: 621.758 }\n",
      "Epoch: 3 Batch_iter: 510 \n",
      " Train Loss: 0.07677503 Valid Loss: 0.122162975 \n",
      " trn_acc: 0.922 val_acc: 0.83\n",
      "spend time = { row/sec: 2744.0 optimize: 0.047 eval: 0.613 Elapsed: 624.544 }\n",
      "Epoch: 3 Batch_iter: 520 \n",
      " Train Loss: 0.11040949 Valid Loss: 0.11328305 \n",
      " trn_acc: 0.836 val_acc: 0.844\n",
      "spend time = { row/sec: 2412.0 optimize: 0.053 eval: 0.563 Elapsed: 627.519 }\n",
      "Epoch: 3 Batch_iter: 530 \n",
      " Train Loss: 0.11012191 Valid Loss: 0.11108646 \n",
      " trn_acc: 0.836 val_acc: 0.847\n",
      "spend time = { row/sec: 2726.0 optimize: 0.047 eval: 0.558 Elapsed: 629.726 }\n",
      "Epoch: 3 Batch_iter: 540 \n",
      " Train Loss: 0.11772324 Valid Loss: 0.11574827 \n",
      " trn_acc: 0.852 val_acc: 0.84\n",
      "spend time = { row/sec: 2719.0 optimize: 0.047 eval: 0.538 Elapsed: 632.4 }\n",
      "Epoch: 3 Batch_iter: 550 \n",
      " Train Loss: 0.15834254 Valid Loss: 0.11358659 \n",
      " trn_acc: 0.766 val_acc: 0.841\n",
      "spend time = { row/sec: 2357.0 optimize: 0.054 eval: 0.554 Elapsed: 634.567 }\n",
      "Epoch: 3 Batch_iter: 560 \n",
      " Train Loss: 0.12044057 Valid Loss: 0.11205226 \n",
      " trn_acc: 0.828 val_acc: 0.845\n",
      "spend time = { row/sec: 2639.0 optimize: 0.048 eval: 0.527 Elapsed: 636.67 }\n",
      "Epoch: 3 Batch_iter: 570 \n",
      " Train Loss: 0.10195047 Valid Loss: 0.11107901 \n",
      " trn_acc: 0.844 val_acc: 0.845\n",
      "spend time = { row/sec: 2760.0 optimize: 0.046 eval: 0.55 Elapsed: 639.372 }\n",
      "Epoch: 3 Batch_iter: 580 \n",
      " Train Loss: 0.09768182 Valid Loss: 0.11080229 \n",
      " trn_acc: 0.891 val_acc: 0.845\n",
      "spend time = { row/sec: 2340.0 optimize: 0.055 eval: 0.537 Elapsed: 641.494 }\n",
      "Epoch: 3 Batch_iter: 590 \n",
      " Train Loss: 0.0704957 Valid Loss: 0.11328312 \n",
      " trn_acc: 0.898 val_acc: 0.841\n",
      "spend time = { row/sec: 2753.0 optimize: 0.046 eval: 0.552 Elapsed: 643.683 }\n",
      "Epoch: 3 Batch_iter: 600 \n",
      " Train Loss: 0.115645945 Valid Loss: 0.114540264 \n",
      " trn_acc: 0.828 val_acc: 0.844\n",
      "spend time = { row/sec: 2681.0 optimize: 0.048 eval: 0.57 Elapsed: 646.382 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Batch_iter: 610 \n",
      " Train Loss: 0.08029018 Valid Loss: 0.11081175 \n",
      " trn_acc: 0.906 val_acc: 0.847\n",
      "spend time = { row/sec: 2681.0 optimize: 0.048 eval: 0.525 Elapsed: 648.5 }\n",
      "Epoch: 3 Batch_iter: 620 \n",
      " Train Loss: 0.11317252 Valid Loss: 0.11667991 \n",
      " trn_acc: 0.859 val_acc: 0.837\n",
      "spend time = { row/sec: 2820.0 optimize: 0.045 eval: 0.584 Elapsed: 650.636 }\n",
      "Epoch: 3 Batch_iter: 630 \n",
      " Train Loss: 0.15340579 Valid Loss: 0.115701936 \n",
      " trn_acc: 0.805 val_acc: 0.84\n",
      "spend time = { row/sec: 2760.0 optimize: 0.046 eval: 0.56 Elapsed: 653.46 }\n",
      "Epoch: 3 Batch_iter: 640 \n",
      " Train Loss: 0.13253084 Valid Loss: 0.111465834 \n",
      " trn_acc: 0.82 val_acc: 0.847\n",
      "spend time = { row/sec: 2485.0 optimize: 0.051 eval: 0.578 Elapsed: 655.634 }\n",
      "Epoch: 3 Batch_iter: 650 \n",
      " Train Loss: 0.10814216 Valid Loss: 0.110484555 \n",
      " trn_acc: 0.82 val_acc: 0.848\n",
      "spend time = { row/sec: 2763.0 optimize: 0.046 eval: 0.588 Elapsed: 657.789 }\n",
      "Epoch: 3 Batch_iter: 660 \n",
      " Train Loss: 0.088245526 Valid Loss: 0.110498525 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2705.0 optimize: 0.047 eval: 0.563 Elapsed: 660.518 }\n",
      "Epoch: 3 Batch_iter: 670 \n",
      " Train Loss: 0.08205205 Valid Loss: 0.11201519 \n",
      " trn_acc: 0.898 val_acc: 0.846\n",
      "spend time = { row/sec: 2263.0 optimize: 0.057 eval: 0.942 Elapsed: 663.059 }\n",
      "Epoch: 3 Batch_iter: 680 \n",
      " Train Loss: 0.09936655 Valid Loss: 0.11129111 \n",
      " trn_acc: 0.859 val_acc: 0.845\n",
      "spend time = { row/sec: 2416.0 optimize: 0.053 eval: 0.592 Elapsed: 665.393 }\n",
      "Epoch: 3 Batch_iter: 690 \n",
      " Train Loss: 0.13695651 Valid Loss: 0.11900153 \n",
      " trn_acc: 0.797 val_acc: 0.834\n",
      "spend time = { row/sec: 2718.0 optimize: 0.047 eval: 0.573 Elapsed: 668.089 }\n",
      "Epoch: 3 Batch_iter: 700 \n",
      " Train Loss: 0.08633271 Valid Loss: 0.111812204 \n",
      " trn_acc: 0.898 val_acc: 0.845\n",
      "spend time = { row/sec: 2561.0 optimize: 0.05 eval: 0.583 Elapsed: 670.214 }\n",
      "Epoch: 3 Batch_iter: 710 \n",
      " Train Loss: 0.13765326 Valid Loss: 0.1117586 \n",
      " trn_acc: 0.812 val_acc: 0.846\n",
      "spend time = { row/sec: 2662.0 optimize: 0.048 eval: 0.597 Elapsed: 672.457 }\n",
      "Epoch: 3 Batch_iter: 720 \n",
      " Train Loss: 0.121697664 Valid Loss: 0.11102342 \n",
      " trn_acc: 0.82 val_acc: 0.845\n",
      "spend time = { row/sec: 2773.0 optimize: 0.046 eval: 0.565 Elapsed: 675.187 }\n",
      "Epoch: 3 Batch_iter: 730 \n",
      " Train Loss: 0.121650726 Valid Loss: 0.11122548 \n",
      " trn_acc: 0.844 val_acc: 0.846\n",
      "spend time = { row/sec: 2370.0 optimize: 0.054 eval: 0.532 Elapsed: 677.697 }\n",
      "Epoch: 3 Batch_iter: 740 \n",
      " Train Loss: 0.12358518 Valid Loss: 0.110207975 \n",
      " trn_acc: 0.805 val_acc: 0.846\n",
      "spend time = { row/sec: 2713.0 optimize: 0.047 eval: 0.565 Elapsed: 679.781 }\n",
      "Epoch: 3 Batch_iter: 750 \n",
      " Train Loss: 0.092207156 Valid Loss: 0.11724089 \n",
      " trn_acc: 0.867 val_acc: 0.837\n",
      "spend time = { row/sec: 2769.0 optimize: 0.046 eval: 0.534 Elapsed: 682.377 }\n",
      "Epoch: 3 Batch_iter: 760 \n",
      " Train Loss: 0.16150364 Valid Loss: 0.12635799 \n",
      " trn_acc: 0.773 val_acc: 0.824\n",
      "spend time = { row/sec: 2718.0 optimize: 0.047 eval: 0.611 Elapsed: 684.697 }\n",
      "Epoch: 3 Batch_iter: 770 \n",
      " Train Loss: 0.11973862 Valid Loss: 0.11002083 \n",
      " trn_acc: 0.836 val_acc: 0.847\n",
      "spend time = { row/sec: 2450.0 optimize: 0.052 eval: 0.554 Elapsed: 686.796 }\n",
      "Epoch: 3 Batch_iter: 780 \n",
      " Train Loss: 0.1353636 Valid Loss: 0.12274848 \n",
      " trn_acc: 0.82 val_acc: 0.833\n",
      "spend time = { row/sec: 2651.0 optimize: 0.048 eval: 0.552 Elapsed: 689.508 }\n",
      "Epoch: 3 Batch_iter: 790 \n",
      " Train Loss: 0.11214834 Valid Loss: 0.11209733 \n",
      " trn_acc: 0.844 val_acc: 0.845\n",
      "spend time = { row/sec: 2353.0 optimize: 0.054 eval: 0.554 Elapsed: 691.689 }\n",
      "Epoch: 3 Batch_iter: 800 \n",
      " Train Loss: 0.13411209 Valid Loss: 0.1103871 \n",
      " trn_acc: 0.781 val_acc: 0.847\n",
      "spend time = { row/sec: 2595.0 optimize: 0.049 eval: 0.558 Elapsed: 693.914 }\n",
      "Epoch: 3 Batch_iter: 810 \n",
      " Train Loss: 0.10705035 Valid Loss: 0.111984424 \n",
      " trn_acc: 0.836 val_acc: 0.844\n",
      "spend time = { row/sec: 2809.0 optimize: 0.046 eval: 0.543 Elapsed: 696.595 }\n",
      "\n",
      " Save the model : current loss  0.11417174132635993 <= 0.11750850171177056 prev loss \n",
      "\n",
      "Epoch: 4 Batch_iter: 0 \n",
      " Train Loss: 0.09758422 Valid Loss: 0.11443662 \n",
      " trn_acc: 0.859 val_acc: 0.843\n",
      "spend time = { row/sec: 2571.0 optimize: 0.05 eval: 0.547 Elapsed: 699.786 }\n",
      "Epoch: 4 Batch_iter: 10 \n",
      " Train Loss: 0.09338065 Valid Loss: 0.11044442 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2720.0 optimize: 0.047 eval: 0.527 Elapsed: 701.86 }\n",
      "Epoch: 4 Batch_iter: 20 \n",
      " Train Loss: 0.060446806 Valid Loss: 0.111221254 \n",
      " trn_acc: 0.938 val_acc: 0.846\n",
      "spend time = { row/sec: 2536.0 optimize: 0.05 eval: 0.545 Elapsed: 704.036 }\n",
      "Epoch: 4 Batch_iter: 30 \n",
      " Train Loss: 0.06880913 Valid Loss: 0.11115472 \n",
      " trn_acc: 0.922 val_acc: 0.845\n",
      "spend time = { row/sec: 2659.0 optimize: 0.048 eval: 0.556 Elapsed: 706.713 }\n",
      "Epoch: 4 Batch_iter: 40 \n",
      " Train Loss: 0.09019131 Valid Loss: 0.111045144 \n",
      " trn_acc: 0.883 val_acc: 0.847\n",
      "spend time = { row/sec: 2400.0 optimize: 0.053 eval: 0.546 Elapsed: 708.795 }\n",
      "Epoch: 4 Batch_iter: 50 \n",
      " Train Loss: 0.13541302 Valid Loss: 0.11443624 \n",
      " trn_acc: 0.789 val_acc: 0.843\n",
      "spend time = { row/sec: 2693.0 optimize: 0.048 eval: 0.526 Elapsed: 710.93 }\n",
      "Epoch: 4 Batch_iter: 60 \n",
      " Train Loss: 0.10764826 Valid Loss: 0.11146564 \n",
      " trn_acc: 0.859 val_acc: 0.846\n",
      "spend time = { row/sec: 2151.0 optimize: 0.059 eval: 0.562 Elapsed: 713.671 }\n",
      "Epoch: 4 Batch_iter: 70 \n",
      " Train Loss: 0.12115179 Valid Loss: 0.1110665 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2455.0 optimize: 0.052 eval: 0.537 Elapsed: 715.809 }\n",
      "Epoch: 4 Batch_iter: 80 \n",
      " Train Loss: 0.13020577 Valid Loss: 0.111993276 \n",
      " trn_acc: 0.82 val_acc: 0.846\n",
      "spend time = { row/sec: 2653.0 optimize: 0.048 eval: 0.563 Elapsed: 717.939 }\n",
      "Epoch: 4 Batch_iter: 90 \n",
      " Train Loss: 0.10039651 Valid Loss: 0.11529841 \n",
      " trn_acc: 0.867 val_acc: 0.841\n",
      "spend time = { row/sec: 2725.0 optimize: 0.047 eval: 0.593 Elapsed: 720.665 }\n",
      "Epoch: 4 Batch_iter: 100 \n",
      " Train Loss: 0.103056036 Valid Loss: 0.111503355 \n",
      " trn_acc: 0.836 val_acc: 0.846\n",
      "spend time = { row/sec: 2375.0 optimize: 0.054 eval: 0.549 Elapsed: 722.841 }\n",
      "Epoch: 4 Batch_iter: 110 \n",
      " Train Loss: 0.10796435 Valid Loss: 0.11536895 \n",
      " trn_acc: 0.859 val_acc: 0.844\n",
      "spend time = { row/sec: 2737.0 optimize: 0.047 eval: 0.538 Elapsed: 724.943 }\n",
      "Epoch: 4 Batch_iter: 120 \n",
      " Train Loss: 0.12587044 Valid Loss: 0.110957064 \n",
      " trn_acc: 0.805 val_acc: 0.846\n",
      "spend time = { row/sec: 2715.0 optimize: 0.047 eval: 0.553 Elapsed: 727.661 }\n",
      "Epoch: 4 Batch_iter: 130 \n",
      " Train Loss: 0.12717238 Valid Loss: 0.12539555 \n",
      " trn_acc: 0.797 val_acc: 0.825\n",
      "spend time = { row/sec: 2323.0 optimize: 0.055 eval: 0.574 Elapsed: 729.835 }\n",
      "Epoch: 4 Batch_iter: 140 \n",
      " Train Loss: 0.093650654 Valid Loss: 0.11068224 \n",
      " trn_acc: 0.867 val_acc: 0.846\n",
      "spend time = { row/sec: 2176.0 optimize: 0.059 eval: 0.534 Elapsed: 731.96 }\n",
      "Epoch: 4 Batch_iter: 150 \n",
      " Train Loss: 0.11161842 Valid Loss: 0.11218519 \n",
      " trn_acc: 0.844 val_acc: 0.846\n",
      "spend time = { row/sec: 2746.0 optimize: 0.047 eval: 0.523 Elapsed: 734.564 }\n",
      "Epoch: 4 Batch_iter: 160 \n",
      " Train Loss: 0.08544546 Valid Loss: 0.11128572 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2537.0 optimize: 0.05 eval: 0.872 Elapsed: 736.985 }\n",
      "Epoch: 4 Batch_iter: 170 \n",
      " Train Loss: 0.09501651 Valid Loss: 0.11082085 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2730.0 optimize: 0.047 eval: 0.552 Elapsed: 739.131 }\n",
      "Epoch: 4 Batch_iter: 180 \n",
      " Train Loss: 0.078805625 Valid Loss: 0.11137374 \n",
      " trn_acc: 0.906 val_acc: 0.847\n",
      "spend time = { row/sec: 2660.0 optimize: 0.048 eval: 0.553 Elapsed: 741.77 }\n",
      "Epoch: 4 Batch_iter: 190 \n",
      " Train Loss: 0.09710272 Valid Loss: 0.111105405 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2503.0 optimize: 0.051 eval: 0.524 Elapsed: 743.873 }\n",
      "Epoch: 4 Batch_iter: 200 \n",
      " Train Loss: 0.09385742 Valid Loss: 0.112488866 \n",
      " trn_acc: 0.891 val_acc: 0.847\n",
      "spend time = { row/sec: 2694.0 optimize: 0.047 eval: 0.546 Elapsed: 745.964 }\n",
      "Epoch: 4 Batch_iter: 210 \n",
      " Train Loss: 0.06442292 Valid Loss: 0.11378781 \n",
      " trn_acc: 0.898 val_acc: 0.844\n",
      "spend time = { row/sec: 2771.0 optimize: 0.046 eval: 0.552 Elapsed: 748.667 }\n",
      "Epoch: 4 Batch_iter: 220 \n",
      " Train Loss: 0.072914585 Valid Loss: 0.1114847 \n",
      " trn_acc: 0.898 val_acc: 0.846\n",
      "spend time = { row/sec: 2496.0 optimize: 0.051 eval: 0.558 Elapsed: 750.835 }\n",
      "Epoch: 4 Batch_iter: 230 \n",
      " Train Loss: 0.12016917 Valid Loss: 0.11279816 \n",
      " trn_acc: 0.852 val_acc: 0.842\n",
      "spend time = { row/sec: 2689.0 optimize: 0.048 eval: 0.529 Elapsed: 753.062 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Batch_iter: 240 \n",
      " Train Loss: 0.10963529 Valid Loss: 0.111531995 \n",
      " trn_acc: 0.828 val_acc: 0.846\n",
      "spend time = { row/sec: 2706.0 optimize: 0.047 eval: 0.548 Elapsed: 755.745 }\n",
      "Epoch: 4 Batch_iter: 250 \n",
      " Train Loss: 0.081118576 Valid Loss: 0.113649964 \n",
      " trn_acc: 0.898 val_acc: 0.844\n",
      "spend time = { row/sec: 2742.0 optimize: 0.047 eval: 0.53 Elapsed: 757.854 }\n",
      "Epoch: 4 Batch_iter: 260 \n",
      " Train Loss: 0.11027515 Valid Loss: 0.11552221 \n",
      " trn_acc: 0.812 val_acc: 0.841\n",
      "spend time = { row/sec: 2681.0 optimize: 0.048 eval: 0.537 Elapsed: 760.052 }\n",
      "Epoch: 4 Batch_iter: 270 \n",
      " Train Loss: 0.09220943 Valid Loss: 0.1283331 \n",
      " trn_acc: 0.867 val_acc: 0.826\n",
      "spend time = { row/sec: 2667.0 optimize: 0.048 eval: 0.549 Elapsed: 762.842 }\n",
      "Epoch: 4 Batch_iter: 280 \n",
      " Train Loss: 0.09940116 Valid Loss: 0.112046994 \n",
      " trn_acc: 0.852 val_acc: 0.845\n",
      "spend time = { row/sec: 2665.0 optimize: 0.048 eval: 0.51 Elapsed: 764.935 }\n",
      "Epoch: 4 Batch_iter: 290 \n",
      " Train Loss: 0.09200232 Valid Loss: 0.11031881 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2483.0 optimize: 0.052 eval: 0.751 Elapsed: 767.374 }\n",
      "Epoch: 4 Batch_iter: 300 \n",
      " Train Loss: 0.103298485 Valid Loss: 0.11173452 \n",
      " trn_acc: 0.852 val_acc: 0.845\n",
      "spend time = { row/sec: 2541.0 optimize: 0.05 eval: 0.565 Elapsed: 770.052 }\n",
      "Epoch: 4 Batch_iter: 310 \n",
      " Train Loss: 0.08595989 Valid Loss: 0.11060822 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2551.0 optimize: 0.05 eval: 0.558 Elapsed: 772.145 }\n",
      "Epoch: 4 Batch_iter: 320 \n",
      " Train Loss: 0.10278584 Valid Loss: 0.11186535 \n",
      " trn_acc: 0.867 val_acc: 0.846\n",
      "spend time = { row/sec: 2660.0 optimize: 0.048 eval: 0.544 Elapsed: 774.277 }\n",
      "Epoch: 4 Batch_iter: 330 \n",
      " Train Loss: 0.14015758 Valid Loss: 0.11065148 \n",
      " trn_acc: 0.805 val_acc: 0.847\n",
      "spend time = { row/sec: 2683.0 optimize: 0.048 eval: 0.582 Elapsed: 777.038 }\n",
      "Epoch: 4 Batch_iter: 340 \n",
      " Train Loss: 0.080495484 Valid Loss: 0.11081514 \n",
      " trn_acc: 0.906 val_acc: 0.847\n",
      "spend time = { row/sec: 2480.0 optimize: 0.052 eval: 0.581 Elapsed: 779.283 }\n",
      "Epoch: 4 Batch_iter: 350 \n",
      " Train Loss: 0.103144415 Valid Loss: 0.11063247 \n",
      " trn_acc: 0.852 val_acc: 0.848\n",
      "spend time = { row/sec: 2755.0 optimize: 0.046 eval: 0.537 Elapsed: 781.419 }\n",
      "Epoch: 4 Batch_iter: 360 \n",
      " Train Loss: 0.09761366 Valid Loss: 0.11208481 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2496.0 optimize: 0.051 eval: 0.532 Elapsed: 784.065 }\n",
      "Epoch: 4 Batch_iter: 370 \n",
      " Train Loss: 0.08229234 Valid Loss: 0.12021276 \n",
      " trn_acc: 0.906 val_acc: 0.835\n",
      "spend time = { row/sec: 2345.0 optimize: 0.055 eval: 0.544 Elapsed: 786.282 }\n",
      "Epoch: 4 Batch_iter: 380 \n",
      " Train Loss: 0.09398623 Valid Loss: 0.11231252 \n",
      " trn_acc: 0.906 val_acc: 0.846\n",
      "spend time = { row/sec: 2780.0 optimize: 0.046 eval: 0.547 Elapsed: 788.422 }\n",
      "Epoch: 4 Batch_iter: 390 \n",
      " Train Loss: 0.09225111 Valid Loss: 0.11194896 \n",
      " trn_acc: 0.906 val_acc: 0.845\n",
      "spend time = { row/sec: 2715.0 optimize: 0.047 eval: 0.555 Elapsed: 791.09 }\n",
      "Epoch: 4 Batch_iter: 400 \n",
      " Train Loss: 0.12072812 Valid Loss: 0.10962634 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2477.0 optimize: 0.052 eval: 0.546 Elapsed: 793.244 }\n",
      "Epoch: 4 Batch_iter: 410 \n",
      " Train Loss: 0.085868984 Valid Loss: 0.11354124 \n",
      " trn_acc: 0.883 val_acc: 0.842\n",
      "spend time = { row/sec: 2724.0 optimize: 0.047 eval: 0.529 Elapsed: 795.641 }\n",
      "Epoch: 4 Batch_iter: 420 \n",
      " Train Loss: 0.09547855 Valid Loss: 0.11198695 \n",
      " trn_acc: 0.852 val_acc: 0.844\n",
      "spend time = { row/sec: 2685.0 optimize: 0.048 eval: 0.515 Elapsed: 798.3 }\n",
      "Epoch: 4 Batch_iter: 430 \n",
      " Train Loss: 0.094800964 Valid Loss: 0.110753074 \n",
      " trn_acc: 0.859 val_acc: 0.848\n",
      "spend time = { row/sec: 2499.0 optimize: 0.051 eval: 0.537 Elapsed: 800.456 }\n",
      "Epoch: 4 Batch_iter: 440 \n",
      " Train Loss: 0.08278622 Valid Loss: 0.11159289 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2757.0 optimize: 0.046 eval: 0.576 Elapsed: 802.62 }\n",
      "Epoch: 4 Batch_iter: 450 \n",
      " Train Loss: 0.11124222 Valid Loss: 0.11174196 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2652.0 optimize: 0.048 eval: 0.584 Elapsed: 805.48 }\n",
      "Epoch: 4 Batch_iter: 460 \n",
      " Train Loss: 0.104519114 Valid Loss: 0.117644 \n",
      " trn_acc: 0.867 val_acc: 0.836\n",
      "spend time = { row/sec: 2494.0 optimize: 0.051 eval: 0.54 Elapsed: 807.631 }\n",
      "Epoch: 4 Batch_iter: 470 \n",
      " Train Loss: 0.08216876 Valid Loss: 0.115512855 \n",
      " trn_acc: 0.914 val_acc: 0.842\n",
      "spend time = { row/sec: 2723.0 optimize: 0.047 eval: 0.577 Elapsed: 809.791 }\n",
      "Epoch: 4 Batch_iter: 480 \n",
      " Train Loss: 0.110485666 Valid Loss: 0.111441106 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2744.0 optimize: 0.047 eval: 0.534 Elapsed: 812.437 }\n",
      "Epoch: 4 Batch_iter: 490 \n",
      " Train Loss: 0.10921638 Valid Loss: 0.11237623 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2401.0 optimize: 0.053 eval: 0.51 Elapsed: 814.524 }\n",
      "Epoch: 4 Batch_iter: 500 \n",
      " Train Loss: 0.09437896 Valid Loss: 0.11404243 \n",
      " trn_acc: 0.867 val_acc: 0.841\n",
      "spend time = { row/sec: 2758.0 optimize: 0.046 eval: 0.558 Elapsed: 816.694 }\n",
      "Epoch: 4 Batch_iter: 510 \n",
      " Train Loss: 0.12716651 Valid Loss: 0.117200345 \n",
      " trn_acc: 0.82 val_acc: 0.836\n",
      "spend time = { row/sec: 2715.0 optimize: 0.047 eval: 0.555 Elapsed: 819.734 }\n",
      "Epoch: 4 Batch_iter: 520 \n",
      " Train Loss: 0.12594481 Valid Loss: 0.115281865 \n",
      " trn_acc: 0.82 val_acc: 0.838\n",
      "spend time = { row/sec: 2402.0 optimize: 0.053 eval: 0.523 Elapsed: 821.841 }\n",
      "Epoch: 4 Batch_iter: 530 \n",
      " Train Loss: 0.09849796 Valid Loss: 0.11154327 \n",
      " trn_acc: 0.859 val_acc: 0.845\n",
      "spend time = { row/sec: 2775.0 optimize: 0.046 eval: 0.546 Elapsed: 824.004 }\n",
      "Epoch: 4 Batch_iter: 540 \n",
      " Train Loss: 0.09031374 Valid Loss: 0.11156902 \n",
      " trn_acc: 0.898 val_acc: 0.849\n",
      "spend time = { row/sec: 2616.0 optimize: 0.049 eval: 0.525 Elapsed: 826.607 }\n",
      "Epoch: 4 Batch_iter: 550 \n",
      " Train Loss: 0.10197094 Valid Loss: 0.11259886 \n",
      " trn_acc: 0.852 val_acc: 0.848\n",
      "spend time = { row/sec: 2560.0 optimize: 0.05 eval: 0.574 Elapsed: 828.762 }\n",
      "Epoch: 4 Batch_iter: 560 \n",
      " Train Loss: 0.092757344 Valid Loss: 0.110893354 \n",
      " trn_acc: 0.883 val_acc: 0.848\n",
      "spend time = { row/sec: 2660.0 optimize: 0.048 eval: 0.533 Elapsed: 830.893 }\n",
      "Epoch: 4 Batch_iter: 570 \n",
      " Train Loss: 0.109153934 Valid Loss: 0.11004007 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2692.0 optimize: 0.048 eval: 0.531 Elapsed: 833.523 }\n",
      "Epoch: 4 Batch_iter: 580 \n",
      " Train Loss: 0.12080978 Valid Loss: 0.11042744 \n",
      " trn_acc: 0.828 val_acc: 0.849\n",
      "spend time = { row/sec: 2483.0 optimize: 0.052 eval: 0.574 Elapsed: 835.685 }\n",
      "Epoch: 4 Batch_iter: 590 \n",
      " Train Loss: 0.115161605 Valid Loss: 0.11088615 \n",
      " trn_acc: 0.82 val_acc: 0.847\n",
      "spend time = { row/sec: 2729.0 optimize: 0.047 eval: 0.544 Elapsed: 837.763 }\n",
      "Epoch: 4 Batch_iter: 600 \n",
      " Train Loss: 0.10189189 Valid Loss: 0.11134039 \n",
      " trn_acc: 0.844 val_acc: 0.845\n",
      "spend time = { row/sec: 2542.0 optimize: 0.05 eval: 0.545 Elapsed: 840.561 }\n",
      "Epoch: 4 Batch_iter: 610 \n",
      " Train Loss: 0.12883851 Valid Loss: 0.11216742 \n",
      " trn_acc: 0.828 val_acc: 0.847\n",
      "spend time = { row/sec: 2312.0 optimize: 0.055 eval: 0.538 Elapsed: 842.673 }\n",
      "Epoch: 4 Batch_iter: 620 \n",
      " Train Loss: 0.113837816 Valid Loss: 0.11347848 \n",
      " trn_acc: 0.828 val_acc: 0.845\n",
      "spend time = { row/sec: 2742.0 optimize: 0.047 eval: 0.548 Elapsed: 844.814 }\n",
      "Epoch: 4 Batch_iter: 630 \n",
      " Train Loss: 0.119261056 Valid Loss: 0.11905252 \n",
      " trn_acc: 0.852 val_acc: 0.833\n",
      "spend time = { row/sec: 2290.0 optimize: 0.056 eval: 0.537 Elapsed: 847.5 }\n",
      "Epoch: 4 Batch_iter: 640 \n",
      " Train Loss: 0.09010846 Valid Loss: 0.10977049 \n",
      " trn_acc: 0.891 val_acc: 0.847\n",
      "spend time = { row/sec: 2730.0 optimize: 0.047 eval: 0.52 Elapsed: 849.599 }\n",
      "Epoch: 4 Batch_iter: 650 \n",
      " Train Loss: 0.13217303 Valid Loss: 0.110789485 \n",
      " trn_acc: 0.805 val_acc: 0.847\n",
      "spend time = { row/sec: 2683.0 optimize: 0.048 eval: 0.538 Elapsed: 851.736 }\n",
      "Epoch: 4 Batch_iter: 660 \n",
      " Train Loss: 0.11619255 Valid Loss: 0.111655064 \n",
      " trn_acc: 0.836 val_acc: 0.846\n",
      "spend time = { row/sec: 2621.0 optimize: 0.049 eval: 0.526 Elapsed: 854.395 }\n",
      "Epoch: 4 Batch_iter: 670 \n",
      " Train Loss: 0.10629578 Valid Loss: 0.11008489 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2464.0 optimize: 0.052 eval: 0.53 Elapsed: 856.537 }\n",
      "Epoch: 4 Batch_iter: 680 \n",
      " Train Loss: 0.07206105 Valid Loss: 0.119598195 \n",
      " trn_acc: 0.898 val_acc: 0.833\n",
      "spend time = { row/sec: 2642.0 optimize: 0.048 eval: 0.607 Elapsed: 858.717 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Batch_iter: 690 \n",
      " Train Loss: 0.103175715 Valid Loss: 0.111420445 \n",
      " trn_acc: 0.867 val_acc: 0.846\n",
      "spend time = { row/sec: 2722.0 optimize: 0.047 eval: 0.536 Elapsed: 861.36 }\n",
      "Epoch: 4 Batch_iter: 700 \n",
      " Train Loss: 0.115284875 Valid Loss: 0.1096127 \n",
      " trn_acc: 0.844 val_acc: 0.849\n",
      "spend time = { row/sec: 2438.0 optimize: 0.052 eval: 0.568 Elapsed: 863.572 }\n",
      "Epoch: 4 Batch_iter: 710 \n",
      " Train Loss: 0.10187134 Valid Loss: 0.116349176 \n",
      " trn_acc: 0.867 val_acc: 0.839\n",
      "spend time = { row/sec: 2696.0 optimize: 0.047 eval: 0.529 Elapsed: 865.711 }\n",
      "Epoch: 4 Batch_iter: 720 \n",
      " Train Loss: 0.10512663 Valid Loss: 0.12957379 \n",
      " trn_acc: 0.867 val_acc: 0.817\n",
      "spend time = { row/sec: 2664.0 optimize: 0.048 eval: 0.543 Elapsed: 868.426 }\n",
      "Epoch: 4 Batch_iter: 730 \n",
      " Train Loss: 0.10076995 Valid Loss: 0.109803274 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2504.0 optimize: 0.051 eval: 0.525 Elapsed: 870.581 }\n",
      "Epoch: 4 Batch_iter: 740 \n",
      " Train Loss: 0.10246977 Valid Loss: 0.113822885 \n",
      " trn_acc: 0.883 val_acc: 0.842\n",
      "spend time = { row/sec: 2713.0 optimize: 0.047 eval: 0.671 Elapsed: 872.983 }\n",
      "Epoch: 4 Batch_iter: 750 \n",
      " Train Loss: 0.10281572 Valid Loss: 0.12398315 \n",
      " trn_acc: 0.828 val_acc: 0.83\n",
      "spend time = { row/sec: 2768.0 optimize: 0.046 eval: 0.533 Elapsed: 875.61 }\n",
      "Epoch: 4 Batch_iter: 760 \n",
      " Train Loss: 0.10135339 Valid Loss: 0.11144172 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2634.0 optimize: 0.049 eval: 0.586 Elapsed: 877.771 }\n",
      "Epoch: 4 Batch_iter: 770 \n",
      " Train Loss: 0.12339489 Valid Loss: 0.115643874 \n",
      " trn_acc: 0.844 val_acc: 0.838\n",
      "spend time = { row/sec: 2297.0 optimize: 0.056 eval: 0.538 Elapsed: 879.924 }\n",
      "Epoch: 4 Batch_iter: 780 \n",
      " Train Loss: 0.11268157 Valid Loss: 0.11267596 \n",
      " trn_acc: 0.828 val_acc: 0.842\n",
      "spend time = { row/sec: 2709.0 optimize: 0.047 eval: 0.537 Elapsed: 882.604 }\n",
      "Epoch: 4 Batch_iter: 790 \n",
      " Train Loss: 0.086593345 Valid Loss: 0.109187156 \n",
      " trn_acc: 0.883 val_acc: 0.848\n",
      "spend time = { row/sec: 2543.0 optimize: 0.05 eval: 0.548 Elapsed: 884.788 }\n",
      "Epoch: 4 Batch_iter: 800 \n",
      " Train Loss: 0.07793852 Valid Loss: 0.11075956 \n",
      " trn_acc: 0.922 val_acc: 0.848\n",
      "spend time = { row/sec: 2660.0 optimize: 0.048 eval: 0.538 Elapsed: 886.895 }\n",
      "Epoch: 4 Batch_iter: 810 \n",
      " Train Loss: 0.13882518 Valid Loss: 0.1169265 \n",
      " trn_acc: 0.812 val_acc: 0.837\n",
      "spend time = { row/sec: 2720.0 optimize: 0.047 eval: 0.524 Elapsed: 889.535 }\n",
      "\n",
      " Save the model : current loss  0.11325716045107284 <= 0.11417174132635993 prev loss \n",
      "\n",
      "Epoch: 5 Batch_iter: 0 \n",
      " Train Loss: 0.08133449 Valid Loss: 0.11525734 \n",
      " trn_acc: 0.898 val_acc: 0.84\n",
      "spend time = { row/sec: 2649.0 optimize: 0.048 eval: 0.542 Elapsed: 892.95 }\n",
      "Epoch: 5 Batch_iter: 10 \n",
      " Train Loss: 0.06736295 Valid Loss: 0.11003608 \n",
      " trn_acc: 0.906 val_acc: 0.849\n",
      "spend time = { row/sec: 2725.0 optimize: 0.047 eval: 0.588 Elapsed: 895.143 }\n",
      "Epoch: 5 Batch_iter: 20 \n",
      " Train Loss: 0.0669894 Valid Loss: 0.10948219 \n",
      " trn_acc: 0.945 val_acc: 0.85\n",
      "spend time = { row/sec: 2674.0 optimize: 0.048 eval: 0.56 Elapsed: 897.389 }\n",
      "Epoch: 5 Batch_iter: 30 \n",
      " Train Loss: 0.110219955 Valid Loss: 0.11016337 \n",
      " trn_acc: 0.852 val_acc: 0.849\n",
      "spend time = { row/sec: 2446.0 optimize: 0.052 eval: 0.59 Elapsed: 900.086 }\n",
      "Epoch: 5 Batch_iter: 40 \n",
      " Train Loss: 0.08168992 Valid Loss: 0.11292464 \n",
      " trn_acc: 0.883 val_acc: 0.844\n",
      "spend time = { row/sec: 2358.0 optimize: 0.054 eval: 0.549 Elapsed: 902.209 }\n",
      "Epoch: 5 Batch_iter: 50 \n",
      " Train Loss: 0.08079576 Valid Loss: 0.11461416 \n",
      " trn_acc: 0.875 val_acc: 0.842\n",
      "spend time = { row/sec: 2678.0 optimize: 0.048 eval: 0.517 Elapsed: 904.326 }\n",
      "Epoch: 5 Batch_iter: 60 \n",
      " Train Loss: 0.111477666 Valid Loss: 0.112837575 \n",
      " trn_acc: 0.812 val_acc: 0.847\n",
      "spend time = { row/sec: 2770.0 optimize: 0.046 eval: 0.597 Elapsed: 907.018 }\n",
      "Epoch: 5 Batch_iter: 70 \n",
      " Train Loss: 0.1258025 Valid Loss: 0.1344978 \n",
      " trn_acc: 0.828 val_acc: 0.819\n",
      "spend time = { row/sec: 2396.0 optimize: 0.053 eval: 0.54 Elapsed: 909.217 }\n",
      "Epoch: 5 Batch_iter: 80 \n",
      " Train Loss: 0.06898478 Valid Loss: 0.110035025 \n",
      " trn_acc: 0.914 val_acc: 0.848\n",
      "spend time = { row/sec: 2800.0 optimize: 0.046 eval: 0.527 Elapsed: 911.318 }\n",
      "Epoch: 5 Batch_iter: 90 \n",
      " Train Loss: 0.11304128 Valid Loss: 0.111393265 \n",
      " trn_acc: 0.836 val_acc: 0.845\n",
      "spend time = { row/sec: 2728.0 optimize: 0.047 eval: 0.562 Elapsed: 913.984 }\n",
      "Epoch: 5 Batch_iter: 100 \n",
      " Train Loss: 0.09116818 Valid Loss: 0.11582609 \n",
      " trn_acc: 0.867 val_acc: 0.839\n",
      "spend time = { row/sec: 2781.0 optimize: 0.046 eval: 0.558 Elapsed: 916.125 }\n",
      "Epoch: 5 Batch_iter: 110 \n",
      " Train Loss: 0.090964094 Valid Loss: 0.10980833 \n",
      " trn_acc: 0.875 val_acc: 0.848\n",
      "spend time = { row/sec: 2721.0 optimize: 0.047 eval: 0.541 Elapsed: 918.234 }\n",
      "Epoch: 5 Batch_iter: 120 \n",
      " Train Loss: 0.06917493 Valid Loss: 0.109757826 \n",
      " trn_acc: 0.906 val_acc: 0.848\n",
      "spend time = { row/sec: 2658.0 optimize: 0.048 eval: 0.557 Elapsed: 920.975 }\n",
      "Epoch: 5 Batch_iter: 130 \n",
      " Train Loss: 0.09665117 Valid Loss: 0.11383188 \n",
      " trn_acc: 0.883 val_acc: 0.843\n",
      "spend time = { row/sec: 2448.0 optimize: 0.052 eval: 0.531 Elapsed: 923.05 }\n",
      "Epoch: 5 Batch_iter: 140 \n",
      " Train Loss: 0.12196976 Valid Loss: 0.11169513 \n",
      " trn_acc: 0.836 val_acc: 0.847\n",
      "spend time = { row/sec: 2832.0 optimize: 0.045 eval: 0.543 Elapsed: 925.169 }\n",
      "Epoch: 5 Batch_iter: 150 \n",
      " Train Loss: 0.09160359 Valid Loss: 0.11469387 \n",
      " trn_acc: 0.875 val_acc: 0.845\n",
      "spend time = { row/sec: 2625.0 optimize: 0.049 eval: 0.543 Elapsed: 927.827 }\n",
      "Epoch: 5 Batch_iter: 160 \n",
      " Train Loss: 0.11941749 Valid Loss: 0.11107153 \n",
      " trn_acc: 0.828 val_acc: 0.848\n",
      "spend time = { row/sec: 2288.0 optimize: 0.056 eval: 0.553 Elapsed: 929.978 }\n",
      "Epoch: 5 Batch_iter: 170 \n",
      " Train Loss: 0.07620418 Valid Loss: 0.11079539 \n",
      " trn_acc: 0.914 val_acc: 0.845\n",
      "spend time = { row/sec: 2767.0 optimize: 0.046 eval: 0.57 Elapsed: 932.127 }\n",
      "Epoch: 5 Batch_iter: 180 \n",
      " Train Loss: 0.08719495 Valid Loss: 0.1113748 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2723.0 optimize: 0.047 eval: 0.544 Elapsed: 934.916 }\n",
      "Epoch: 5 Batch_iter: 190 \n",
      " Train Loss: 0.09990579 Valid Loss: 0.11039814 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2228.0 optimize: 0.057 eval: 0.561 Elapsed: 937.147 }\n",
      "Epoch: 5 Batch_iter: 200 \n",
      " Train Loss: 0.09018234 Valid Loss: 0.10990105 \n",
      " trn_acc: 0.883 val_acc: 0.849\n",
      "spend time = { row/sec: 2735.0 optimize: 0.047 eval: 0.571 Elapsed: 939.387 }\n",
      "Epoch: 5 Batch_iter: 210 \n",
      " Train Loss: 0.102292955 Valid Loss: 0.11062757 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2725.0 optimize: 0.047 eval: 0.55 Elapsed: 942.026 }\n",
      "Epoch: 5 Batch_iter: 220 \n",
      " Train Loss: 0.08342943 Valid Loss: 0.11036418 \n",
      " trn_acc: 0.875 val_acc: 0.848\n",
      "spend time = { row/sec: 2470.0 optimize: 0.052 eval: 0.561 Elapsed: 944.156 }\n",
      "Epoch: 5 Batch_iter: 230 \n",
      " Train Loss: 0.09348254 Valid Loss: 0.11361341 \n",
      " trn_acc: 0.898 val_acc: 0.841\n",
      "spend time = { row/sec: 2363.0 optimize: 0.054 eval: 0.599 Elapsed: 946.324 }\n",
      "Epoch: 5 Batch_iter: 240 \n",
      " Train Loss: 0.10433498 Valid Loss: 0.112116195 \n",
      " trn_acc: 0.875 val_acc: 0.841\n",
      "spend time = { row/sec: 2664.0 optimize: 0.048 eval: 0.636 Elapsed: 949.183 }\n",
      "Epoch: 5 Batch_iter: 250 \n",
      " Train Loss: 0.09252666 Valid Loss: 0.11350114 \n",
      " trn_acc: 0.883 val_acc: 0.844\n",
      "spend time = { row/sec: 2510.0 optimize: 0.051 eval: 0.535 Elapsed: 951.252 }\n",
      "Epoch: 5 Batch_iter: 260 \n",
      " Train Loss: 0.118522555 Valid Loss: 0.11458019 \n",
      " trn_acc: 0.805 val_acc: 0.842\n",
      "spend time = { row/sec: 2720.0 optimize: 0.047 eval: 0.556 Elapsed: 953.403 }\n",
      "Epoch: 5 Batch_iter: 270 \n",
      " Train Loss: 0.082132444 Valid Loss: 0.10929594 \n",
      " trn_acc: 0.891 val_acc: 0.849\n",
      "spend time = { row/sec: 2464.0 optimize: 0.052 eval: 0.54 Elapsed: 956.279 }\n",
      "Epoch: 5 Batch_iter: 280 \n",
      " Train Loss: 0.10150869 Valid Loss: 0.115508035 \n",
      " trn_acc: 0.844 val_acc: 0.84\n",
      "spend time = { row/sec: 2352.0 optimize: 0.054 eval: 0.567 Elapsed: 958.433 }\n",
      "Epoch: 5 Batch_iter: 290 \n",
      " Train Loss: 0.10890505 Valid Loss: 0.10946159 \n",
      " trn_acc: 0.852 val_acc: 0.849\n",
      "spend time = { row/sec: 2652.0 optimize: 0.048 eval: 0.535 Elapsed: 960.542 }\n",
      "Epoch: 5 Batch_iter: 300 \n",
      " Train Loss: 0.08608133 Valid Loss: 0.10951874 \n",
      " trn_acc: 0.875 val_acc: 0.851\n",
      "spend time = { row/sec: 2627.0 optimize: 0.049 eval: 0.532 Elapsed: 963.204 }\n",
      "Epoch: 5 Batch_iter: 310 \n",
      " Train Loss: 0.075042605 Valid Loss: 0.110594615 \n",
      " trn_acc: 0.891 val_acc: 0.846\n",
      "spend time = { row/sec: 2686.0 optimize: 0.048 eval: 0.525 Elapsed: 965.271 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Batch_iter: 320 \n",
      " Train Loss: 0.097957775 Valid Loss: 0.11105356 \n",
      " trn_acc: 0.883 val_acc: 0.85\n",
      "spend time = { row/sec: 2606.0 optimize: 0.049 eval: 0.52 Elapsed: 967.384 }\n",
      "Epoch: 5 Batch_iter: 330 \n",
      " Train Loss: 0.08608013 Valid Loss: 0.11462837 \n",
      " trn_acc: 0.867 val_acc: 0.846\n",
      "spend time = { row/sec: 2778.0 optimize: 0.046 eval: 0.537 Elapsed: 970.002 }\n",
      "Epoch: 5 Batch_iter: 340 \n",
      " Train Loss: 0.09514638 Valid Loss: 0.1104063 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2368.0 optimize: 0.054 eval: 0.552 Elapsed: 972.217 }\n",
      "Epoch: 5 Batch_iter: 350 \n",
      " Train Loss: 0.102976345 Valid Loss: 0.11273019 \n",
      " trn_acc: 0.867 val_acc: 0.842\n",
      "spend time = { row/sec: 2607.0 optimize: 0.049 eval: 0.547 Elapsed: 974.298 }\n",
      "Epoch: 5 Batch_iter: 360 \n",
      " Train Loss: 0.063602656 Valid Loss: 0.11139064 \n",
      " trn_acc: 0.922 val_acc: 0.848\n",
      "spend time = { row/sec: 2668.0 optimize: 0.048 eval: 0.525 Elapsed: 977.061 }\n",
      "Epoch: 5 Batch_iter: 370 \n",
      " Train Loss: 0.07450007 Valid Loss: 0.11247922 \n",
      " trn_acc: 0.875 val_acc: 0.845\n",
      "spend time = { row/sec: 2503.0 optimize: 0.051 eval: 0.567 Elapsed: 979.23 }\n",
      "Epoch: 5 Batch_iter: 380 \n",
      " Train Loss: 0.082892165 Valid Loss: 0.110827774 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2364.0 optimize: 0.054 eval: 0.541 Elapsed: 981.394 }\n",
      "Epoch: 5 Batch_iter: 390 \n",
      " Train Loss: 0.09422143 Valid Loss: 0.11204412 \n",
      " trn_acc: 0.875 val_acc: 0.849\n",
      "spend time = { row/sec: 2723.0 optimize: 0.047 eval: 0.547 Elapsed: 984.025 }\n",
      "Epoch: 5 Batch_iter: 400 \n",
      " Train Loss: 0.08719526 Valid Loss: 0.11259603 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2490.0 optimize: 0.051 eval: 0.539 Elapsed: 986.219 }\n",
      "Epoch: 5 Batch_iter: 410 \n",
      " Train Loss: 0.07658048 Valid Loss: 0.1109186 \n",
      " trn_acc: 0.914 val_acc: 0.849\n",
      "spend time = { row/sec: 2745.0 optimize: 0.047 eval: 0.619 Elapsed: 988.4 }\n",
      "Epoch: 5 Batch_iter: 420 \n",
      " Train Loss: 0.10486342 Valid Loss: 0.11095445 \n",
      " trn_acc: 0.859 val_acc: 0.846\n",
      "spend time = { row/sec: 2608.0 optimize: 0.049 eval: 0.567 Elapsed: 991.13 }\n",
      "Epoch: 5 Batch_iter: 430 \n",
      " Train Loss: 0.07428227 Valid Loss: 0.11018361 \n",
      " trn_acc: 0.914 val_acc: 0.845\n",
      "spend time = { row/sec: 2706.0 optimize: 0.047 eval: 0.527 Elapsed: 993.225 }\n",
      "Epoch: 5 Batch_iter: 440 \n",
      " Train Loss: 0.11633554 Valid Loss: 0.1118923 \n",
      " trn_acc: 0.844 val_acc: 0.846\n",
      "spend time = { row/sec: 2539.0 optimize: 0.05 eval: 0.544 Elapsed: 995.493 }\n",
      "Epoch: 5 Batch_iter: 450 \n",
      " Train Loss: 0.12611707 Valid Loss: 0.111689046 \n",
      " trn_acc: 0.812 val_acc: 0.847\n",
      "spend time = { row/sec: 2787.0 optimize: 0.046 eval: 0.562 Elapsed: 998.192 }\n",
      "Epoch: 5 Batch_iter: 460 \n",
      " Train Loss: 0.08233614 Valid Loss: 0.110009596 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2533.0 optimize: 0.051 eval: 0.526 Elapsed: 1000.313 }\n",
      "Epoch: 5 Batch_iter: 470 \n",
      " Train Loss: 0.13404867 Valid Loss: 0.11403413 \n",
      " trn_acc: 0.812 val_acc: 0.839\n",
      "spend time = { row/sec: 2660.0 optimize: 0.048 eval: 0.533 Elapsed: 1002.406 }\n",
      "Epoch: 5 Batch_iter: 480 \n",
      " Train Loss: 0.123605244 Valid Loss: 0.110686965 \n",
      " trn_acc: 0.82 val_acc: 0.847\n",
      "spend time = { row/sec: 2713.0 optimize: 0.047 eval: 0.575 Elapsed: 1005.139 }\n",
      "Epoch: 5 Batch_iter: 490 \n",
      " Train Loss: 0.07752697 Valid Loss: 0.11184514 \n",
      " trn_acc: 0.922 val_acc: 0.844\n",
      "spend time = { row/sec: 2461.0 optimize: 0.052 eval: 0.526 Elapsed: 1007.239 }\n",
      "Epoch: 5 Batch_iter: 500 \n",
      " Train Loss: 0.089083076 Valid Loss: 0.11014944 \n",
      " trn_acc: 0.867 val_acc: 0.847\n",
      "spend time = { row/sec: 2741.0 optimize: 0.047 eval: 0.522 Elapsed: 1009.402 }\n",
      "Epoch: 5 Batch_iter: 510 \n",
      " Train Loss: 0.08795408 Valid Loss: 0.11003039 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2744.0 optimize: 0.047 eval: 0.548 Elapsed: 1012.064 }\n",
      "Epoch: 5 Batch_iter: 520 \n",
      " Train Loss: 0.1090934 Valid Loss: 0.12281738 \n",
      " trn_acc: 0.852 val_acc: 0.835\n",
      "spend time = { row/sec: 2314.0 optimize: 0.055 eval: 0.561 Elapsed: 1014.197 }\n",
      "Epoch: 5 Batch_iter: 530 \n",
      " Train Loss: 0.09078482 Valid Loss: 0.11598733 \n",
      " trn_acc: 0.891 val_acc: 0.842\n",
      "spend time = { row/sec: 2797.0 optimize: 0.046 eval: 0.555 Elapsed: 1016.299 }\n",
      "Epoch: 5 Batch_iter: 540 \n",
      " Train Loss: 0.066829585 Valid Loss: 0.1105937 \n",
      " trn_acc: 0.922 val_acc: 0.846\n",
      "spend time = { row/sec: 2683.0 optimize: 0.048 eval: 0.52 Elapsed: 1018.886 }\n",
      "Epoch: 5 Batch_iter: 550 \n",
      " Train Loss: 0.112834856 Valid Loss: 0.11509093 \n",
      " trn_acc: 0.844 val_acc: 0.838\n",
      "spend time = { row/sec: 2298.0 optimize: 0.056 eval: 0.525 Elapsed: 1020.978 }\n",
      "Epoch: 5 Batch_iter: 560 \n",
      " Train Loss: 0.08783794 Valid Loss: 0.1105729 \n",
      " trn_acc: 0.875 val_acc: 0.846\n",
      "spend time = { row/sec: 2752.0 optimize: 0.046 eval: 0.577 Elapsed: 1023.114 }\n",
      "Epoch: 5 Batch_iter: 570 \n",
      " Train Loss: 0.094862275 Valid Loss: 0.110620216 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2654.0 optimize: 0.048 eval: 0.545 Elapsed: 1025.775 }\n",
      "Epoch: 5 Batch_iter: 580 \n",
      " Train Loss: 0.080371395 Valid Loss: 0.11134058 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2712.0 optimize: 0.047 eval: 0.536 Elapsed: 1027.857 }\n",
      "Epoch: 5 Batch_iter: 590 \n",
      " Train Loss: 0.09865069 Valid Loss: 0.11125103 \n",
      " trn_acc: 0.883 val_acc: 0.847\n",
      "spend time = { row/sec: 2642.0 optimize: 0.048 eval: 0.534 Elapsed: 1030.001 }\n",
      "Epoch: 5 Batch_iter: 600 \n",
      " Train Loss: 0.071538225 Valid Loss: 0.120232 \n",
      " trn_acc: 0.93 val_acc: 0.839\n",
      "spend time = { row/sec: 2801.0 optimize: 0.046 eval: 0.538 Elapsed: 1032.686 }\n",
      "Epoch: 5 Batch_iter: 610 \n",
      " Train Loss: 0.09057139 Valid Loss: 0.11237799 \n",
      " trn_acc: 0.867 val_acc: 0.843\n",
      "spend time = { row/sec: 2670.0 optimize: 0.048 eval: 0.528 Elapsed: 1034.821 }\n",
      "Epoch: 5 Batch_iter: 620 \n",
      " Train Loss: 0.08472341 Valid Loss: 0.10956788 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2758.0 optimize: 0.046 eval: 0.539 Elapsed: 1036.879 }\n",
      "Epoch: 5 Batch_iter: 630 \n",
      " Train Loss: 0.08985686 Valid Loss: 0.10971675 \n",
      " trn_acc: 0.875 val_acc: 0.85\n",
      "spend time = { row/sec: 2517.0 optimize: 0.051 eval: 0.549 Elapsed: 1039.521 }\n",
      "Epoch: 5 Batch_iter: 640 \n",
      " Train Loss: 0.0823932 Valid Loss: 0.110352404 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2464.0 optimize: 0.052 eval: 0.583 Elapsed: 1041.655 }\n",
      "Epoch: 5 Batch_iter: 650 \n",
      " Train Loss: 0.093562044 Valid Loss: 0.111611746 \n",
      " trn_acc: 0.891 val_acc: 0.846\n",
      "spend time = { row/sec: 2733.0 optimize: 0.047 eval: 0.526 Elapsed: 1043.744 }\n",
      "Epoch: 5 Batch_iter: 660 \n",
      " Train Loss: 0.08194091 Valid Loss: 0.11037919 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2782.0 optimize: 0.046 eval: 0.535 Elapsed: 1046.364 }\n",
      "Epoch: 5 Batch_iter: 670 \n",
      " Train Loss: 0.0878151 Valid Loss: 0.11102804 \n",
      " trn_acc: 0.859 val_acc: 0.845\n",
      "spend time = { row/sec: 2435.0 optimize: 0.053 eval: 0.515 Elapsed: 1048.456 }\n",
      "Epoch: 5 Batch_iter: 680 \n",
      " Train Loss: 0.11842941 Valid Loss: 0.114198275 \n",
      " trn_acc: 0.844 val_acc: 0.842\n",
      "spend time = { row/sec: 2644.0 optimize: 0.048 eval: 0.517 Elapsed: 1050.493 }\n",
      "Epoch: 5 Batch_iter: 690 \n",
      " Train Loss: 0.08757793 Valid Loss: 0.11063282 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2688.0 optimize: 0.048 eval: 0.514 Elapsed: 1053.09 }\n",
      "Epoch: 5 Batch_iter: 700 \n",
      " Train Loss: 0.09069302 Valid Loss: 0.111392625 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2311.0 optimize: 0.055 eval: 0.535 Elapsed: 1055.226 }\n",
      "Epoch: 5 Batch_iter: 710 \n",
      " Train Loss: 0.12236108 Valid Loss: 0.11072105 \n",
      " trn_acc: 0.812 val_acc: 0.85\n",
      "spend time = { row/sec: 2578.0 optimize: 0.05 eval: 0.53 Elapsed: 1057.344 }\n",
      "Epoch: 5 Batch_iter: 720 \n",
      " Train Loss: 0.10364508 Valid Loss: 0.109558724 \n",
      " trn_acc: 0.852 val_acc: 0.851\n",
      "spend time = { row/sec: 2515.0 optimize: 0.051 eval: 0.526 Elapsed: 1059.975 }\n",
      "Epoch: 5 Batch_iter: 730 \n",
      " Train Loss: 0.08521662 Valid Loss: 0.112361506 \n",
      " trn_acc: 0.891 val_acc: 0.844\n",
      "spend time = { row/sec: 2508.0 optimize: 0.051 eval: 0.491 Elapsed: 1062.022 }\n",
      "Epoch: 5 Batch_iter: 740 \n",
      " Train Loss: 0.1307066 Valid Loss: 0.11040743 \n",
      " trn_acc: 0.828 val_acc: 0.847\n",
      "spend time = { row/sec: 2490.0 optimize: 0.051 eval: 0.531 Elapsed: 1064.109 }\n",
      "Epoch: 5 Batch_iter: 750 \n",
      " Train Loss: 0.0785135 Valid Loss: 0.10975374 \n",
      " trn_acc: 0.906 val_acc: 0.848\n",
      "spend time = { row/sec: 2784.0 optimize: 0.046 eval: 0.546 Elapsed: 1066.763 }\n",
      "Epoch: 5 Batch_iter: 760 \n",
      " Train Loss: 0.08450183 Valid Loss: 0.11048449 \n",
      " trn_acc: 0.891 val_acc: 0.847\n",
      "spend time = { row/sec: 2417.0 optimize: 0.053 eval: 0.518 Elapsed: 1068.833 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Batch_iter: 770 \n",
      " Train Loss: 0.09670307 Valid Loss: 0.11198778 \n",
      " trn_acc: 0.852 val_acc: 0.845\n",
      "spend time = { row/sec: 2743.0 optimize: 0.047 eval: 0.518 Elapsed: 1070.887 }\n",
      "Epoch: 5 Batch_iter: 780 \n",
      " Train Loss: 0.1111305 Valid Loss: 0.109556526 \n",
      " trn_acc: 0.859 val_acc: 0.851\n",
      "spend time = { row/sec: 2805.0 optimize: 0.046 eval: 0.541 Elapsed: 1073.544 }\n",
      "Epoch: 5 Batch_iter: 790 \n",
      " Train Loss: 0.07854281 Valid Loss: 0.10902131 \n",
      " trn_acc: 0.914 val_acc: 0.849\n",
      "spend time = { row/sec: 2644.0 optimize: 0.048 eval: 0.509 Elapsed: 1075.588 }\n",
      "Epoch: 5 Batch_iter: 800 \n",
      " Train Loss: 0.07119894 Valid Loss: 0.110599 \n",
      " trn_acc: 0.875 val_acc: 0.851\n",
      "spend time = { row/sec: 2563.0 optimize: 0.05 eval: 0.567 Elapsed: 1077.697 }\n",
      "Epoch: 5 Batch_iter: 810 \n",
      " Train Loss: 0.11305578 Valid Loss: 0.115653515 \n",
      " trn_acc: 0.859 val_acc: 0.839\n",
      "spend time = { row/sec: 2771.0 optimize: 0.046 eval: 0.546 Elapsed: 1080.295 }\n",
      "\n",
      " Save the model : current loss  0.11245834569100045 <= 0.11325716045107284 prev loss \n",
      "\n",
      "Epoch: 6 Batch_iter: 0 \n",
      " Train Loss: 0.09708595 Valid Loss: 0.110609084 \n",
      " trn_acc: 0.883 val_acc: 0.845\n",
      "spend time = { row/sec: 2677.0 optimize: 0.048 eval: 0.54 Elapsed: 1083.198 }\n",
      "Epoch: 6 Batch_iter: 10 \n",
      " Train Loss: 0.08337326 Valid Loss: 0.112235256 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2392.0 optimize: 0.054 eval: 0.512 Elapsed: 1085.235 }\n",
      "Epoch: 6 Batch_iter: 20 \n",
      " Train Loss: 0.11485475 Valid Loss: 0.11182018 \n",
      " trn_acc: 0.852 val_acc: 0.85\n",
      "spend time = { row/sec: 2723.0 optimize: 0.047 eval: 0.526 Elapsed: 1087.354 }\n",
      "Epoch: 6 Batch_iter: 30 \n",
      " Train Loss: 0.08187722 Valid Loss: 0.1104368 \n",
      " trn_acc: 0.914 val_acc: 0.849\n",
      "spend time = { row/sec: 2700.0 optimize: 0.047 eval: 0.523 Elapsed: 1090.004 }\n",
      "Epoch: 6 Batch_iter: 40 \n",
      " Train Loss: 0.098647766 Valid Loss: 0.110121764 \n",
      " trn_acc: 0.875 val_acc: 0.85\n",
      "spend time = { row/sec: 2185.0 optimize: 0.059 eval: 0.535 Elapsed: 1092.134 }\n",
      "Epoch: 6 Batch_iter: 50 \n",
      " Train Loss: 0.08229831 Valid Loss: 0.11332287 \n",
      " trn_acc: 0.891 val_acc: 0.846\n",
      "spend time = { row/sec: 2596.0 optimize: 0.049 eval: 0.529 Elapsed: 1094.242 }\n",
      "Epoch: 6 Batch_iter: 60 \n",
      " Train Loss: 0.090275526 Valid Loss: 0.1133994 \n",
      " trn_acc: 0.898 val_acc: 0.844\n",
      "spend time = { row/sec: 2756.0 optimize: 0.046 eval: 0.52 Elapsed: 1096.846 }\n",
      "Epoch: 6 Batch_iter: 70 \n",
      " Train Loss: 0.124107465 Valid Loss: 0.11094709 \n",
      " trn_acc: 0.836 val_acc: 0.848\n",
      "spend time = { row/sec: 2289.0 optimize: 0.056 eval: 0.54 Elapsed: 1098.948 }\n",
      "Epoch: 6 Batch_iter: 80 \n",
      " Train Loss: 0.09762945 Valid Loss: 0.110581614 \n",
      " trn_acc: 0.891 val_acc: 0.847\n",
      "spend time = { row/sec: 2732.0 optimize: 0.047 eval: 0.529 Elapsed: 1101.04 }\n",
      "Epoch: 6 Batch_iter: 90 \n",
      " Train Loss: 0.08220496 Valid Loss: 0.111796275 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2696.0 optimize: 0.047 eval: 0.53 Elapsed: 1103.667 }\n",
      "Epoch: 6 Batch_iter: 100 \n",
      " Train Loss: 0.07366502 Valid Loss: 0.11273919 \n",
      " trn_acc: 0.898 val_acc: 0.846\n",
      "spend time = { row/sec: 2734.0 optimize: 0.047 eval: 0.536 Elapsed: 1105.76 }\n",
      "Epoch: 6 Batch_iter: 110 \n",
      " Train Loss: 0.12132443 Valid Loss: 0.113852344 \n",
      " trn_acc: 0.844 val_acc: 0.843\n",
      "spend time = { row/sec: 2769.0 optimize: 0.046 eval: 0.517 Elapsed: 1107.827 }\n",
      "Epoch: 6 Batch_iter: 120 \n",
      " Train Loss: 0.10209308 Valid Loss: 0.12329751 \n",
      " trn_acc: 0.875 val_acc: 0.827\n",
      "spend time = { row/sec: 2780.0 optimize: 0.046 eval: 0.517 Elapsed: 1110.446 }\n",
      "Epoch: 6 Batch_iter: 130 \n",
      " Train Loss: 0.10044936 Valid Loss: 0.11061609 \n",
      " trn_acc: 0.828 val_acc: 0.848\n",
      "spend time = { row/sec: 2640.0 optimize: 0.048 eval: 0.548 Elapsed: 1112.538 }\n",
      "Epoch: 6 Batch_iter: 140 \n",
      " Train Loss: 0.10683476 Valid Loss: 0.11394826 \n",
      " trn_acc: 0.852 val_acc: 0.844\n",
      "spend time = { row/sec: 2518.0 optimize: 0.051 eval: 0.538 Elapsed: 1114.671 }\n",
      "Epoch: 6 Batch_iter: 150 \n",
      " Train Loss: 0.09314154 Valid Loss: 0.11363465 \n",
      " trn_acc: 0.883 val_acc: 0.845\n",
      "spend time = { row/sec: 2721.0 optimize: 0.047 eval: 0.524 Elapsed: 1117.246 }\n",
      "Epoch: 6 Batch_iter: 160 \n",
      " Train Loss: 0.11503272 Valid Loss: 0.11203304 \n",
      " trn_acc: 0.812 val_acc: 0.848\n",
      "spend time = { row/sec: 2710.0 optimize: 0.047 eval: 0.557 Elapsed: 1119.333 }\n",
      "Epoch: 6 Batch_iter: 170 \n",
      " Train Loss: 0.07897889 Valid Loss: 0.11357654 \n",
      " trn_acc: 0.875 val_acc: 0.845\n",
      "spend time = { row/sec: 2807.0 optimize: 0.046 eval: 0.552 Elapsed: 1121.461 }\n",
      "Epoch: 6 Batch_iter: 180 \n",
      " Train Loss: 0.122798905 Valid Loss: 0.11310432 \n",
      " trn_acc: 0.836 val_acc: 0.846\n",
      "spend time = { row/sec: 2813.0 optimize: 0.045 eval: 0.559 Elapsed: 1124.07 }\n",
      "Epoch: 6 Batch_iter: 190 \n",
      " Train Loss: 0.09385153 Valid Loss: 0.11134261 \n",
      " trn_acc: 0.859 val_acc: 0.848\n",
      "spend time = { row/sec: 2664.0 optimize: 0.048 eval: 0.549 Elapsed: 1126.214 }\n",
      "Epoch: 6 Batch_iter: 200 \n",
      " Train Loss: 0.105999246 Valid Loss: 0.11612131 \n",
      " trn_acc: 0.828 val_acc: 0.843\n",
      "spend time = { row/sec: 2442.0 optimize: 0.052 eval: 0.526 Elapsed: 1128.296 }\n",
      "Epoch: 6 Batch_iter: 210 \n",
      " Train Loss: 0.11193523 Valid Loss: 0.11268666 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2698.0 optimize: 0.047 eval: 0.54 Elapsed: 1131.005 }\n",
      "Epoch: 6 Batch_iter: 220 \n",
      " Train Loss: 0.12272823 Valid Loss: 0.110631615 \n",
      " trn_acc: 0.82 val_acc: 0.848\n",
      "spend time = { row/sec: 2421.0 optimize: 0.053 eval: 0.513 Elapsed: 1133.038 }\n",
      "Epoch: 6 Batch_iter: 230 \n",
      " Train Loss: 0.095140696 Valid Loss: 0.11315044 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2585.0 optimize: 0.049 eval: 0.528 Elapsed: 1135.119 }\n",
      "Epoch: 6 Batch_iter: 240 \n",
      " Train Loss: 0.10918725 Valid Loss: 0.11270801 \n",
      " trn_acc: 0.836 val_acc: 0.847\n",
      "spend time = { row/sec: 2742.0 optimize: 0.047 eval: 0.514 Elapsed: 1137.695 }\n",
      "Epoch: 6 Batch_iter: 250 \n",
      " Train Loss: 0.09440195 Valid Loss: 0.11095913 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2706.0 optimize: 0.047 eval: 0.519 Elapsed: 1139.776 }\n",
      "Epoch: 6 Batch_iter: 260 \n",
      " Train Loss: 0.10110875 Valid Loss: 0.11549544 \n",
      " trn_acc: 0.883 val_acc: 0.842\n",
      "spend time = { row/sec: 2652.0 optimize: 0.048 eval: 0.516 Elapsed: 1141.901 }\n",
      "Epoch: 6 Batch_iter: 270 \n",
      " Train Loss: 0.07050704 Valid Loss: 0.110431574 \n",
      " trn_acc: 0.938 val_acc: 0.848\n",
      "spend time = { row/sec: 2469.0 optimize: 0.052 eval: 0.548 Elapsed: 1144.569 }\n",
      "Epoch: 6 Batch_iter: 280 \n",
      " Train Loss: 0.08709646 Valid Loss: 0.11437341 \n",
      " trn_acc: 0.867 val_acc: 0.844\n",
      "spend time = { row/sec: 2433.0 optimize: 0.053 eval: 0.548 Elapsed: 1146.684 }\n",
      "Epoch: 6 Batch_iter: 290 \n",
      " Train Loss: 0.1212628 Valid Loss: 0.11107765 \n",
      " trn_acc: 0.828 val_acc: 0.848\n",
      "spend time = { row/sec: 2406.0 optimize: 0.053 eval: 0.529 Elapsed: 1148.789 }\n",
      "Epoch: 6 Batch_iter: 300 \n",
      " Train Loss: 0.10625821 Valid Loss: 0.113753274 \n",
      " trn_acc: 0.836 val_acc: 0.842\n",
      "spend time = { row/sec: 2663.0 optimize: 0.048 eval: 0.52 Elapsed: 1151.432 }\n",
      "Epoch: 6 Batch_iter: 310 \n",
      " Train Loss: 0.106291145 Valid Loss: 0.111343406 \n",
      " trn_acc: 0.867 val_acc: 0.846\n",
      "spend time = { row/sec: 2664.0 optimize: 0.048 eval: 0.524 Elapsed: 1153.491 }\n",
      "Epoch: 6 Batch_iter: 320 \n",
      " Train Loss: 0.07479442 Valid Loss: 0.11043309 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2511.0 optimize: 0.051 eval: 0.529 Elapsed: 1155.587 }\n",
      "Epoch: 6 Batch_iter: 330 \n",
      " Train Loss: 0.11032827 Valid Loss: 0.11154781 \n",
      " trn_acc: 0.867 val_acc: 0.844\n",
      "spend time = { row/sec: 2708.0 optimize: 0.047 eval: 0.586 Elapsed: 1158.232 }\n",
      "Epoch: 6 Batch_iter: 340 \n",
      " Train Loss: 0.13171443 Valid Loss: 0.10966869 \n",
      " trn_acc: 0.82 val_acc: 0.848\n",
      "spend time = { row/sec: 2505.0 optimize: 0.051 eval: 0.531 Elapsed: 1160.351 }\n",
      "Epoch: 6 Batch_iter: 350 \n",
      " Train Loss: 0.1062175 Valid Loss: 0.10981758 \n",
      " trn_acc: 0.844 val_acc: 0.848\n",
      "spend time = { row/sec: 2490.0 optimize: 0.051 eval: 0.523 Elapsed: 1162.447 }\n",
      "Epoch: 6 Batch_iter: 360 \n",
      " Train Loss: 0.11366852 Valid Loss: 0.11048103 \n",
      " trn_acc: 0.836 val_acc: 0.849\n",
      "spend time = { row/sec: 2695.0 optimize: 0.047 eval: 0.532 Elapsed: 1165.062 }\n",
      "Epoch: 6 Batch_iter: 370 \n",
      " Train Loss: 0.100593306 Valid Loss: 0.11121716 \n",
      " trn_acc: 0.859 val_acc: 0.848\n",
      "spend time = { row/sec: 2319.0 optimize: 0.055 eval: 0.521 Elapsed: 1167.152 }\n",
      "Epoch: 6 Batch_iter: 380 \n",
      " Train Loss: 0.074553266 Valid Loss: 0.11205695 \n",
      " trn_acc: 0.906 val_acc: 0.85\n",
      "spend time = { row/sec: 2771.0 optimize: 0.046 eval: 0.613 Elapsed: 1169.403 }\n",
      "Epoch: 6 Batch_iter: 390 \n",
      " Train Loss: 0.119908825 Valid Loss: 0.10994528 \n",
      " trn_acc: 0.844 val_acc: 0.85\n",
      "spend time = { row/sec: 2681.0 optimize: 0.048 eval: 0.537 Elapsed: 1172.055 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Batch_iter: 400 \n",
      " Train Loss: 0.08032751 Valid Loss: 0.113704026 \n",
      " trn_acc: 0.898 val_acc: 0.844\n",
      "spend time = { row/sec: 2768.0 optimize: 0.046 eval: 0.527 Elapsed: 1174.129 }\n",
      "Epoch: 6 Batch_iter: 410 \n",
      " Train Loss: 0.11744004 Valid Loss: 0.11063331 \n",
      " trn_acc: 0.859 val_acc: 0.85\n",
      "spend time = { row/sec: 2496.0 optimize: 0.051 eval: 0.535 Elapsed: 1176.23 }\n",
      "Epoch: 6 Batch_iter: 420 \n",
      " Train Loss: 0.11368914 Valid Loss: 0.112040594 \n",
      " trn_acc: 0.852 val_acc: 0.844\n",
      "spend time = { row/sec: 2742.0 optimize: 0.047 eval: 0.525 Elapsed: 1178.855 }\n",
      "Epoch: 6 Batch_iter: 430 \n",
      " Train Loss: 0.07538034 Valid Loss: 0.1100735 \n",
      " trn_acc: 0.891 val_acc: 0.85\n",
      "spend time = { row/sec: 2554.0 optimize: 0.05 eval: 0.524 Elapsed: 1180.95 }\n",
      "Epoch: 6 Batch_iter: 440 \n",
      " Train Loss: 0.13152826 Valid Loss: 0.110134 \n",
      " trn_acc: 0.844 val_acc: 0.848\n",
      "spend time = { row/sec: 2648.0 optimize: 0.048 eval: 0.554 Elapsed: 1183.054 }\n",
      "Epoch: 6 Batch_iter: 450 \n",
      " Train Loss: 0.09123443 Valid Loss: 0.109193236 \n",
      " trn_acc: 0.883 val_acc: 0.848\n",
      "spend time = { row/sec: 2751.0 optimize: 0.047 eval: 0.533 Elapsed: 1185.695 }\n",
      "Epoch: 6 Batch_iter: 460 \n",
      " Train Loss: 0.08118628 Valid Loss: 0.110312164 \n",
      " trn_acc: 0.891 val_acc: 0.85\n",
      "spend time = { row/sec: 2735.0 optimize: 0.047 eval: 0.547 Elapsed: 1187.84 }\n",
      "Epoch: 6 Batch_iter: 470 \n",
      " Train Loss: 0.09915583 Valid Loss: 0.11750068 \n",
      " trn_acc: 0.867 val_acc: 0.838\n",
      "spend time = { row/sec: 2745.0 optimize: 0.047 eval: 0.507 Elapsed: 1189.974 }\n",
      "Epoch: 6 Batch_iter: 480 \n",
      " Train Loss: 0.10938257 Valid Loss: 0.11082892 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2757.0 optimize: 0.046 eval: 0.536 Elapsed: 1192.637 }\n",
      "Epoch: 6 Batch_iter: 490 \n",
      " Train Loss: 0.12110692 Valid Loss: 0.1120391 \n",
      " trn_acc: 0.828 val_acc: 0.843\n",
      "spend time = { row/sec: 2403.0 optimize: 0.053 eval: 0.539 Elapsed: 1194.764 }\n",
      "Epoch: 6 Batch_iter: 500 \n",
      " Train Loss: 0.14453357 Valid Loss: 0.11383819 \n",
      " trn_acc: 0.828 val_acc: 0.84\n",
      "spend time = { row/sec: 2556.0 optimize: 0.05 eval: 0.734 Elapsed: 1197.077 }\n",
      "Epoch: 6 Batch_iter: 510 \n",
      " Train Loss: 0.095808804 Valid Loss: 0.10935667 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2325.0 optimize: 0.055 eval: 0.53 Elapsed: 1199.742 }\n",
      "Epoch: 6 Batch_iter: 520 \n",
      " Train Loss: 0.08646214 Valid Loss: 0.10958929 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2483.0 optimize: 0.052 eval: 0.531 Elapsed: 1201.816 }\n",
      "Epoch: 6 Batch_iter: 530 \n",
      " Train Loss: 0.08781688 Valid Loss: 0.11766012 \n",
      " trn_acc: 0.883 val_acc: 0.842\n",
      "spend time = { row/sec: 2649.0 optimize: 0.048 eval: 0.544 Elapsed: 1203.993 }\n",
      "Epoch: 6 Batch_iter: 540 \n",
      " Train Loss: 0.09406353 Valid Loss: 0.11198068 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2543.0 optimize: 0.05 eval: 0.534 Elapsed: 1206.67 }\n",
      "Epoch: 6 Batch_iter: 550 \n",
      " Train Loss: 0.09272271 Valid Loss: 0.111751646 \n",
      " trn_acc: 0.859 val_acc: 0.846\n",
      "spend time = { row/sec: 2157.0 optimize: 0.059 eval: 0.532 Elapsed: 1208.836 }\n",
      "Epoch: 6 Batch_iter: 560 \n",
      " Train Loss: 0.097750366 Valid Loss: 0.11107278 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2646.0 optimize: 0.048 eval: 0.546 Elapsed: 1210.916 }\n",
      "Epoch: 6 Batch_iter: 570 \n",
      " Train Loss: 0.093580484 Valid Loss: 0.11522191 \n",
      " trn_acc: 0.875 val_acc: 0.842\n",
      "spend time = { row/sec: 2587.0 optimize: 0.049 eval: 0.522 Elapsed: 1213.655 }\n",
      "Epoch: 6 Batch_iter: 580 \n",
      " Train Loss: 0.11458391 Valid Loss: 0.11085942 \n",
      " trn_acc: 0.844 val_acc: 0.849\n",
      "spend time = { row/sec: 2461.0 optimize: 0.052 eval: 0.574 Elapsed: 1215.783 }\n",
      "Epoch: 6 Batch_iter: 590 \n",
      " Train Loss: 0.08084609 Valid Loss: 0.116116844 \n",
      " trn_acc: 0.891 val_acc: 0.84\n",
      "spend time = { row/sec: 2645.0 optimize: 0.048 eval: 0.635 Elapsed: 1217.978 }\n",
      "Epoch: 6 Batch_iter: 600 \n",
      " Train Loss: 0.095102474 Valid Loss: 0.112915464 \n",
      " trn_acc: 0.867 val_acc: 0.843\n",
      "spend time = { row/sec: 2793.0 optimize: 0.046 eval: 0.511 Elapsed: 1220.606 }\n",
      "Epoch: 6 Batch_iter: 610 \n",
      " Train Loss: 0.085638195 Valid Loss: 0.10862458 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2511.0 optimize: 0.051 eval: 0.527 Elapsed: 1222.693 }\n",
      "Epoch: 6 Batch_iter: 620 \n",
      " Train Loss: 0.10928221 Valid Loss: 0.109729625 \n",
      " trn_acc: 0.875 val_acc: 0.85\n",
      "spend time = { row/sec: 2723.0 optimize: 0.047 eval: 0.524 Elapsed: 1224.799 }\n",
      "Epoch: 6 Batch_iter: 630 \n",
      " Train Loss: 0.090116546 Valid Loss: 0.10956054 \n",
      " trn_acc: 0.883 val_acc: 0.849\n",
      "spend time = { row/sec: 2730.0 optimize: 0.047 eval: 0.539 Elapsed: 1227.438 }\n",
      "Epoch: 6 Batch_iter: 640 \n",
      " Train Loss: 0.09581714 Valid Loss: 0.11238608 \n",
      " trn_acc: 0.875 val_acc: 0.844\n",
      "spend time = { row/sec: 2412.0 optimize: 0.053 eval: 0.529 Elapsed: 1229.58 }\n",
      "Epoch: 6 Batch_iter: 650 \n",
      " Train Loss: 0.08053561 Valid Loss: 0.10940904 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2671.0 optimize: 0.048 eval: 0.535 Elapsed: 1231.704 }\n",
      "Epoch: 6 Batch_iter: 660 \n",
      " Train Loss: 0.097704634 Valid Loss: 0.12296186 \n",
      " trn_acc: 0.859 val_acc: 0.836\n",
      "spend time = { row/sec: 2745.0 optimize: 0.047 eval: 0.52 Elapsed: 1234.329 }\n",
      "Epoch: 6 Batch_iter: 670 \n",
      " Train Loss: 0.07504877 Valid Loss: 0.11229908 \n",
      " trn_acc: 0.906 val_acc: 0.847\n",
      "spend time = { row/sec: 2568.0 optimize: 0.05 eval: 0.526 Elapsed: 1236.387 }\n",
      "Epoch: 6 Batch_iter: 680 \n",
      " Train Loss: 0.08871877 Valid Loss: 0.11035634 \n",
      " trn_acc: 0.891 val_acc: 0.847\n",
      "spend time = { row/sec: 2682.0 optimize: 0.048 eval: 0.539 Elapsed: 1238.478 }\n",
      "Epoch: 6 Batch_iter: 690 \n",
      " Train Loss: 0.06382953 Valid Loss: 0.109172784 \n",
      " trn_acc: 0.938 val_acc: 0.849\n",
      "spend time = { row/sec: 2715.0 optimize: 0.047 eval: 0.545 Elapsed: 1241.242 }\n",
      "Epoch: 6 Batch_iter: 700 \n",
      " Train Loss: 0.116237946 Valid Loss: 0.11219176 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2518.0 optimize: 0.051 eval: 0.568 Elapsed: 1243.409 }\n",
      "Epoch: 6 Batch_iter: 710 \n",
      " Train Loss: 0.07785127 Valid Loss: 0.10909642 \n",
      " trn_acc: 0.906 val_acc: 0.849\n",
      "spend time = { row/sec: 2283.0 optimize: 0.056 eval: 0.545 Elapsed: 1245.722 }\n",
      "Epoch: 6 Batch_iter: 720 \n",
      " Train Loss: 0.08633733 Valid Loss: 0.1106715 \n",
      " trn_acc: 0.898 val_acc: 0.849\n",
      "spend time = { row/sec: 2680.0 optimize: 0.048 eval: 0.526 Elapsed: 1248.372 }\n",
      "Epoch: 6 Batch_iter: 730 \n",
      " Train Loss: 0.104999565 Valid Loss: 0.11080755 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2565.0 optimize: 0.05 eval: 0.521 Elapsed: 1250.475 }\n",
      "Epoch: 6 Batch_iter: 740 \n",
      " Train Loss: 0.09543172 Valid Loss: 0.10959037 \n",
      " trn_acc: 0.859 val_acc: 0.849\n",
      "spend time = { row/sec: 2621.0 optimize: 0.049 eval: 0.526 Elapsed: 1252.616 }\n",
      "Epoch: 6 Batch_iter: 750 \n",
      " Train Loss: 0.09336335 Valid Loss: 0.10813231 \n",
      " trn_acc: 0.883 val_acc: 0.85\n",
      "spend time = { row/sec: 2665.0 optimize: 0.048 eval: 0.551 Elapsed: 1255.337 }\n",
      "Epoch: 6 Batch_iter: 760 \n",
      " Train Loss: 0.0859702 Valid Loss: 0.10816614 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2612.0 optimize: 0.049 eval: 0.564 Elapsed: 1257.465 }\n",
      "Epoch: 6 Batch_iter: 770 \n",
      " Train Loss: 0.06023074 Valid Loss: 0.11076445 \n",
      " trn_acc: 0.922 val_acc: 0.849\n",
      "spend time = { row/sec: 2589.0 optimize: 0.049 eval: 0.528 Elapsed: 1259.56 }\n",
      "Epoch: 6 Batch_iter: 780 \n",
      " Train Loss: 0.09190439 Valid Loss: 0.12769987 \n",
      " trn_acc: 0.875 val_acc: 0.828\n",
      "spend time = { row/sec: 2806.0 optimize: 0.046 eval: 0.551 Elapsed: 1262.221 }\n",
      "Epoch: 6 Batch_iter: 790 \n",
      " Train Loss: 0.10888498 Valid Loss: 0.111035496 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2329.0 optimize: 0.055 eval: 0.519 Elapsed: 1264.343 }\n",
      "Epoch: 6 Batch_iter: 800 \n",
      " Train Loss: 0.10675104 Valid Loss: 0.11516191 \n",
      " trn_acc: 0.828 val_acc: 0.84\n",
      "spend time = { row/sec: 2835.0 optimize: 0.045 eval: 0.604 Elapsed: 1266.511 }\n",
      "Epoch: 6 Batch_iter: 810 \n",
      " Train Loss: 0.07412106 Valid Loss: 0.11908867 \n",
      " trn_acc: 0.898 val_acc: 0.837\n",
      "spend time = { row/sec: 2834.0 optimize: 0.045 eval: 0.529 Elapsed: 1269.278 }\n",
      "\n",
      " Save the model : current loss  0.11220771055260714 <= 0.11245834569100045 prev loss \n",
      "\n",
      "Epoch: 7 Batch_iter: 0 \n",
      " Train Loss: 0.07643118 Valid Loss: 0.11159544 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2576.0 optimize: 0.05 eval: 0.58 Elapsed: 1272.823 }\n",
      "Epoch: 7 Batch_iter: 10 \n",
      " Train Loss: 0.114932664 Valid Loss: 0.117327005 \n",
      " trn_acc: 0.852 val_acc: 0.838\n",
      "spend time = { row/sec: 2468.0 optimize: 0.052 eval: 0.612 Elapsed: 1275.022 }\n",
      "Epoch: 7 Batch_iter: 20 \n",
      " Train Loss: 0.07616468 Valid Loss: 0.10946327 \n",
      " trn_acc: 0.898 val_acc: 0.851\n",
      "spend time = { row/sec: 2541.0 optimize: 0.05 eval: 0.539 Elapsed: 1277.155 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Batch_iter: 30 \n",
      " Train Loss: 0.07516505 Valid Loss: 0.110232964 \n",
      " trn_acc: 0.93 val_acc: 0.85\n",
      "spend time = { row/sec: 2649.0 optimize: 0.048 eval: 0.514 Elapsed: 1280.008 }\n",
      "Epoch: 7 Batch_iter: 40 \n",
      " Train Loss: 0.075590216 Valid Loss: 0.113606155 \n",
      " trn_acc: 0.914 val_acc: 0.848\n",
      "spend time = { row/sec: 2452.0 optimize: 0.052 eval: 0.555 Elapsed: 1282.145 }\n",
      "Epoch: 7 Batch_iter: 50 \n",
      " Train Loss: 0.08429375 Valid Loss: 0.11387999 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2596.0 optimize: 0.049 eval: 0.52 Elapsed: 1284.324 }\n",
      "Epoch: 7 Batch_iter: 60 \n",
      " Train Loss: 0.11641014 Valid Loss: 0.12781806 \n",
      " trn_acc: 0.859 val_acc: 0.831\n",
      "spend time = { row/sec: 2359.0 optimize: 0.054 eval: 0.535 Elapsed: 1286.948 }\n",
      "Epoch: 7 Batch_iter: 70 \n",
      " Train Loss: 0.10257378 Valid Loss: 0.118319094 \n",
      " trn_acc: 0.844 val_acc: 0.835\n",
      "spend time = { row/sec: 2299.0 optimize: 0.056 eval: 0.569 Elapsed: 1289.128 }\n",
      "Epoch: 7 Batch_iter: 80 \n",
      " Train Loss: 0.10001368 Valid Loss: 0.109480895 \n",
      " trn_acc: 0.875 val_acc: 0.851\n",
      "spend time = { row/sec: 2707.0 optimize: 0.047 eval: 0.574 Elapsed: 1291.257 }\n",
      "Epoch: 7 Batch_iter: 90 \n",
      " Train Loss: 0.08026484 Valid Loss: 0.108991034 \n",
      " trn_acc: 0.898 val_acc: 0.851\n",
      "spend time = { row/sec: 2722.0 optimize: 0.047 eval: 0.524 Elapsed: 1293.948 }\n",
      "Epoch: 7 Batch_iter: 100 \n",
      " Train Loss: 0.09093418 Valid Loss: 0.11082393 \n",
      " trn_acc: 0.914 val_acc: 0.849\n",
      "spend time = { row/sec: 2538.0 optimize: 0.05 eval: 0.521 Elapsed: 1296.026 }\n",
      "Epoch: 7 Batch_iter: 110 \n",
      " Train Loss: 0.061609376 Valid Loss: 0.11029072 \n",
      " trn_acc: 0.93 val_acc: 0.851\n",
      "spend time = { row/sec: 2693.0 optimize: 0.048 eval: 0.534 Elapsed: 1298.109 }\n",
      "Epoch: 7 Batch_iter: 120 \n",
      " Train Loss: 0.09522424 Valid Loss: 0.10948164 \n",
      " trn_acc: 0.875 val_acc: 0.851\n",
      "spend time = { row/sec: 2690.0 optimize: 0.048 eval: 0.577 Elapsed: 1300.808 }\n",
      "Epoch: 7 Batch_iter: 130 \n",
      " Train Loss: 0.10511789 Valid Loss: 0.11167161 \n",
      " trn_acc: 0.852 val_acc: 0.845\n",
      "spend time = { row/sec: 2400.0 optimize: 0.053 eval: 0.53 Elapsed: 1302.942 }\n",
      "Epoch: 7 Batch_iter: 140 \n",
      " Train Loss: 0.05863199 Valid Loss: 0.110533796 \n",
      " trn_acc: 0.938 val_acc: 0.848\n",
      "spend time = { row/sec: 2736.0 optimize: 0.047 eval: 0.526 Elapsed: 1305.062 }\n",
      "Epoch: 7 Batch_iter: 150 \n",
      " Train Loss: 0.09689466 Valid Loss: 0.11414617 \n",
      " trn_acc: 0.883 val_acc: 0.847\n",
      "spend time = { row/sec: 2746.0 optimize: 0.047 eval: 0.543 Elapsed: 1307.721 }\n",
      "Epoch: 7 Batch_iter: 160 \n",
      " Train Loss: 0.10278578 Valid Loss: 0.11259559 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2128.0 optimize: 0.06 eval: 0.542 Elapsed: 1309.854 }\n",
      "Epoch: 7 Batch_iter: 170 \n",
      " Train Loss: 0.093097925 Valid Loss: 0.11175704 \n",
      " trn_acc: 0.906 val_acc: 0.845\n",
      "spend time = { row/sec: 2737.0 optimize: 0.047 eval: 0.546 Elapsed: 1311.983 }\n",
      "Epoch: 7 Batch_iter: 180 \n",
      " Train Loss: 0.082315885 Valid Loss: 0.11293425 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2725.0 optimize: 0.047 eval: 0.52 Elapsed: 1314.699 }\n",
      "Epoch: 7 Batch_iter: 190 \n",
      " Train Loss: 0.08836553 Valid Loss: 0.11219551 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2213.0 optimize: 0.058 eval: 0.579 Elapsed: 1316.843 }\n",
      "Epoch: 7 Batch_iter: 200 \n",
      " Train Loss: 0.09960172 Valid Loss: 0.13024078 \n",
      " trn_acc: 0.867 val_acc: 0.824\n",
      "spend time = { row/sec: 2756.0 optimize: 0.046 eval: 0.522 Elapsed: 1318.983 }\n",
      "Epoch: 7 Batch_iter: 210 \n",
      " Train Loss: 0.115911976 Valid Loss: 0.11701007 \n",
      " trn_acc: 0.859 val_acc: 0.84\n",
      "spend time = { row/sec: 2677.0 optimize: 0.048 eval: 0.525 Elapsed: 1321.603 }\n",
      "Epoch: 7 Batch_iter: 220 \n",
      " Train Loss: 0.0681296 Valid Loss: 0.10998259 \n",
      " trn_acc: 0.922 val_acc: 0.849\n",
      "spend time = { row/sec: 2365.0 optimize: 0.054 eval: 0.542 Elapsed: 1323.711 }\n",
      "Epoch: 7 Batch_iter: 230 \n",
      " Train Loss: 0.09572673 Valid Loss: 0.11042811 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2660.0 optimize: 0.048 eval: 0.558 Elapsed: 1325.824 }\n",
      "Epoch: 7 Batch_iter: 240 \n",
      " Train Loss: 0.09124397 Valid Loss: 0.11164883 \n",
      " trn_acc: 0.867 val_acc: 0.85\n",
      "spend time = { row/sec: 2575.0 optimize: 0.05 eval: 0.526 Elapsed: 1328.511 }\n",
      "Epoch: 7 Batch_iter: 250 \n",
      " Train Loss: 0.070913 Valid Loss: 0.1119639 \n",
      " trn_acc: 0.898 val_acc: 0.85\n",
      "spend time = { row/sec: 2496.0 optimize: 0.051 eval: 0.536 Elapsed: 1330.698 }\n",
      "Epoch: 7 Batch_iter: 260 \n",
      " Train Loss: 0.112874165 Valid Loss: 0.11071262 \n",
      " trn_acc: 0.859 val_acc: 0.849\n",
      "spend time = { row/sec: 2675.0 optimize: 0.048 eval: 0.533 Elapsed: 1332.852 }\n",
      "Epoch: 7 Batch_iter: 270 \n",
      " Train Loss: 0.05938566 Valid Loss: 0.11147954 \n",
      " trn_acc: 0.938 val_acc: 0.847\n",
      "spend time = { row/sec: 2773.0 optimize: 0.046 eval: 0.585 Elapsed: 1335.615 }\n",
      "Epoch: 7 Batch_iter: 280 \n",
      " Train Loss: 0.0868607 Valid Loss: 0.11278794 \n",
      " trn_acc: 0.891 val_acc: 0.845\n",
      "spend time = { row/sec: 2447.0 optimize: 0.052 eval: 0.559 Elapsed: 1337.731 }\n",
      "Epoch: 7 Batch_iter: 290 \n",
      " Train Loss: 0.08845703 Valid Loss: 0.11803985 \n",
      " trn_acc: 0.867 val_acc: 0.839\n",
      "spend time = { row/sec: 2823.0 optimize: 0.045 eval: 0.565 Elapsed: 1339.88 }\n",
      "Epoch: 7 Batch_iter: 300 \n",
      " Train Loss: 0.06042094 Valid Loss: 0.12767138 \n",
      " trn_acc: 0.922 val_acc: 0.827\n",
      "spend time = { row/sec: 2737.0 optimize: 0.047 eval: 0.53 Elapsed: 1342.502 }\n",
      "Epoch: 7 Batch_iter: 310 \n",
      " Train Loss: 0.08298327 Valid Loss: 0.11017497 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2529.0 optimize: 0.051 eval: 0.536 Elapsed: 1344.629 }\n",
      "Epoch: 7 Batch_iter: 320 \n",
      " Train Loss: 0.09960401 Valid Loss: 0.11008345 \n",
      " trn_acc: 0.836 val_acc: 0.849\n",
      "spend time = { row/sec: 2759.0 optimize: 0.046 eval: 0.549 Elapsed: 1346.956 }\n",
      "Epoch: 7 Batch_iter: 330 \n",
      " Train Loss: 0.08218441 Valid Loss: 0.11013078 \n",
      " trn_acc: 0.875 val_acc: 0.848\n",
      "spend time = { row/sec: 2801.0 optimize: 0.046 eval: 0.525 Elapsed: 1349.615 }\n",
      "Epoch: 7 Batch_iter: 340 \n",
      " Train Loss: 0.11916814 Valid Loss: 0.10955905 \n",
      " trn_acc: 0.844 val_acc: 0.848\n",
      "spend time = { row/sec: 2453.0 optimize: 0.052 eval: 0.564 Elapsed: 1351.738 }\n",
      "Epoch: 7 Batch_iter: 350 \n",
      " Train Loss: 0.079956435 Valid Loss: 0.11063192 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2481.0 optimize: 0.052 eval: 0.523 Elapsed: 1353.855 }\n",
      "Epoch: 7 Batch_iter: 360 \n",
      " Train Loss: 0.099072635 Valid Loss: 0.112092465 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2754.0 optimize: 0.046 eval: 0.52 Elapsed: 1356.477 }\n",
      "Epoch: 7 Batch_iter: 370 \n",
      " Train Loss: 0.10672219 Valid Loss: 0.11976208 \n",
      " trn_acc: 0.867 val_acc: 0.836\n",
      "spend time = { row/sec: 2385.0 optimize: 0.054 eval: 0.599 Elapsed: 1358.623 }\n",
      "Epoch: 7 Batch_iter: 380 \n",
      " Train Loss: 0.104804866 Valid Loss: 0.11448512 \n",
      " trn_acc: 0.875 val_acc: 0.845\n",
      "spend time = { row/sec: 2684.0 optimize: 0.048 eval: 0.531 Elapsed: 1360.735 }\n",
      "Epoch: 7 Batch_iter: 390 \n",
      " Train Loss: 0.09215818 Valid Loss: 0.11011948 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2659.0 optimize: 0.048 eval: 0.547 Elapsed: 1363.379 }\n",
      "Epoch: 7 Batch_iter: 400 \n",
      " Train Loss: 0.08671422 Valid Loss: 0.10998457 \n",
      " trn_acc: 0.883 val_acc: 0.848\n",
      "spend time = { row/sec: 2679.0 optimize: 0.048 eval: 0.513 Elapsed: 1365.48 }\n",
      "Epoch: 7 Batch_iter: 410 \n",
      " Train Loss: 0.06432141 Valid Loss: 0.11038649 \n",
      " trn_acc: 0.906 val_acc: 0.85\n",
      "spend time = { row/sec: 2693.0 optimize: 0.048 eval: 0.546 Elapsed: 1367.541 }\n",
      "Epoch: 7 Batch_iter: 420 \n",
      " Train Loss: 0.09142911 Valid Loss: 0.11085997 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2628.0 optimize: 0.049 eval: 0.537 Elapsed: 1370.244 }\n",
      "Epoch: 7 Batch_iter: 430 \n",
      " Train Loss: 0.099208504 Valid Loss: 0.11740187 \n",
      " trn_acc: 0.852 val_acc: 0.838\n",
      "spend time = { row/sec: 2648.0 optimize: 0.048 eval: 0.56 Elapsed: 1372.391 }\n",
      "Epoch: 7 Batch_iter: 440 \n",
      " Train Loss: 0.1143614 Valid Loss: 0.11049384 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2626.0 optimize: 0.049 eval: 0.581 Elapsed: 1374.611 }\n",
      "Epoch: 7 Batch_iter: 450 \n",
      " Train Loss: 0.09339465 Valid Loss: 0.11741121 \n",
      " trn_acc: 0.883 val_acc: 0.839\n",
      "spend time = { row/sec: 2774.0 optimize: 0.046 eval: 0.559 Elapsed: 1377.262 }\n",
      "Epoch: 7 Batch_iter: 460 \n",
      " Train Loss: 0.098476276 Valid Loss: 0.11262258 \n",
      " trn_acc: 0.867 val_acc: 0.847\n",
      "spend time = { row/sec: 2416.0 optimize: 0.053 eval: 0.689 Elapsed: 1379.5 }\n",
      "Epoch: 7 Batch_iter: 470 \n",
      " Train Loss: 0.084724054 Valid Loss: 0.11242995 \n",
      " trn_acc: 0.883 val_acc: 0.845\n",
      "spend time = { row/sec: 2780.0 optimize: 0.046 eval: 0.515 Elapsed: 1381.614 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Batch_iter: 480 \n",
      " Train Loss: 0.103255205 Valid Loss: 0.10903087 \n",
      " trn_acc: 0.859 val_acc: 0.847\n",
      "spend time = { row/sec: 2734.0 optimize: 0.047 eval: 0.543 Elapsed: 1384.287 }\n",
      "Epoch: 7 Batch_iter: 490 \n",
      " Train Loss: 0.12845698 Valid Loss: 0.10972373 \n",
      " trn_acc: 0.82 val_acc: 0.849\n",
      "spend time = { row/sec: 2600.0 optimize: 0.049 eval: 0.549 Elapsed: 1386.453 }\n",
      "Epoch: 7 Batch_iter: 500 \n",
      " Train Loss: 0.08982992 Valid Loss: 0.110193826 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2578.0 optimize: 0.05 eval: 0.502 Elapsed: 1388.536 }\n",
      "Epoch: 7 Batch_iter: 510 \n",
      " Train Loss: 0.10480264 Valid Loss: 0.11088042 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2765.0 optimize: 0.046 eval: 0.539 Elapsed: 1391.143 }\n",
      "Epoch: 7 Batch_iter: 520 \n",
      " Train Loss: 0.10976503 Valid Loss: 0.1143513 \n",
      " trn_acc: 0.812 val_acc: 0.844\n",
      "spend time = { row/sec: 2176.0 optimize: 0.059 eval: 0.583 Elapsed: 1393.953 }\n",
      "Epoch: 7 Batch_iter: 530 \n",
      " Train Loss: 0.05238349 Valid Loss: 0.11013213 \n",
      " trn_acc: 0.93 val_acc: 0.847\n",
      "spend time = { row/sec: 2437.0 optimize: 0.053 eval: 0.552 Elapsed: 1396.074 }\n",
      "Epoch: 7 Batch_iter: 540 \n",
      " Train Loss: 0.079501405 Valid Loss: 0.11054211 \n",
      " trn_acc: 0.883 val_acc: 0.849\n",
      "spend time = { row/sec: 2759.0 optimize: 0.046 eval: 0.516 Elapsed: 1398.698 }\n",
      "Epoch: 7 Batch_iter: 550 \n",
      " Train Loss: 0.11337572 Valid Loss: 0.10998935 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2143.0 optimize: 0.06 eval: 0.521 Elapsed: 1400.804 }\n",
      "Epoch: 7 Batch_iter: 560 \n",
      " Train Loss: 0.090920135 Valid Loss: 0.11304148 \n",
      " trn_acc: 0.883 val_acc: 0.844\n",
      "spend time = { row/sec: 2584.0 optimize: 0.05 eval: 0.544 Elapsed: 1402.916 }\n",
      "Epoch: 7 Batch_iter: 570 \n",
      " Train Loss: 0.056388926 Valid Loss: 0.11125109 \n",
      " trn_acc: 0.945 val_acc: 0.848\n",
      "spend time = { row/sec: 2690.0 optimize: 0.048 eval: 0.604 Elapsed: 1405.602 }\n",
      "Epoch: 7 Batch_iter: 580 \n",
      " Train Loss: 0.07410067 Valid Loss: 0.11056142 \n",
      " trn_acc: 0.914 val_acc: 0.85\n",
      "spend time = { row/sec: 2745.0 optimize: 0.047 eval: 0.565 Elapsed: 1407.777 }\n",
      "Epoch: 7 Batch_iter: 590 \n",
      " Train Loss: 0.08175932 Valid Loss: 0.11177775 \n",
      " trn_acc: 0.906 val_acc: 0.849\n",
      "spend time = { row/sec: 2800.0 optimize: 0.046 eval: 0.54 Elapsed: 1409.92 }\n",
      "Epoch: 7 Batch_iter: 600 \n",
      " Train Loss: 0.12610301 Valid Loss: 0.117614955 \n",
      " trn_acc: 0.805 val_acc: 0.837\n",
      "spend time = { row/sec: 2718.0 optimize: 0.047 eval: 1.502 Elapsed: 1413.499 }\n",
      "Epoch: 7 Batch_iter: 610 \n",
      " Train Loss: 0.08609817 Valid Loss: 0.10941486 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2583.0 optimize: 0.05 eval: 0.539 Elapsed: 1415.592 }\n",
      "Epoch: 7 Batch_iter: 620 \n",
      " Train Loss: 0.10098651 Valid Loss: 0.11277381 \n",
      " trn_acc: 0.875 val_acc: 0.848\n",
      "spend time = { row/sec: 2734.0 optimize: 0.047 eval: 0.57 Elapsed: 1417.755 }\n",
      "Epoch: 7 Batch_iter: 630 \n",
      " Train Loss: 0.08119069 Valid Loss: 0.11623371 \n",
      " trn_acc: 0.883 val_acc: 0.843\n",
      "spend time = { row/sec: 2727.0 optimize: 0.047 eval: 0.526 Elapsed: 1420.403 }\n",
      "Epoch: 7 Batch_iter: 640 \n",
      " Train Loss: 0.10054399 Valid Loss: 0.11768856 \n",
      " trn_acc: 0.883 val_acc: 0.842\n",
      "spend time = { row/sec: 2496.0 optimize: 0.051 eval: 0.54 Elapsed: 1422.516 }\n",
      "Epoch: 7 Batch_iter: 650 \n",
      " Train Loss: 0.10499391 Valid Loss: 0.10959511 \n",
      " trn_acc: 0.883 val_acc: 0.849\n",
      "spend time = { row/sec: 2747.0 optimize: 0.047 eval: 0.618 Elapsed: 1424.745 }\n",
      "Epoch: 7 Batch_iter: 660 \n",
      " Train Loss: 0.098784685 Valid Loss: 0.11040472 \n",
      " trn_acc: 0.867 val_acc: 0.847\n",
      "spend time = { row/sec: 2815.0 optimize: 0.045 eval: 0.52 Elapsed: 1427.392 }\n",
      "Epoch: 7 Batch_iter: 670 \n",
      " Train Loss: 0.07621268 Valid Loss: 0.109644465 \n",
      " trn_acc: 0.906 val_acc: 0.846\n",
      "spend time = { row/sec: 2551.0 optimize: 0.05 eval: 0.564 Elapsed: 1429.565 }\n",
      "Epoch: 7 Batch_iter: 680 \n",
      " Train Loss: 0.115894735 Valid Loss: 0.11986501 \n",
      " trn_acc: 0.859 val_acc: 0.837\n",
      "spend time = { row/sec: 2542.0 optimize: 0.05 eval: 0.55 Elapsed: 1431.668 }\n",
      "Epoch: 7 Batch_iter: 690 \n",
      " Train Loss: 0.10174208 Valid Loss: 0.112715885 \n",
      " trn_acc: 0.844 val_acc: 0.846\n",
      "spend time = { row/sec: 2648.0 optimize: 0.048 eval: 0.557 Elapsed: 1434.409 }\n",
      "Epoch: 7 Batch_iter: 700 \n",
      " Train Loss: 0.09371591 Valid Loss: 0.11144976 \n",
      " trn_acc: 0.891 val_acc: 0.847\n",
      "spend time = { row/sec: 2441.0 optimize: 0.052 eval: 0.548 Elapsed: 1436.523 }\n",
      "Epoch: 7 Batch_iter: 710 \n",
      " Train Loss: 0.14871448 Valid Loss: 0.11063278 \n",
      " trn_acc: 0.805 val_acc: 0.848\n",
      "spend time = { row/sec: 2577.0 optimize: 0.05 eval: 0.545 Elapsed: 1438.703 }\n",
      "Epoch: 7 Batch_iter: 720 \n",
      " Train Loss: 0.106085695 Valid Loss: 0.1084326 \n",
      " trn_acc: 0.852 val_acc: 0.85\n",
      "spend time = { row/sec: 2749.0 optimize: 0.047 eval: 0.52 Elapsed: 1441.323 }\n",
      "Epoch: 7 Batch_iter: 730 \n",
      " Train Loss: 0.071531236 Valid Loss: 0.11105421 \n",
      " trn_acc: 0.914 val_acc: 0.845\n",
      "spend time = { row/sec: 2757.0 optimize: 0.046 eval: 0.547 Elapsed: 1443.475 }\n",
      "Epoch: 7 Batch_iter: 740 \n",
      " Train Loss: 0.10928168 Valid Loss: 0.10967084 \n",
      " trn_acc: 0.867 val_acc: 0.85\n",
      "spend time = { row/sec: 2579.0 optimize: 0.05 eval: 0.515 Elapsed: 1445.558 }\n",
      "Epoch: 7 Batch_iter: 750 \n",
      " Train Loss: 0.100569956 Valid Loss: 0.110368036 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2758.0 optimize: 0.046 eval: 0.589 Elapsed: 1448.24 }\n",
      "Epoch: 7 Batch_iter: 760 \n",
      " Train Loss: 0.12071259 Valid Loss: 0.110739775 \n",
      " trn_acc: 0.836 val_acc: 0.847\n",
      "spend time = { row/sec: 2324.0 optimize: 0.055 eval: 0.54 Elapsed: 1450.477 }\n",
      "Epoch: 7 Batch_iter: 770 \n",
      " Train Loss: 0.105029814 Valid Loss: 0.109996885 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2673.0 optimize: 0.048 eval: 0.538 Elapsed: 1452.608 }\n",
      "Epoch: 7 Batch_iter: 780 \n",
      " Train Loss: 0.10480143 Valid Loss: 0.108509734 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2616.0 optimize: 0.049 eval: 0.561 Elapsed: 1455.29 }\n",
      "Epoch: 7 Batch_iter: 790 \n",
      " Train Loss: 0.0986907 Valid Loss: 0.11222132 \n",
      " trn_acc: 0.859 val_acc: 0.845\n",
      "spend time = { row/sec: 2615.0 optimize: 0.049 eval: 0.603 Elapsed: 1457.44 }\n",
      "Epoch: 7 Batch_iter: 800 \n",
      " Train Loss: 0.087216154 Valid Loss: 0.110336035 \n",
      " trn_acc: 0.883 val_acc: 0.849\n",
      "spend time = { row/sec: 2693.0 optimize: 0.048 eval: 0.545 Elapsed: 1459.592 }\n",
      "Epoch: 7 Batch_iter: 810 \n",
      " Train Loss: 0.1059469 Valid Loss: 0.10933124 \n",
      " trn_acc: 0.844 val_acc: 0.851\n",
      "spend time = { row/sec: 2723.0 optimize: 0.047 eval: 0.537 Elapsed: 1462.213 }\n",
      "\n",
      " train stop penalty: 1 current loss  0.11231160637018454 > 0.11220771055260714 prev loss \n",
      "\n",
      "Epoch: 8 Batch_iter: 0 \n",
      " Train Loss: 0.06824657 Valid Loss: 0.10966942 \n",
      " trn_acc: 0.914 val_acc: 0.849\n",
      "spend time = { row/sec: 2705.0 optimize: 0.047 eval: 0.558 Elapsed: 1464.954 }\n",
      "Epoch: 8 Batch_iter: 10 \n",
      " Train Loss: 0.08976595 Valid Loss: 0.11182444 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2370.0 optimize: 0.054 eval: 0.532 Elapsed: 1467.066 }\n",
      "Epoch: 8 Batch_iter: 20 \n",
      " Train Loss: 0.07280749 Valid Loss: 0.11190477 \n",
      " trn_acc: 0.883 val_acc: 0.848\n",
      "spend time = { row/sec: 2559.0 optimize: 0.05 eval: 0.533 Elapsed: 1469.173 }\n",
      "Epoch: 8 Batch_iter: 30 \n",
      " Train Loss: 0.11565 Valid Loss: 0.11267036 \n",
      " trn_acc: 0.844 val_acc: 0.845\n",
      "spend time = { row/sec: 2722.0 optimize: 0.047 eval: 0.531 Elapsed: 1471.873 }\n",
      "Epoch: 8 Batch_iter: 40 \n",
      " Train Loss: 0.087624855 Valid Loss: 0.10944362 \n",
      " trn_acc: 0.891 val_acc: 0.85\n",
      "spend time = { row/sec: 2579.0 optimize: 0.05 eval: 0.522 Elapsed: 1474.053 }\n",
      "Epoch: 8 Batch_iter: 50 \n",
      " Train Loss: 0.06334555 Valid Loss: 0.10956105 \n",
      " trn_acc: 0.938 val_acc: 0.85\n",
      "spend time = { row/sec: 2501.0 optimize: 0.051 eval: 0.52 Elapsed: 1476.145 }\n",
      "Epoch: 8 Batch_iter: 60 \n",
      " Train Loss: 0.10270181 Valid Loss: 0.111098975 \n",
      " trn_acc: 0.844 val_acc: 0.848\n",
      "spend time = { row/sec: 2714.0 optimize: 0.047 eval: 0.567 Elapsed: 1478.852 }\n",
      "Epoch: 8 Batch_iter: 70 \n",
      " Train Loss: 0.09214792 Valid Loss: 0.11406907 \n",
      " trn_acc: 0.867 val_acc: 0.844\n",
      "spend time = { row/sec: 2378.0 optimize: 0.054 eval: 0.535 Elapsed: 1480.984 }\n",
      "Epoch: 8 Batch_iter: 80 \n",
      " Train Loss: 0.09351537 Valid Loss: 0.110194266 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2742.0 optimize: 0.047 eval: 0.572 Elapsed: 1483.126 }\n",
      "Epoch: 8 Batch_iter: 90 \n",
      " Train Loss: 0.11882885 Valid Loss: 0.11094367 \n",
      " trn_acc: 0.844 val_acc: 0.849\n",
      "spend time = { row/sec: 2743.0 optimize: 0.047 eval: 0.517 Elapsed: 1485.937 }\n",
      "Epoch: 8 Batch_iter: 100 \n",
      " Train Loss: 0.06919843 Valid Loss: 0.11090116 \n",
      " trn_acc: 0.922 val_acc: 0.849\n",
      "spend time = { row/sec: 2578.0 optimize: 0.05 eval: 0.542 Elapsed: 1488.03 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Batch_iter: 110 \n",
      " Train Loss: 0.07518141 Valid Loss: 0.11211671 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2773.0 optimize: 0.046 eval: 0.541 Elapsed: 1490.191 }\n",
      "Epoch: 8 Batch_iter: 120 \n",
      " Train Loss: 0.09092942 Valid Loss: 0.110318735 \n",
      " trn_acc: 0.859 val_acc: 0.849\n",
      "spend time = { row/sec: 2562.0 optimize: 0.05 eval: 0.525 Elapsed: 1492.867 }\n",
      "Epoch: 8 Batch_iter: 130 \n",
      " Train Loss: 0.063900545 Valid Loss: 0.112003006 \n",
      " trn_acc: 0.914 val_acc: 0.85\n",
      "spend time = { row/sec: 2599.0 optimize: 0.049 eval: 0.534 Elapsed: 1494.96 }\n",
      "Epoch: 8 Batch_iter: 140 \n",
      " Train Loss: 0.096899934 Valid Loss: 0.11096823 \n",
      " trn_acc: 0.883 val_acc: 0.849\n",
      "spend time = { row/sec: 2677.0 optimize: 0.048 eval: 0.52 Elapsed: 1497.054 }\n",
      "Epoch: 8 Batch_iter: 150 \n",
      " Train Loss: 0.060415477 Valid Loss: 0.110241376 \n",
      " trn_acc: 0.93 val_acc: 0.848\n",
      "spend time = { row/sec: 2592.0 optimize: 0.049 eval: 0.52 Elapsed: 1499.665 }\n",
      "Epoch: 8 Batch_iter: 160 \n",
      " Train Loss: 0.10356181 Valid Loss: 0.11229427 \n",
      " trn_acc: 0.852 val_acc: 0.845\n",
      "spend time = { row/sec: 2317.0 optimize: 0.055 eval: 0.551 Elapsed: 1501.814 }\n",
      "Epoch: 8 Batch_iter: 170 \n",
      " Train Loss: 0.104770534 Valid Loss: 0.11029582 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2685.0 optimize: 0.048 eval: 0.579 Elapsed: 1504.05 }\n",
      "Epoch: 8 Batch_iter: 180 \n",
      " Train Loss: 0.072286636 Valid Loss: 0.11037929 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2712.0 optimize: 0.047 eval: 0.548 Elapsed: 1506.747 }\n",
      "Epoch: 8 Batch_iter: 190 \n",
      " Train Loss: 0.085353464 Valid Loss: 0.11144047 \n",
      " trn_acc: 0.883 val_acc: 0.852\n",
      "spend time = { row/sec: 2494.0 optimize: 0.051 eval: 0.577 Elapsed: 1508.918 }\n",
      "Epoch: 8 Batch_iter: 200 \n",
      " Train Loss: 0.082633555 Valid Loss: 0.10956692 \n",
      " trn_acc: 0.875 val_acc: 0.849\n",
      "spend time = { row/sec: 2520.0 optimize: 0.051 eval: 0.524 Elapsed: 1511.017 }\n",
      "Epoch: 8 Batch_iter: 210 \n",
      " Train Loss: 0.08053893 Valid Loss: 0.109778464 \n",
      " trn_acc: 0.891 val_acc: 0.851\n",
      "spend time = { row/sec: 2689.0 optimize: 0.048 eval: 0.531 Elapsed: 1513.691 }\n",
      "Epoch: 8 Batch_iter: 220 \n",
      " Train Loss: 0.10443476 Valid Loss: 0.11308033 \n",
      " trn_acc: 0.859 val_acc: 0.845\n",
      "spend time = { row/sec: 2527.0 optimize: 0.051 eval: 0.523 Elapsed: 1515.83 }\n",
      "Epoch: 8 Batch_iter: 230 \n",
      " Train Loss: 0.08408825 Valid Loss: 0.10925037 \n",
      " trn_acc: 0.891 val_acc: 0.851\n",
      "spend time = { row/sec: 2746.0 optimize: 0.047 eval: 0.513 Elapsed: 1517.934 }\n",
      "Epoch: 8 Batch_iter: 240 \n",
      " Train Loss: 0.119691074 Valid Loss: 0.11118065 \n",
      " trn_acc: 0.844 val_acc: 0.848\n",
      "spend time = { row/sec: 2558.0 optimize: 0.05 eval: 0.574 Elapsed: 1520.677 }\n",
      "Epoch: 8 Batch_iter: 250 \n",
      " Train Loss: 0.109565474 Valid Loss: 0.111847445 \n",
      " trn_acc: 0.867 val_acc: 0.847\n",
      "spend time = { row/sec: 2452.0 optimize: 0.052 eval: 0.538 Elapsed: 1522.799 }\n",
      "Epoch: 8 Batch_iter: 260 \n",
      " Train Loss: 0.066111095 Valid Loss: 0.10952155 \n",
      " trn_acc: 0.906 val_acc: 0.85\n",
      "spend time = { row/sec: 2542.0 optimize: 0.05 eval: 0.545 Elapsed: 1524.916 }\n",
      "Epoch: 8 Batch_iter: 270 \n",
      " Train Loss: 0.07822648 Valid Loss: 0.111960664 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2654.0 optimize: 0.048 eval: 0.553 Elapsed: 1527.554 }\n",
      "Epoch: 8 Batch_iter: 280 \n",
      " Train Loss: 0.08467057 Valid Loss: 0.11222532 \n",
      " trn_acc: 0.898 val_acc: 0.85\n",
      "spend time = { row/sec: 2550.0 optimize: 0.05 eval: 0.515 Elapsed: 1529.611 }\n",
      "Epoch: 8 Batch_iter: 290 \n",
      " Train Loss: 0.0810719 Valid Loss: 0.12446119 \n",
      " trn_acc: 0.883 val_acc: 0.837\n",
      "spend time = { row/sec: 2672.0 optimize: 0.048 eval: 0.547 Elapsed: 1531.722 }\n",
      "Epoch: 8 Batch_iter: 300 \n",
      " Train Loss: 0.11875457 Valid Loss: 0.1289853 \n",
      " trn_acc: 0.859 val_acc: 0.825\n",
      "spend time = { row/sec: 2600.0 optimize: 0.049 eval: 0.578 Elapsed: 1534.36 }\n",
      "Epoch: 8 Batch_iter: 310 \n",
      " Train Loss: 0.047199383 Valid Loss: 0.110153325 \n",
      " trn_acc: 0.945 val_acc: 0.849\n",
      "spend time = { row/sec: 2430.0 optimize: 0.053 eval: 0.524 Elapsed: 1536.425 }\n",
      "Epoch: 8 Batch_iter: 320 \n",
      " Train Loss: 0.09437205 Valid Loss: 0.113704674 \n",
      " trn_acc: 0.875 val_acc: 0.844\n",
      "spend time = { row/sec: 2730.0 optimize: 0.047 eval: 0.517 Elapsed: 1538.543 }\n",
      "Epoch: 8 Batch_iter: 330 \n",
      " Train Loss: 0.09493759 Valid Loss: 0.112885155 \n",
      " trn_acc: 0.875 val_acc: 0.844\n",
      "spend time = { row/sec: 2732.0 optimize: 0.047 eval: 0.549 Elapsed: 1541.203 }\n",
      "Epoch: 8 Batch_iter: 340 \n",
      " Train Loss: 0.097045064 Valid Loss: 0.11051861 \n",
      " trn_acc: 0.867 val_acc: 0.846\n",
      "spend time = { row/sec: 2634.0 optimize: 0.049 eval: 0.535 Elapsed: 1543.29 }\n",
      "Epoch: 8 Batch_iter: 350 \n",
      " Train Loss: 0.062985145 Valid Loss: 0.11002543 \n",
      " trn_acc: 0.93 val_acc: 0.847\n",
      "spend time = { row/sec: 2628.0 optimize: 0.049 eval: 0.542 Elapsed: 1545.389 }\n",
      "Epoch: 8 Batch_iter: 360 \n",
      " Train Loss: 0.10982142 Valid Loss: 0.112920985 \n",
      " trn_acc: 0.828 val_acc: 0.849\n",
      "spend time = { row/sec: 2697.0 optimize: 0.047 eval: 0.518 Elapsed: 1548.002 }\n",
      "Epoch: 8 Batch_iter: 370 \n",
      " Train Loss: 0.07206471 Valid Loss: 0.11285718 \n",
      " trn_acc: 0.906 val_acc: 0.849\n",
      "spend time = { row/sec: 2555.0 optimize: 0.05 eval: 0.524 Elapsed: 1550.087 }\n",
      "Epoch: 8 Batch_iter: 380 \n",
      " Train Loss: 0.08019315 Valid Loss: 0.11481331 \n",
      " trn_acc: 0.875 val_acc: 0.842\n",
      "spend time = { row/sec: 2684.0 optimize: 0.048 eval: 0.524 Elapsed: 1552.178 }\n",
      "Epoch: 8 Batch_iter: 390 \n",
      " Train Loss: 0.1104517 Valid Loss: 0.11326667 \n",
      " trn_acc: 0.867 val_acc: 0.844\n",
      "spend time = { row/sec: 2569.0 optimize: 0.05 eval: 0.535 Elapsed: 1554.905 }\n",
      "Epoch: 8 Batch_iter: 400 \n",
      " Train Loss: 0.086876184 Valid Loss: 0.1111671 \n",
      " trn_acc: 0.891 val_acc: 0.851\n",
      "spend time = { row/sec: 2500.0 optimize: 0.051 eval: 0.554 Elapsed: 1557.05 }\n",
      "Epoch: 8 Batch_iter: 410 \n",
      " Train Loss: 0.0634401 Valid Loss: 0.10986224 \n",
      " trn_acc: 0.93 val_acc: 0.848\n",
      "spend time = { row/sec: 2577.0 optimize: 0.05 eval: 0.542 Elapsed: 1559.175 }\n",
      "Epoch: 8 Batch_iter: 420 \n",
      " Train Loss: 0.08691716 Valid Loss: 0.11250905 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2785.0 optimize: 0.046 eval: 0.546 Elapsed: 1561.83 }\n",
      "Epoch: 8 Batch_iter: 430 \n",
      " Train Loss: 0.085727274 Valid Loss: 0.11792983 \n",
      " trn_acc: 0.898 val_acc: 0.842\n",
      "spend time = { row/sec: 2335.0 optimize: 0.055 eval: 0.536 Elapsed: 1563.974 }\n",
      "Epoch: 8 Batch_iter: 440 \n",
      " Train Loss: 0.06864954 Valid Loss: 0.111683205 \n",
      " trn_acc: 0.906 val_acc: 0.847\n",
      "spend time = { row/sec: 2616.0 optimize: 0.049 eval: 0.589 Elapsed: 1566.139 }\n",
      "Epoch: 8 Batch_iter: 450 \n",
      " Train Loss: 0.10380757 Valid Loss: 0.11093263 \n",
      " trn_acc: 0.836 val_acc: 0.847\n",
      "spend time = { row/sec: 2680.0 optimize: 0.048 eval: 0.531 Elapsed: 1568.769 }\n",
      "Epoch: 8 Batch_iter: 460 \n",
      " Train Loss: 0.113030255 Valid Loss: 0.109808415 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2366.0 optimize: 0.054 eval: 0.572 Elapsed: 1570.933 }\n",
      "Epoch: 8 Batch_iter: 470 \n",
      " Train Loss: 0.09402229 Valid Loss: 0.11435831 \n",
      " trn_acc: 0.852 val_acc: 0.842\n",
      "spend time = { row/sec: 2614.0 optimize: 0.049 eval: 0.553 Elapsed: 1573.038 }\n",
      "Epoch: 8 Batch_iter: 480 \n",
      " Train Loss: 0.059345998 Valid Loss: 0.11080441 \n",
      " trn_acc: 0.938 val_acc: 0.848\n",
      "spend time = { row/sec: 2704.0 optimize: 0.047 eval: 0.521 Elapsed: 1575.669 }\n",
      "Epoch: 8 Batch_iter: 490 \n",
      " Train Loss: 0.09551745 Valid Loss: 0.111369684 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2206.0 optimize: 0.058 eval: 0.539 Elapsed: 1577.788 }\n",
      "Epoch: 8 Batch_iter: 500 \n",
      " Train Loss: 0.11031716 Valid Loss: 0.115578204 \n",
      " trn_acc: 0.844 val_acc: 0.844\n",
      "spend time = { row/sec: 2677.0 optimize: 0.048 eval: 0.536 Elapsed: 1579.894 }\n",
      "Epoch: 8 Batch_iter: 510 \n",
      " Train Loss: 0.1202488 Valid Loss: 0.112777345 \n",
      " trn_acc: 0.844 val_acc: 0.846\n",
      "spend time = { row/sec: 2681.0 optimize: 0.048 eval: 0.534 Elapsed: 1582.496 }\n",
      "Epoch: 8 Batch_iter: 520 \n",
      " Train Loss: 0.10135701 Valid Loss: 0.11514628 \n",
      " trn_acc: 0.867 val_acc: 0.843\n",
      "spend time = { row/sec: 2473.0 optimize: 0.052 eval: 0.546 Elapsed: 1584.612 }\n",
      "Epoch: 8 Batch_iter: 530 \n",
      " Train Loss: 0.10647765 Valid Loss: 0.11474353 \n",
      " trn_acc: 0.883 val_acc: 0.843\n",
      "spend time = { row/sec: 2830.0 optimize: 0.045 eval: 0.542 Elapsed: 1586.71 }\n",
      "Epoch: 8 Batch_iter: 540 \n",
      " Train Loss: 0.06252438 Valid Loss: 0.11621624 \n",
      " trn_acc: 0.906 val_acc: 0.841\n",
      "spend time = { row/sec: 2538.0 optimize: 0.05 eval: 0.538 Elapsed: 1589.411 }\n",
      "Epoch: 8 Batch_iter: 550 \n",
      " Train Loss: 0.091756396 Valid Loss: 0.11363526 \n",
      " trn_acc: 0.883 val_acc: 0.844\n",
      "spend time = { row/sec: 2518.0 optimize: 0.051 eval: 0.575 Elapsed: 1591.53 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Batch_iter: 560 \n",
      " Train Loss: 0.09607889 Valid Loss: 0.1106959 \n",
      " trn_acc: 0.859 val_acc: 0.85\n",
      "spend time = { row/sec: 2781.0 optimize: 0.046 eval: 0.528 Elapsed: 1593.651 }\n",
      "Epoch: 8 Batch_iter: 570 \n",
      " Train Loss: 0.09118281 Valid Loss: 0.11023497 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2782.0 optimize: 0.046 eval: 0.529 Elapsed: 1596.328 }\n",
      "Epoch: 8 Batch_iter: 580 \n",
      " Train Loss: 0.104209855 Valid Loss: 0.11273009 \n",
      " trn_acc: 0.828 val_acc: 0.846\n",
      "spend time = { row/sec: 2114.0 optimize: 0.061 eval: 0.558 Elapsed: 1598.484 }\n",
      "Epoch: 8 Batch_iter: 590 \n",
      " Train Loss: 0.10313464 Valid Loss: 0.112320505 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2723.0 optimize: 0.047 eval: 0.544 Elapsed: 1600.762 }\n",
      "Epoch: 8 Batch_iter: 600 \n",
      " Train Loss: 0.11174908 Valid Loss: 0.11604168 \n",
      " trn_acc: 0.875 val_acc: 0.84\n",
      "spend time = { row/sec: 2632.0 optimize: 0.049 eval: 0.546 Elapsed: 1603.398 }\n",
      "Epoch: 8 Batch_iter: 610 \n",
      " Train Loss: 0.087901 Valid Loss: 0.11277831 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2449.0 optimize: 0.052 eval: 0.538 Elapsed: 1605.489 }\n",
      "Epoch: 8 Batch_iter: 620 \n",
      " Train Loss: 0.09027842 Valid Loss: 0.1101942 \n",
      " trn_acc: 0.891 val_acc: 0.85\n",
      "spend time = { row/sec: 2663.0 optimize: 0.048 eval: 0.528 Elapsed: 1607.553 }\n",
      "Epoch: 8 Batch_iter: 630 \n",
      " Train Loss: 0.07236182 Valid Loss: 0.10998145 \n",
      " trn_acc: 0.891 val_acc: 0.849\n",
      "spend time = { row/sec: 2752.0 optimize: 0.046 eval: 0.533 Elapsed: 1610.164 }\n",
      "Epoch: 8 Batch_iter: 640 \n",
      " Train Loss: 0.1034039 Valid Loss: 0.116013624 \n",
      " trn_acc: 0.875 val_acc: 0.841\n",
      "spend time = { row/sec: 2171.0 optimize: 0.059 eval: 0.551 Elapsed: 1612.278 }\n",
      "Epoch: 8 Batch_iter: 650 \n",
      " Train Loss: 0.08279231 Valid Loss: 0.11327398 \n",
      " trn_acc: 0.898 val_acc: 0.846\n",
      "spend time = { row/sec: 2487.0 optimize: 0.051 eval: 0.52 Elapsed: 1614.408 }\n",
      "Epoch: 8 Batch_iter: 660 \n",
      " Train Loss: 0.09634233 Valid Loss: 0.10935763 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2675.0 optimize: 0.048 eval: 0.593 Elapsed: 1617.267 }\n",
      "Epoch: 8 Batch_iter: 670 \n",
      " Train Loss: 0.08613563 Valid Loss: 0.10900799 \n",
      " trn_acc: 0.891 val_acc: 0.848\n",
      "spend time = { row/sec: 2687.0 optimize: 0.048 eval: 0.515 Elapsed: 1619.395 }\n",
      "Epoch: 8 Batch_iter: 680 \n",
      " Train Loss: 0.07890235 Valid Loss: 0.11024432 \n",
      " trn_acc: 0.898 val_acc: 0.85\n",
      "spend time = { row/sec: 2401.0 optimize: 0.053 eval: 0.56 Elapsed: 1621.582 }\n",
      "Epoch: 8 Batch_iter: 690 \n",
      " Train Loss: 0.067523 Valid Loss: 0.11406615 \n",
      " trn_acc: 0.906 val_acc: 0.844\n",
      "spend time = { row/sec: 2428.0 optimize: 0.053 eval: 0.526 Elapsed: 1624.361 }\n",
      "Epoch: 8 Batch_iter: 700 \n",
      " Train Loss: 0.050587963 Valid Loss: 0.11103166 \n",
      " trn_acc: 0.938 val_acc: 0.85\n",
      "spend time = { row/sec: 2576.0 optimize: 0.05 eval: 0.527 Elapsed: 1626.46 }\n",
      "Epoch: 8 Batch_iter: 710 \n",
      " Train Loss: 0.10070549 Valid Loss: 0.11128083 \n",
      " trn_acc: 0.867 val_acc: 0.85\n",
      "spend time = { row/sec: 2505.0 optimize: 0.051 eval: 0.518 Elapsed: 1628.513 }\n",
      "Epoch: 8 Batch_iter: 720 \n",
      " Train Loss: 0.07675086 Valid Loss: 0.11293937 \n",
      " trn_acc: 0.891 val_acc: 0.843\n",
      "spend time = { row/sec: 2640.0 optimize: 0.048 eval: 0.55 Elapsed: 1631.155 }\n",
      "Epoch: 8 Batch_iter: 730 \n",
      " Train Loss: 0.098572634 Valid Loss: 0.111177765 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2737.0 optimize: 0.047 eval: 0.515 Elapsed: 1633.26 }\n",
      "Epoch: 8 Batch_iter: 740 \n",
      " Train Loss: 0.073803924 Valid Loss: 0.11154492 \n",
      " trn_acc: 0.914 val_acc: 0.85\n",
      "spend time = { row/sec: 2557.0 optimize: 0.05 eval: 0.525 Elapsed: 1635.371 }\n",
      "Epoch: 8 Batch_iter: 750 \n",
      " Train Loss: 0.11017941 Valid Loss: 0.11078421 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2785.0 optimize: 0.046 eval: 0.51 Elapsed: 1637.952 }\n",
      "Epoch: 8 Batch_iter: 760 \n",
      " Train Loss: 0.091842055 Valid Loss: 0.11178665 \n",
      " trn_acc: 0.867 val_acc: 0.846\n",
      "spend time = { row/sec: 2504.0 optimize: 0.051 eval: 0.526 Elapsed: 1640.044 }\n",
      "Epoch: 8 Batch_iter: 770 \n",
      " Train Loss: 0.1045999 Valid Loss: 0.11205266 \n",
      " trn_acc: 0.859 val_acc: 0.848\n",
      "spend time = { row/sec: 2611.0 optimize: 0.049 eval: 0.516 Elapsed: 1642.15 }\n",
      "Epoch: 8 Batch_iter: 780 \n",
      " Train Loss: 0.084254585 Valid Loss: 0.10953885 \n",
      " trn_acc: 0.875 val_acc: 0.849\n",
      "spend time = { row/sec: 2748.0 optimize: 0.047 eval: 0.533 Elapsed: 1644.732 }\n",
      "Epoch: 8 Batch_iter: 790 \n",
      " Train Loss: 0.049122274 Valid Loss: 0.11179248 \n",
      " trn_acc: 0.938 val_acc: 0.847\n",
      "spend time = { row/sec: 2415.0 optimize: 0.053 eval: 0.551 Elapsed: 1646.827 }\n",
      "Epoch: 8 Batch_iter: 800 \n",
      " Train Loss: 0.087693274 Valid Loss: 0.11236763 \n",
      " trn_acc: 0.898 val_acc: 0.845\n",
      "spend time = { row/sec: 2424.0 optimize: 0.053 eval: 0.53 Elapsed: 1648.915 }\n",
      "Epoch: 8 Batch_iter: 810 \n",
      " Train Loss: 0.11145583 Valid Loss: 0.10903257 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2605.0 optimize: 0.049 eval: 0.515 Elapsed: 1651.493 }\n",
      "\n",
      " Save the model : current loss  0.11211656148198747 <= 0.11220771055260714 prev loss \n",
      "\n",
      "Epoch: 9 Batch_iter: 0 \n",
      " Train Loss: 0.09771194 Valid Loss: 0.109162666 \n",
      " trn_acc: 0.875 val_acc: 0.849\n",
      "spend time = { row/sec: 2603.0 optimize: 0.049 eval: 0.551 Elapsed: 1654.438 }\n",
      "Epoch: 9 Batch_iter: 10 \n",
      " Train Loss: 0.08547117 Valid Loss: 0.11283673 \n",
      " trn_acc: 0.891 val_acc: 0.845\n",
      "spend time = { row/sec: 2456.0 optimize: 0.052 eval: 0.526 Elapsed: 1656.514 }\n",
      "Epoch: 9 Batch_iter: 20 \n",
      " Train Loss: 0.08158381 Valid Loss: 0.112324804 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2781.0 optimize: 0.046 eval: 0.532 Elapsed: 1658.681 }\n",
      "Epoch: 9 Batch_iter: 30 \n",
      " Train Loss: 0.068798944 Valid Loss: 0.110485435 \n",
      " trn_acc: 0.891 val_acc: 0.849\n",
      "spend time = { row/sec: 2755.0 optimize: 0.046 eval: 0.557 Elapsed: 1661.336 }\n",
      "Epoch: 9 Batch_iter: 40 \n",
      " Train Loss: 0.091618985 Valid Loss: 0.111010745 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2544.0 optimize: 0.05 eval: 0.53 Elapsed: 1663.468 }\n",
      "Epoch: 9 Batch_iter: 50 \n",
      " Train Loss: 0.08449949 Valid Loss: 0.113206916 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2633.0 optimize: 0.049 eval: 0.543 Elapsed: 1665.568 }\n",
      "Epoch: 9 Batch_iter: 60 \n",
      " Train Loss: 0.10746861 Valid Loss: 0.11041535 \n",
      " trn_acc: 0.875 val_acc: 0.85\n",
      "spend time = { row/sec: 2542.0 optimize: 0.05 eval: 0.529 Elapsed: 1668.206 }\n",
      "Epoch: 9 Batch_iter: 70 \n",
      " Train Loss: 0.10542036 Valid Loss: 0.110894 \n",
      " trn_acc: 0.859 val_acc: 0.849\n",
      "spend time = { row/sec: 2158.0 optimize: 0.059 eval: 0.527 Elapsed: 1670.312 }\n",
      "Epoch: 9 Batch_iter: 80 \n",
      " Train Loss: 0.09340819 Valid Loss: 0.11414956 \n",
      " trn_acc: 0.891 val_acc: 0.847\n",
      "spend time = { row/sec: 2733.0 optimize: 0.047 eval: 0.572 Elapsed: 1672.442 }\n",
      "Epoch: 9 Batch_iter: 90 \n",
      " Train Loss: 0.06577814 Valid Loss: 0.115796655 \n",
      " trn_acc: 0.914 val_acc: 0.842\n",
      "spend time = { row/sec: 2725.0 optimize: 0.047 eval: 0.564 Elapsed: 1675.442 }\n",
      "Epoch: 9 Batch_iter: 100 \n",
      " Train Loss: 0.15299404 Valid Loss: 0.12771814 \n",
      " trn_acc: 0.789 val_acc: 0.833\n",
      "spend time = { row/sec: 2478.0 optimize: 0.052 eval: 0.535 Elapsed: 1677.546 }\n",
      "Epoch: 9 Batch_iter: 110 \n",
      " Train Loss: 0.11287346 Valid Loss: 0.1188148 \n",
      " trn_acc: 0.844 val_acc: 0.843\n",
      "spend time = { row/sec: 2507.0 optimize: 0.051 eval: 0.525 Elapsed: 1679.656 }\n",
      "Epoch: 9 Batch_iter: 120 \n",
      " Train Loss: 0.103392646 Valid Loss: 0.10994406 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2641.0 optimize: 0.048 eval: 0.521 Elapsed: 1682.254 }\n",
      "Epoch: 9 Batch_iter: 130 \n",
      " Train Loss: 0.11876073 Valid Loss: 0.11048946 \n",
      " trn_acc: 0.836 val_acc: 0.848\n",
      "spend time = { row/sec: 2468.0 optimize: 0.052 eval: 0.524 Elapsed: 1684.372 }\n",
      "Epoch: 9 Batch_iter: 140 \n",
      " Train Loss: 0.09223266 Valid Loss: 0.111239724 \n",
      " trn_acc: 0.883 val_acc: 0.849\n",
      "spend time = { row/sec: 2673.0 optimize: 0.048 eval: 0.532 Elapsed: 1686.48 }\n",
      "Epoch: 9 Batch_iter: 150 \n",
      " Train Loss: 0.06803882 Valid Loss: 0.11249777 \n",
      " trn_acc: 0.922 val_acc: 0.846\n",
      "spend time = { row/sec: 2434.0 optimize: 0.053 eval: 0.545 Elapsed: 1689.164 }\n",
      "Epoch: 9 Batch_iter: 160 \n",
      " Train Loss: 0.090929694 Valid Loss: 0.11066078 \n",
      " trn_acc: 0.836 val_acc: 0.846\n",
      "spend time = { row/sec: 2394.0 optimize: 0.053 eval: 0.524 Elapsed: 1691.251 }\n",
      "Epoch: 9 Batch_iter: 170 \n",
      " Train Loss: 0.084113605 Valid Loss: 0.11655221 \n",
      " trn_acc: 0.867 val_acc: 0.841\n",
      "spend time = { row/sec: 2519.0 optimize: 0.051 eval: 0.547 Elapsed: 1693.343 }\n",
      "Epoch: 9 Batch_iter: 180 \n",
      " Train Loss: 0.10009833 Valid Loss: 0.11305332 \n",
      " trn_acc: 0.859 val_acc: 0.848\n",
      "spend time = { row/sec: 2815.0 optimize: 0.045 eval: 0.546 Elapsed: 1696.024 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Batch_iter: 190 \n",
      " Train Loss: 0.06241507 Valid Loss: 0.11627412 \n",
      " trn_acc: 0.922 val_acc: 0.847\n",
      "spend time = { row/sec: 2536.0 optimize: 0.05 eval: 0.515 Elapsed: 1698.096 }\n",
      "Epoch: 9 Batch_iter: 200 \n",
      " Train Loss: 0.067480296 Valid Loss: 0.11451844 \n",
      " trn_acc: 0.93 val_acc: 0.845\n",
      "spend time = { row/sec: 2441.0 optimize: 0.052 eval: 0.536 Elapsed: 1700.234 }\n",
      "Epoch: 9 Batch_iter: 210 \n",
      " Train Loss: 0.10530302 Valid Loss: 0.113457955 \n",
      " trn_acc: 0.891 val_acc: 0.846\n",
      "spend time = { row/sec: 2757.0 optimize: 0.046 eval: 0.525 Elapsed: 1702.824 }\n",
      "Epoch: 9 Batch_iter: 220 \n",
      " Train Loss: 0.059348434 Valid Loss: 0.112959474 \n",
      " trn_acc: 0.922 val_acc: 0.849\n",
      "spend time = { row/sec: 2408.0 optimize: 0.053 eval: 0.55 Elapsed: 1705.002 }\n",
      "Epoch: 9 Batch_iter: 230 \n",
      " Train Loss: 0.08412037 Valid Loss: 0.1109132 \n",
      " trn_acc: 0.883 val_acc: 0.85\n",
      "spend time = { row/sec: 2662.0 optimize: 0.048 eval: 0.524 Elapsed: 1707.126 }\n",
      "Epoch: 9 Batch_iter: 240 \n",
      " Train Loss: 0.08878236 Valid Loss: 0.11881346 \n",
      " trn_acc: 0.883 val_acc: 0.838\n",
      "spend time = { row/sec: 2546.0 optimize: 0.05 eval: 0.532 Elapsed: 1709.793 }\n",
      "Epoch: 9 Batch_iter: 250 \n",
      " Train Loss: 0.0805517 Valid Loss: 0.10963501 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2583.0 optimize: 0.05 eval: 0.548 Elapsed: 1711.91 }\n",
      "Epoch: 9 Batch_iter: 260 \n",
      " Train Loss: 0.0921982 Valid Loss: 0.11076625 \n",
      " trn_acc: 0.891 val_acc: 0.846\n",
      "spend time = { row/sec: 2725.0 optimize: 0.047 eval: 0.554 Elapsed: 1713.987 }\n",
      "Epoch: 9 Batch_iter: 270 \n",
      " Train Loss: 0.11366902 Valid Loss: 0.109839715 \n",
      " trn_acc: 0.844 val_acc: 0.848\n",
      "spend time = { row/sec: 2702.0 optimize: 0.047 eval: 0.613 Elapsed: 1716.912 }\n",
      "Epoch: 9 Batch_iter: 280 \n",
      " Train Loss: 0.091537766 Valid Loss: 0.10965501 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2366.0 optimize: 0.054 eval: 0.546 Elapsed: 1719.042 }\n",
      "Epoch: 9 Batch_iter: 290 \n",
      " Train Loss: 0.09259561 Valid Loss: 0.111235365 \n",
      " trn_acc: 0.867 val_acc: 0.847\n",
      "spend time = { row/sec: 2649.0 optimize: 0.048 eval: 0.537 Elapsed: 1721.103 }\n",
      "Epoch: 9 Batch_iter: 300 \n",
      " Train Loss: 0.060636863 Valid Loss: 0.113420665 \n",
      " trn_acc: 0.922 val_acc: 0.849\n",
      "spend time = { row/sec: 2765.0 optimize: 0.046 eval: 0.564 Elapsed: 1723.791 }\n",
      "Epoch: 9 Batch_iter: 310 \n",
      " Train Loss: 0.077742465 Valid Loss: 0.11584659 \n",
      " trn_acc: 0.906 val_acc: 0.847\n",
      "spend time = { row/sec: 2162.0 optimize: 0.059 eval: 0.538 Elapsed: 1726.085 }\n",
      "Epoch: 9 Batch_iter: 320 \n",
      " Train Loss: 0.089571714 Valid Loss: 0.11362743 \n",
      " trn_acc: 0.883 val_acc: 0.846\n",
      "spend time = { row/sec: 2467.0 optimize: 0.052 eval: 0.591 Elapsed: 1728.256 }\n",
      "Epoch: 9 Batch_iter: 330 \n",
      " Train Loss: 0.101398155 Valid Loss: 0.11038895 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2744.0 optimize: 0.047 eval: 0.541 Elapsed: 1730.865 }\n",
      "Epoch: 9 Batch_iter: 340 \n",
      " Train Loss: 0.08821929 Valid Loss: 0.10971516 \n",
      " trn_acc: 0.891 val_acc: 0.849\n",
      "spend time = { row/sec: 2748.0 optimize: 0.047 eval: 0.527 Elapsed: 1732.989 }\n",
      "Epoch: 9 Batch_iter: 350 \n",
      " Train Loss: 0.095469356 Valid Loss: 0.10928399 \n",
      " trn_acc: 0.859 val_acc: 0.851\n",
      "spend time = { row/sec: 2766.0 optimize: 0.046 eval: 0.524 Elapsed: 1735.068 }\n",
      "Epoch: 9 Batch_iter: 360 \n",
      " Train Loss: 0.11561786 Valid Loss: 0.11894508 \n",
      " trn_acc: 0.836 val_acc: 0.837\n",
      "spend time = { row/sec: 2745.0 optimize: 0.047 eval: 0.543 Elapsed: 1737.71 }\n",
      "Epoch: 9 Batch_iter: 370 \n",
      " Train Loss: 0.09254986 Valid Loss: 0.11220434 \n",
      " trn_acc: 0.891 val_acc: 0.847\n",
      "spend time = { row/sec: 2097.0 optimize: 0.061 eval: 0.556 Elapsed: 1739.866 }\n",
      "Epoch: 9 Batch_iter: 380 \n",
      " Train Loss: 0.07385734 Valid Loss: 0.11062266 \n",
      " trn_acc: 0.891 val_acc: 0.849\n",
      "spend time = { row/sec: 2744.0 optimize: 0.047 eval: 0.542 Elapsed: 1741.963 }\n",
      "Epoch: 9 Batch_iter: 390 \n",
      " Train Loss: 0.086704314 Valid Loss: 0.111913145 \n",
      " trn_acc: 0.898 val_acc: 0.85\n",
      "spend time = { row/sec: 2676.0 optimize: 0.048 eval: 0.538 Elapsed: 1744.612 }\n",
      "Epoch: 9 Batch_iter: 400 \n",
      " Train Loss: 0.09689753 Valid Loss: 0.1212507 \n",
      " trn_acc: 0.883 val_acc: 0.836\n",
      "spend time = { row/sec: 2569.0 optimize: 0.05 eval: 0.543 Elapsed: 1746.784 }\n",
      "Epoch: 9 Batch_iter: 410 \n",
      " Train Loss: 0.09472352 Valid Loss: 0.11768414 \n",
      " trn_acc: 0.859 val_acc: 0.84\n",
      "spend time = { row/sec: 2701.0 optimize: 0.047 eval: 0.541 Elapsed: 1748.908 }\n",
      "Epoch: 9 Batch_iter: 420 \n",
      " Train Loss: 0.12437536 Valid Loss: 0.10984097 \n",
      " trn_acc: 0.82 val_acc: 0.849\n",
      "spend time = { row/sec: 2745.0 optimize: 0.047 eval: 0.524 Elapsed: 1751.531 }\n",
      "Epoch: 9 Batch_iter: 430 \n",
      " Train Loss: 0.095962554 Valid Loss: 0.10975164 \n",
      " trn_acc: 0.891 val_acc: 0.851\n",
      "spend time = { row/sec: 2435.0 optimize: 0.053 eval: 0.529 Elapsed: 1753.651 }\n",
      "Epoch: 9 Batch_iter: 440 \n",
      " Train Loss: 0.06700433 Valid Loss: 0.110399395 \n",
      " trn_acc: 0.922 val_acc: 0.85\n",
      "spend time = { row/sec: 2675.0 optimize: 0.048 eval: 0.537 Elapsed: 1755.763 }\n",
      "Epoch: 9 Batch_iter: 450 \n",
      " Train Loss: 0.10651358 Valid Loss: 0.115211844 \n",
      " trn_acc: 0.859 val_acc: 0.844\n",
      "spend time = { row/sec: 2619.0 optimize: 0.049 eval: 0.538 Elapsed: 1758.456 }\n",
      "Epoch: 9 Batch_iter: 460 \n",
      " Train Loss: 0.08287573 Valid Loss: 0.11104754 \n",
      " trn_acc: 0.906 val_acc: 0.851\n",
      "spend time = { row/sec: 2517.0 optimize: 0.051 eval: 0.636 Elapsed: 1760.673 }\n",
      "Epoch: 9 Batch_iter: 470 \n",
      " Train Loss: 0.08581119 Valid Loss: 0.11064061 \n",
      " trn_acc: 0.891 val_acc: 0.851\n",
      "spend time = { row/sec: 2594.0 optimize: 0.049 eval: 0.681 Elapsed: 1762.916 }\n",
      "Epoch: 9 Batch_iter: 480 \n",
      " Train Loss: 0.08578131 Valid Loss: 0.11356032 \n",
      " trn_acc: 0.875 val_acc: 0.846\n",
      "spend time = { row/sec: 2719.0 optimize: 0.047 eval: 0.541 Elapsed: 1765.572 }\n",
      "Epoch: 9 Batch_iter: 490 \n",
      " Train Loss: 0.09690865 Valid Loss: 0.11687863 \n",
      " trn_acc: 0.891 val_acc: 0.842\n",
      "spend time = { row/sec: 2468.0 optimize: 0.052 eval: 0.535 Elapsed: 1767.701 }\n",
      "Epoch: 9 Batch_iter: 500 \n",
      " Train Loss: 0.07654488 Valid Loss: 0.11171379 \n",
      " trn_acc: 0.867 val_acc: 0.849\n",
      "spend time = { row/sec: 2719.0 optimize: 0.047 eval: 0.526 Elapsed: 1769.794 }\n",
      "Epoch: 9 Batch_iter: 510 \n",
      " Train Loss: 0.08910662 Valid Loss: 0.11135415 \n",
      " trn_acc: 0.875 val_acc: 0.847\n",
      "spend time = { row/sec: 2720.0 optimize: 0.047 eval: 0.543 Elapsed: 1772.395 }\n",
      "Epoch: 9 Batch_iter: 520 \n",
      " Train Loss: 0.08485182 Valid Loss: 0.11271317 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2106.0 optimize: 0.061 eval: 0.562 Elapsed: 1774.568 }\n",
      "Epoch: 9 Batch_iter: 530 \n",
      " Train Loss: 0.07656713 Valid Loss: 0.11284108 \n",
      " trn_acc: 0.906 val_acc: 0.846\n",
      "spend time = { row/sec: 2750.0 optimize: 0.047 eval: 0.531 Elapsed: 1776.621 }\n",
      "Epoch: 9 Batch_iter: 540 \n",
      " Train Loss: 0.08621538 Valid Loss: 0.11349793 \n",
      " trn_acc: 0.906 val_acc: 0.844\n",
      "spend time = { row/sec: 2729.0 optimize: 0.047 eval: 0.562 Elapsed: 1779.47 }\n",
      "Epoch: 9 Batch_iter: 550 \n",
      " Train Loss: 0.11755455 Valid Loss: 0.11427249 \n",
      " trn_acc: 0.836 val_acc: 0.84\n",
      "spend time = { row/sec: 2671.0 optimize: 0.048 eval: 0.531 Elapsed: 1781.64 }\n",
      "Epoch: 9 Batch_iter: 560 \n",
      " Train Loss: 0.079763584 Valid Loss: 0.1101486 \n",
      " trn_acc: 0.914 val_acc: 0.848\n",
      "spend time = { row/sec: 2787.0 optimize: 0.046 eval: 0.543 Elapsed: 1783.772 }\n",
      "Epoch: 9 Batch_iter: 570 \n",
      " Train Loss: 0.10212129 Valid Loss: 0.110172965 \n",
      " trn_acc: 0.859 val_acc: 0.849\n",
      "spend time = { row/sec: 2734.0 optimize: 0.047 eval: 0.525 Elapsed: 1786.416 }\n",
      "Epoch: 9 Batch_iter: 580 \n",
      " Train Loss: 0.120751746 Valid Loss: 0.11053761 \n",
      " trn_acc: 0.852 val_acc: 0.847\n",
      "spend time = { row/sec: 2443.0 optimize: 0.052 eval: 0.533 Elapsed: 1788.5 }\n",
      "Epoch: 9 Batch_iter: 590 \n",
      " Train Loss: 0.0752382 Valid Loss: 0.115161486 \n",
      " trn_acc: 0.906 val_acc: 0.841\n",
      "spend time = { row/sec: 2811.0 optimize: 0.046 eval: 0.545 Elapsed: 1790.631 }\n",
      "Epoch: 9 Batch_iter: 600 \n",
      " Train Loss: 0.09866955 Valid Loss: 0.1132717 \n",
      " trn_acc: 0.867 val_acc: 0.847\n",
      "spend time = { row/sec: 2770.0 optimize: 0.046 eval: 0.532 Elapsed: 1793.225 }\n",
      "Epoch: 9 Batch_iter: 610 \n",
      " Train Loss: 0.077983856 Valid Loss: 0.11031125 \n",
      " trn_acc: 0.914 val_acc: 0.848\n",
      "spend time = { row/sec: 2646.0 optimize: 0.048 eval: 0.555 Elapsed: 1795.362 }\n",
      "Epoch: 9 Batch_iter: 620 \n",
      " Train Loss: 0.1055104 Valid Loss: 0.11693165 \n",
      " trn_acc: 0.82 val_acc: 0.838\n",
      "spend time = { row/sec: 2763.0 optimize: 0.046 eval: 0.547 Elapsed: 1797.641 }\n",
      "Epoch: 9 Batch_iter: 630 \n",
      " Train Loss: 0.08576927 Valid Loss: 0.10896337 \n",
      " trn_acc: 0.883 val_acc: 0.847\n",
      "spend time = { row/sec: 2697.0 optimize: 0.047 eval: 0.543 Elapsed: 1800.395 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Batch_iter: 640 \n",
      " Train Loss: 0.0838186 Valid Loss: 0.11139777 \n",
      " trn_acc: 0.898 val_acc: 0.846\n",
      "spend time = { row/sec: 2741.0 optimize: 0.047 eval: 0.618 Elapsed: 1802.64 }\n",
      "Epoch: 9 Batch_iter: 650 \n",
      " Train Loss: 0.08339214 Valid Loss: 0.111094646 \n",
      " trn_acc: 0.875 val_acc: 0.85\n",
      "spend time = { row/sec: 2593.0 optimize: 0.049 eval: 0.516 Elapsed: 1804.716 }\n",
      "Epoch: 9 Batch_iter: 660 \n",
      " Train Loss: 0.10736982 Valid Loss: 0.112472005 \n",
      " trn_acc: 0.844 val_acc: 0.844\n",
      "spend time = { row/sec: 2693.0 optimize: 0.048 eval: 0.678 Elapsed: 1807.557 }\n",
      "Epoch: 9 Batch_iter: 670 \n",
      " Train Loss: 0.073526435 Valid Loss: 0.109199055 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2286.0 optimize: 0.056 eval: 0.555 Elapsed: 1809.671 }\n",
      "Epoch: 9 Batch_iter: 680 \n",
      " Train Loss: 0.10389748 Valid Loss: 0.10980479 \n",
      " trn_acc: 0.844 val_acc: 0.847\n",
      "spend time = { row/sec: 2680.0 optimize: 0.048 eval: 0.552 Elapsed: 1811.811 }\n",
      "Epoch: 9 Batch_iter: 690 \n",
      " Train Loss: 0.1034797 Valid Loss: 0.11147627 \n",
      " trn_acc: 0.867 val_acc: 0.848\n",
      "spend time = { row/sec: 2696.0 optimize: 0.047 eval: 0.532 Elapsed: 1814.461 }\n",
      "Epoch: 9 Batch_iter: 700 \n",
      " Train Loss: 0.08420037 Valid Loss: 0.11330994 \n",
      " trn_acc: 0.891 val_acc: 0.846\n",
      "spend time = { row/sec: 2311.0 optimize: 0.055 eval: 0.54 Elapsed: 1816.568 }\n",
      "Epoch: 9 Batch_iter: 710 \n",
      " Train Loss: 0.08464985 Valid Loss: 0.110764615 \n",
      " trn_acc: 0.898 val_acc: 0.847\n",
      "spend time = { row/sec: 2416.0 optimize: 0.053 eval: 0.53 Elapsed: 1818.672 }\n",
      "Epoch: 9 Batch_iter: 720 \n",
      " Train Loss: 0.08826262 Valid Loss: 0.10953053 \n",
      " trn_acc: 0.891 val_acc: 0.851\n",
      "spend time = { row/sec: 2232.0 optimize: 0.057 eval: 0.577 Elapsed: 1821.342 }\n",
      "Epoch: 9 Batch_iter: 730 \n",
      " Train Loss: 0.08300444 Valid Loss: 0.10947161 \n",
      " trn_acc: 0.898 val_acc: 0.851\n",
      "spend time = { row/sec: 2339.0 optimize: 0.055 eval: 0.539 Elapsed: 1823.521 }\n",
      "Epoch: 9 Batch_iter: 740 \n",
      " Train Loss: 0.060746126 Valid Loss: 0.109216146 \n",
      " trn_acc: 0.922 val_acc: 0.851\n",
      "spend time = { row/sec: 2513.0 optimize: 0.051 eval: 0.598 Elapsed: 1825.668 }\n",
      "Epoch: 9 Batch_iter: 750 \n",
      " Train Loss: 0.0849147 Valid Loss: 0.11083458 \n",
      " trn_acc: 0.852 val_acc: 0.85\n",
      "spend time = { row/sec: 2711.0 optimize: 0.047 eval: 0.529 Elapsed: 1828.378 }\n",
      "Epoch: 9 Batch_iter: 760 \n",
      " Train Loss: 0.10907839 Valid Loss: 0.1117718 \n",
      " trn_acc: 0.852 val_acc: 0.85\n",
      "spend time = { row/sec: 2481.0 optimize: 0.052 eval: 0.541 Elapsed: 1830.513 }\n",
      "Epoch: 9 Batch_iter: 770 \n",
      " Train Loss: 0.12036825 Valid Loss: 0.11524849 \n",
      " trn_acc: 0.812 val_acc: 0.846\n",
      "spend time = { row/sec: 2812.0 optimize: 0.046 eval: 0.518 Elapsed: 1832.608 }\n",
      "Epoch: 9 Batch_iter: 780 \n",
      " Train Loss: 0.10373204 Valid Loss: 0.1085521 \n",
      " trn_acc: 0.875 val_acc: 0.85\n",
      "spend time = { row/sec: 2675.0 optimize: 0.048 eval: 0.533 Elapsed: 1835.298 }\n",
      "Epoch: 9 Batch_iter: 790 \n",
      " Train Loss: 0.13680264 Valid Loss: 0.1089658 \n",
      " trn_acc: 0.836 val_acc: 0.851\n",
      "spend time = { row/sec: 2671.0 optimize: 0.048 eval: 0.523 Elapsed: 1837.408 }\n",
      "Epoch: 9 Batch_iter: 800 \n",
      " Train Loss: 0.08422836 Valid Loss: 0.11133548 \n",
      " trn_acc: 0.883 val_acc: 0.849\n",
      "spend time = { row/sec: 2453.0 optimize: 0.052 eval: 0.56 Elapsed: 1839.569 }\n",
      "Epoch: 9 Batch_iter: 810 \n",
      " Train Loss: 0.08489994 Valid Loss: 0.111905664 \n",
      " trn_acc: 0.898 val_acc: 0.848\n",
      "spend time = { row/sec: 2715.0 optimize: 0.047 eval: 0.559 Elapsed: 1842.254 }\n",
      "\n",
      " train stop penalty: 2 current loss  0.11247089632997548 > 0.11211656148198747 prev loss \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "tic = time.time()\n",
    "spend_t = [0, 0, 0]\n",
    "prev_val_epoc_loss = sess.run(cost, feed_dict={inputs: val_data[0], \n",
    "                                               target: val_data[1], keep_prob: 1.0})\n",
    "print('current val_loss:', prev_val_epoc_loss)\n",
    "trn_stop_penalty = 0\n",
    "\n",
    "for e in range(epoch):\n",
    "    val_epoc_loss = 0 \n",
    "    trn_data = mk_model_data(model_df.iloc[trn_idx,:], shuffle=True)\n",
    "    batch_num = len(trn_data[0])//batch_size\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        batch_x = trn_data[0][batch_size*(i):batch_size*(i+1)]\n",
    "        batch_y = trn_data[1][batch_size*(i):batch_size*(i+1)]\n",
    "\n",
    "        otic=time.time()    \n",
    "        _, summary, loss, trn_acc = sess.run([optimizer, summary_mg, cost, accuracy], \n",
    "                    feed_dict={inputs: batch_x, target: batch_y, \n",
    "                               keep_prob: drop_keep_prob})\n",
    "        trn_writer.add_summary(summary, i + batch_num*e)\n",
    "        otoc = time.time() - otic\n",
    "        spend_t[0] += otoc\n",
    "\n",
    "        val_step=3\n",
    "        if i % val_step == 0:\n",
    "            etic=time.time()\n",
    "            val_loss, val_acc, summary = \\\n",
    "                sess.run([cost, accuracy, summary_mg], \\\n",
    "                         feed_dict={inputs: val_data[0], target: val_data[1], keep_prob: 1.0})\n",
    "            val_epoc_loss += val_loss\n",
    "            tst_writer.add_summary(summary, i + batch_num*e)\n",
    "            etoc = time.time() - etic\n",
    "            spend_t[1] += etoc\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch:\", e+1, \"Batch_iter:\", i, '\\n',\n",
    "                  \"Train Loss:\", loss, \"Valid Loss:\", val_loss, '\\n',\n",
    "                  \"trn_acc:\", round(trn_acc,3), \"val_acc:\", round(val_acc,3))\n",
    "            print(\"spend time = { row/sec:\", batch_size//otoc, \n",
    "                  \"optimize:\", round(otoc,3), \"eval:\", round(etoc,3), \n",
    "                  \"Elapsed:\", round(time.time() - tic,3), \"}\")\n",
    "\n",
    "    ## train stop logic\n",
    "    val_epoc_loss = val_epoc_loss / np.ceil(batch_num / val_step)\n",
    "    if val_epoc_loss <= prev_val_epoc_loss:\n",
    "        print(\"\\n\", \"Save the model : current loss \", val_epoc_loss, \"<=\", \n",
    "              prev_val_epoc_loss, \"prev loss\", \"\\n\")\n",
    "        saver.save(sess, work_dir + '/model/abuse.ckpt', global_step=e)\n",
    "        saver.save(sess, work_dir + '/model/abuse.ckpt-last')\n",
    "        prev_val_epoc_loss = val_epoc_loss\n",
    "    else:\n",
    "        trn_stop_penalty += 1\n",
    "        print(\"\\n\", \"train stop penalty:\", trn_stop_penalty, \n",
    "              \"current loss \", val_epoc_loss, \">\",\n",
    "              prev_val_epoc_loss, \"prev loss\", \"\\n\")\n",
    "        if trn_stop_penalty == 2:\n",
    "            break\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tensorboard --logdir work_dir/model/tb <br>\n",
    "위 tensorboard를 실행하면 학습과정을 확인할 수 있다. <br>\n",
    "파란선은 train, 주황선은 valid\n",
    "<img src=\"img/cost.png\" width=\"480\" height=\"320\" />\n",
    "<img src=\"img/accuracy.png\" width=\"480\" height=\"320\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best model parameter를 restore 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/khlee/tutorial/review_pos_neg_classification/model/abuse.ckpt-last\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "saver.restore(sess, work_dir + \"/model/abuse.ckpt-last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy: 0.85126173\n"
     ]
    }
   ],
   "source": [
    "tst_acc = sess.run(accuracy, feed_dict={inputs: tst_data[0], target: tst_data[1], \n",
    "                                        keep_prob: 1.0})\n",
    "print('test set accuracy:', tst_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "네이버 영화 리뷰 평점을 가지고 긍부정 리뷰를 분리하는 모델을 만드는, 튜토리얼 수준으로 진행하였다. <br>\n",
    "모델 과정을 단순하게 요약하면 다음과 같다. <br>\n",
    "\n",
    "1. 리뷰 단어들을 형태소 분석기를 통해 분리한다.\n",
    "2. 단어들을 word2vec model을 통해 벡터화 한다.\n",
    "3. RNN 기반의 모델을 통해 binomial classification 문제를 수행한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "위에서 수행한 과정은 리뷰의 긍부정을 분리하기 위해 단순하게 수행한 튜토리얼 수준으로 진행하였다. <br>\n",
    "모델을 고도화 하기 위해서는 다음과 같은 실험들이 수행되어야 한다. <br>\n",
    "\n",
    "1. 적절한 형태소 분석기의 선택.\n",
    "    * 위에서는 단순히 가장 많이 사용되는 twitter 형태소 분석기를 그대로 사용하였고, 형태소가 잘 분리 되었는지, 더 처리 되어야할 word들이 있는지에 대한 자세한 전처리 과정은 생략하였다.\n",
    "2. word2vec model 검증.\n",
    "    * 위에서는 프리트레이닝 개념으로 컴퓨팅 파워가 허락되는 선에서 간단하게 수행하였다.\n",
    "    * word2vec 모델의 파라미터 튜닝등 적절이 embedding 되었는지에 대한 추가 검증이 필요할 것으로 생각한다.\n",
    "3. RNN 모델의 고도화\n",
    "    * 위에서는 가장 많이 사용되는 LSTM 모형을 사용하였고, 파라미터 서치를 거치지 않았다.\n",
    "    * GRU, Bi-Rnn, Attention 등의 고도화된 모델을 수행해볼 필요가 있다.\n",
    "4. Label 데이터 변경\n",
    "    * 위 데이터는 긍, 부정(1,0)으로 프로세싱된 데이터를 참조하였다. \n",
    "    * binomial이 아닌 1~10점을 그대로 linear 변수를 사용하여 Score 예측을 수행하고, 후에 점수를 커팅하여 긍부정을 분리한다면, 더 좋은 성능을 보이지 않을까 생각해 본다.\n",
    "    * score로 예측하는 것이 추후 활용면에서 더 다양할 것으로 생각된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
